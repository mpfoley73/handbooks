[["index.html", "Statistics Handbook Statistics handbook for a data analyst Introduction", " Statistics Handbook Statistics handbook for a data analyst Michael Foley 2021-02-24 Introduction These notes mostly self-education from books, online classes, tutorials, vignettes, etc. They probably have a lot of mistakes, are poorly organized, and shaky on fundamentals. I hope over time this document grows and improves in quality along with my own mastery of data analysis, but thats all I can say for it. If you found this from an internet search, use at your own risk! The focus of this handbook is statistical inference, including population estimates, group comparisons, and regression modeling. Not included in this handbook is foundational knowledge of probability and statistics, machine learning, text mining, survey analysis, or survival analysis. All these subjects frequently arise at work, but seem distinct and large enough to warrant separate handbooks. "],["one-sample-inference-tests.html", "Chapter 1 One-Sample Inference Tests 1.1 One-Sample Mean z Test 1.2 One-Sample Mean t Test 1.3 One-Sample Median Wilcoxon Test 1.4 Chi-Squared Goodness-of-Fit Test 1.5 G-Test 1.6 One-Sample Poisson Test 1.7 One-Sample Binomial Test 1.8 One-Sample Proportion z Test 1.9 1 sample t Test for Categorical Var 1.10 Wilcoxon 1-Sample Median Test for Categorical Var", " Chapter 1 One-Sample Inference Tests Use one-sample tests to either describe a single variables frequency or central tendency, or to compare the frequency or central tendency to a hypothesized distribution or value. If the data generating process produces continuous outcomes (interval or ratio), and the outcomes are symmetrically distributed, the sample mean, \\(\\bar{x}\\), is a random variable centered at the population mean, \\(\\mu\\). You can then use a theoretical distribution (normal or student t) to estimate a 95% confidence interval (CI) around \\(\\mu\\), or compare \\(\\bar{x}\\) to an hypothesized population mean, \\(\\mu_0\\). If you (somehow) know the population variance, or the Central Limit Theorem (CLT) conditions hold, you can assume the random variable is normally distributed and use the z-test, otherwise assume the random variable has student t distribution and use the t-test.1 If the data generating process produces continuous outcomes that are not symmetrically distributed, use a non-parametric test like the Wilcoxon median test. If the data generating process produces discrete outcomes (counts), the sample count, \\(x\\), is a random variable from a Poisson, binomial, normal, or multinomial distribution, or a random variable from a theoretical outcome. For counts over a fixed time or space, treat the count as a random variable from a Poisson distribution with expected value \\(\\lambda\\) and variance \\(\\lambda\\). For counts within a fixed total that are then classified into two levels (usually yes/no), then treat the count as a random variable from a binomial distribution with expected value \\(n\\pi\\) and variance \\(n\\pi(1-\\pi)\\). For binomial distributions where \\(n\\ge30\\) and the frequency counts of both levels is \\(\\ge\\) 5, treat the proportion as a random variable from the normal distribution with expected valued \\(\\pi\\) and variance \\(\\frac{\\pi(1-\\pi)}{n}\\). For counts within a fixed total that are then classified into three or more levels, treat the count as a random variable from the multinomial distribution with expected value \\(n\\pi_j\\) and variance \\(n\\pi_j(1-\\pi_j)\\). Whatever the source of the expected values, you use either the chi-squared goodness-of-fit test or G test to test whether the observed values fit the expected values from the distribution. In the special case of binary outcomes with small (n &lt; 1,000), you can use Fishers exact test instead. The discrete variable tests are discussed in PSU STATS 504. 1.1 One-Sample Mean z Test The z test is also called the normal approximation z test. It only applies when the sampling distribution of the population mean is normally distributed with known variance, and there are no significant outliers. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. The t test returns similar results, plus it is valid when the variance is unknown, and that is pretty much always. For that reason, you probably will never use this test. Under the normal approximation method, the measured mean \\(\\bar{x}\\) approximates the population mean \\(\\mu\\), and the sampling distribution has a normal distribution centered at \\(\\mu\\) with standard error \\(se_\\mu = \\frac{\\sigma}{\\sqrt{n}}\\) where \\(\\sigma\\) is the standard deviation of the underlying population. Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm z_{(1 - \\alpha) {/} 2} se_\\mu\\), or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}\\). Example The mtcars data set is a sample of n = 32 cars. The mean fuel economy is \\(\\bar{x} \\pm s\\) = 20.1 \\(\\pm\\) 6.0 mpg. The prior measured overall fuel economy for vehicles was \\(\\mu_0 \\pm \\sigma\\) = 18.0 \\(\\pm\\) 6.0 mpg. Has fuel economy improved? The sample size is \\(\\ge\\) 30, so the sampling distribution of the population mean is normally distributed. The population variance is known, so use the z test. \\(H_0: \\mu = 16.0\\), and \\(H_a: \\mu &gt; 16.0\\) - a right-tail test. The test statistic is \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}=\\) 1.97 where \\(se_{\\mu_0} = \\frac{\\mu_0}{\\sqrt{n}} =\\) 1.06. \\(P(z &gt; Z) =\\) 0.0244, so reject \\(H_0\\) at the \\(\\alpha =\\) 0.05 level of significance. The 95% confidence interval for \\(\\mu\\) is \\(\\bar{x} \\pm z_{(1 - \\alpha){/}2} se_\\mu\\) where \\(z_{(1 - \\alpha){/}2} =\\) 1.96. \\(\\mu =\\) 20.09 \\(\\pm\\) 2.08 (95% CI 18.01 to 22.17). 1.2 One-Sample Mean t Test The one-sample t test applies when the sampling distribution of the population mean is normally distributed and there are no significant outliers. Unlike the z test, the population variance can be unknown. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. Under the t test method, the measured mean, \\(\\bar{x}\\), approximates the population mean, \\(\\mu\\). The sample standard deviation, \\(s\\), estimates the unknown population standard deviation, \\(\\sigma\\). The resulting sampling distribution has a t distribution centered at \\(\\mu\\) with standard error \\(se_\\bar{x} = \\frac{s}{\\sqrt{n}}\\). Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} se_\\bar{x}\\) and/or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(T = \\frac{\\bar{x} - \\mu_0}{se_\\bar{x}}\\). Example A researcher recruits a random sample of n = 40 people to participate in a study about depression intervention. The researcher measures the participants depression level prior to the study. The mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population normal depression score of 4.0. The null hypothesis is that the sample is representative of the overall population. Should you reject \\(H_0\\)? dep %&gt;% gtsummary::tbl_summary(statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dvakprykmu .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dvakprykmu .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dvakprykmu .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dvakprykmu .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #dvakprykmu .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dvakprykmu .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dvakprykmu .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dvakprykmu .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dvakprykmu .gt_column_spanner_outer:first-child { padding-left: 0; } #dvakprykmu .gt_column_spanner_outer:last-child { padding-right: 0; } #dvakprykmu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #dvakprykmu .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dvakprykmu .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dvakprykmu .gt_from_md > :first-child { margin-top: 0; } #dvakprykmu .gt_from_md > :last-child { margin-bottom: 0; } #dvakprykmu .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dvakprykmu .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dvakprykmu .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dvakprykmu .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dvakprykmu .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dvakprykmu .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dvakprykmu .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dvakprykmu .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dvakprykmu .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dvakprykmu .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dvakprykmu .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dvakprykmu .gt_sourcenote { font-size: 90%; padding: 4px; } #dvakprykmu .gt_left { text-align: left; } #dvakprykmu .gt_center { text-align: center; } #dvakprykmu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dvakprykmu .gt_font_normal { font-weight: normal; } #dvakprykmu .gt_font_bold { font-weight: bold; } #dvakprykmu .gt_font_italic { font-style: italic; } #dvakprykmu .gt_super { font-size: 65%; } #dvakprykmu .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 401 dep_score 3.72 (0.74) 1 Statistics presented: Mean (SD) Conditions The one-sample t test applies when the variable is continuous and the observations are independent. Additionally, there are two conditions related to the data distribution. If either condition fails, try the suggested work-arounds or use the non-parametric [Wilcoxon 1-Sample Median Test for Numeric Var] instead. Outliers. There should be no significant outliers. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Values should be nearly normally distributed (nearly because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. The boxplot shows no outliers. If the outliers might are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you have a couple options before reverting to Wilcoxon. Transform the variable. Dont do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult. Leave it in if it doesnt affect the conclusion (compared to taking it out). Normality Assume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still dont feel confident about normality, run a [Shapiro-Wilk Test]. The data set has n = 40 observations, so you can assume normality. Here is a QQ plot anyway. The QQ plot indicates normality. dep %&gt;% ggplot(aes(sample = dep_score)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) Here is the Shapiro-Wilk normality test. It fails to reject the null hypothesis of a normally distributed population. shapiro.test(dep$dep_score) ## ## Shapiro-Wilk normality test ## ## data: dep$dep_score ## W = 0.98446, p-value = 0.8474 If the data is not normally distributed, you still have a couple options before reverting to Wilcoxon. Transform the dependent variable. Carry on regardless - the one-sample t-test is fairly robust to deviations from normality. Results Conduct the t-test. To get a 95% CI around the difference (instead of around the estimate), run the test using the difference, \\(\\mu_0 - \\bar{x}\\), and leave mu at its default of 0. (dep_95ci &lt;- t.test(x = mu_0 - dep$dep_score, alternative = &quot;two.sided&quot;, conf.level = .95)) ## ## One Sample t-test ## ## data: mu_0 - dep$dep_score ## t = 2.3811, df = 39, p-value = 0.02224 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.04176615 0.51323385 ## sample estimates: ## mean of x ## 0.2775 The difference is statistically different from 0 at the p = .05 level. The effect size, called Cohens d, is defined as \\(d = |M_D| / s\\), where \\(|M_D| = \\bar{x} - \\mu_0\\), and \\(s\\) is the sample standard deviation. \\(d &lt;.2\\) is considered trivial, \\(.2 \\le d &lt; .5\\) small, and \\(.5 \\le d &lt; .8\\) large. (d &lt;- rstatix::cohens_d(dep, dep_score ~ 1, mu = 4) %&gt;% pull(effsize) %&gt;% abs()) ## Cohen&#39;s d ## 0.3764788 Cohens d is 0.38, a small effect. Make a habit of constructing a plot, just to make sure your head is on straight. Now you are ready to report the results. A one-sample t-test was run to determine whether depression score in recruited subjects was different from normal, as defined as a depression score of 4.0. Depression scores were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05) and there were no outliers in the data, as assessed by inspection of a boxplot. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population normal depression score of 4.00, a statistically significant difference of 0.28 (95% CI, 0.04 to 0.51), t(39) = 2.38, p = 0.022, d = 0.38. Appendix: Deciding Sample Size Determine the sample size required for a maximum error \\(\\epsilon\\) in the estimate by solving the confidence interval equation, \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} \\frac{s}{\\sqrt{n}}\\) for \\(n=\\frac{{t_{\\alpha/2,n-1}^2se^2}}{{\\epsilon^2}}\\) . Unfortunately, \\(t_{\\alpha/2,n-1}^2\\) is dependent on \\(n\\), so replace it with \\(z_{\\alpha/2}^2\\). What about \\(s^2\\)? Estimate it from the literature, a pilot study, or using the empirical rule that 95% of the range falls within two standard deviations, \\(s=range / 4\\). For example, if the maximum tolerable error is* \\(\\epsilon\\) = 3, and \\(s\\) is approximately 10, what sample size produces an \\(\\alpha\\) =0.05 confidence level? ceiling(qnorm(.975)^2 * 10^2 / 3^2) ## [1] 43 1.3 One-Sample Median Wilcoxon Test The Wilcoxon one-sample median test (aka Wilcoxon signed rank test) is a non-parametric alternative to the t-test for cases when the the sampling distribution of the population mean is not normally distributed, but is at least symmetric. Under the Wilcoxon test, the measured median, \\(\\eta_x\\), approximates the population median, \\(\\eta\\). The method calculates the difference between each value and the hypothesized median, \\(\\eta_0\\), ranks the difference magnitudes, then sums the ranks for the negative and the positive differences, \\(W+\\) and \\(W-\\). The test compares the smaller of the two sums to a table of critical values. Here is a case study. A store claims their checkout wait times are \\(\\le\\) 4 minutes. You challenge the claim by sampling 6 checkout experiences. The mean wait time was 4.6, but the data may violate normality. data.frame(wait = wait) %&gt;% ggplot(aes(sample = wait)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) Shapiro-Wilk rejects the null hypothesis of a normally distributed population. shapiro.test(wait) ## ## Shapiro-Wilk normality test ## ## data: wait ## W = 0.75105, p-value = 0.0204 Use the Wilcoxon test instead. (wt &lt;- wilcox.test(wait, mu = 4, alternative = &quot;greater&quot;)) ## Warning in wilcox.test.default(wait, mu = 4, alternative = &quot;greater&quot;): cannot ## compute exact p-value with ties ## ## Wilcoxon signed rank test with continuity correction ## ## data: wait ## V = 14.5, p-value = 0.2309 ## alternative hypothesis: true location is greater than 4 A Wilcoxon Signed-Ranks Test indicated that wait times were not statistically significantly higher than the 4-minute claim, z = 14.5, p = 0.231. 1.4 Chi-Squared Goodness-of-Fit Test Use the chi-squared goodness-of-fit test to test whether the observed frequency counts, \\(O_j\\), of the \\(J\\) levels of a categorical variable differ from the expected frequency counts, \\(E_j\\). \\(H_0\\) is \\(O_j = E_j\\). You can use this test for dichotomous, nominal, or ordinal variables. There are only two conditions to use this test: the observations are independent, meaning either random assignment or random sampling without replacement from &lt;10% of the population, and the expected frequency in each group is &gt;=5. The Pearson goodness-of-fit test statistic is \\[X^2 = \\sum \\frac{(O_j - E_j)^2}{E_j}\\] where \\(O_j = p_j n\\) and \\(E_j = \\pi_j n\\). The sampling distribution of \\(X^2\\) approaches the \\(\\chi_{J-1}^2\\) as the sample size \\(n \\rightarrow \\infty\\). The assumption that \\(X^2\\) is distributed \\(\\sim \\chi^2\\) is not quite correct, so you will see researchers subtract .5 from the differences to increase the p-value, the so-called Yates Continuity Correction. \\[X^2 = \\sum \\frac{(O_j - E_j - 0.5)^2}{E_j}\\] \\(X^2 \\rightarrow 0\\) as the saturated model (the observed data represent the fit of the saturated model, the most complex model possible with the data) proportions approach the expected proportions, \\(p_j \\rightarrow \\pi_j\\). The chi-squared test calculates the probability of the occurrence of \\(X^2\\) at least as extreme given that it is a chi-squared random variable with degrees of freedom equal to the number of levels of the variable minus one, \\(J-1\\). Example with Theoretical Values A researcher crosses tall cut-leaf tomatoes with dwarf potato-leaf tomatoes, then classifies the n = 1,611 offsprings phenotype. The four phenotypes should occur with relative frequencies 9:3:3:1. The observed frequencies constitute a one-way table. If you only care about one level (or if the variable is binary) of if, conduct a one-proportion Z-test or an exact binomial test. Otherwise, conduct an exact multinomial test (recommended when n &lt;= 1,000), Pearsons chi-squared goodness-of-fit test, or a G-test. Conditions This is a randomized experiment. The minimum expected frequency was 100, so the chi-squared test of independence is valid. Had the data violated the \\(\\ge\\) 5 condition, you could run an exact test (like the binomial, or in this case, the multinomial), or lump some factor levels together. Results You can calculate \\(X^2\\) by hand, and find the probability of a test statistic at least as extreme using the \\(\\chi^2\\) distribution with 4-1 = 3 degrees of freedom. (pheno_x2 &lt;- sum((pheno_obs - pheno_exp)^2 / pheno_exp)) ## [1] 9.54652 (pheno_p &lt;- pchisq(q = pheno_x2, df = length(pheno_type) - 1, lower.tail = FALSE)) ## [1] 0.02284158 That is what chisq.test() does. The function applies the Yates continuity correction by default, so I had to specify correct = FALSE to exclude it. In this case, setting it to TRUE has almost no effect because the sample size is large. (pheno_chisq_test &lt;- chisq.test(pheno_obs, p = pheno_pi, correct = FALSE)) ## ## Chi-squared test for given probabilities ## ## data: pheno_obs ## X-squared = 9.5465, df = 3, p-value = 0.02284 As always, plot the distribution. At this point you can report, Of the 1,611 offspring produced from the cross-fertiliation, 956 were tall cut-leaf, 258 were tall potato-leaf, 293 where dwarf cut-leaf, and 104 were dwarf potato-leaf. A chi-square goodness-of-fit test was conducted to determine whether the offspring had the same proportion of phenotypes as the theoretical distribution. The minimum expected frequency was 101. The chi-square goodness-of-fit test indicated that the number of tall cut-leaf, tall potato-leaf, dwarf cut-leaf, and dwarf potato-leaf offspring was statistically significantly different from the proportions expected in the theoretical distribution (\\(X^2\\)(3) = 9.547, p = 0.023). If you reject \\(H_0\\), inspect the residuals to learn which differences contribute most to the rejection. Notice how \\(X^2\\) is a sum of squared standardized cell differences, or Pearson residuals, \\[r_i = \\frac{o_j - e_j}{\\sqrt{e_j}}\\] Cells with the largest \\(|r|\\) contribute the most to the total \\(X^2\\). pheno_chisq_test$residuals^2 / pheno_chisq_test$statistic ## tall cut-leaf tall potato-leaf dwarf cut-leaf dwarf potato-leaf ## 0.28682269 0.67328098 0.02848093 0.01141540 The two tall cells contributed over 95% of the \\(X^2\\) test statistic, with the tall potato-leaf accounting for 67%. This aligns with what youd expect from the bar plot. Example with Theoretical Distribution You need to reduce the degrees of freedom (df) in the chi-squared goodness-of-fit test by 1 if you test whether the data conform to a particular distribution instead of a set of theoretical values. j &lt;- c(0:5) o &lt;- c(19, 26, 29, 13, 10, 3) childr_n &lt;- as.character(0:5) Suppose you sample n = 100 families and count the number of children. The count of children is a Poisson random variable, \\(J\\), with maximum likelihood estimate \\(\\hat{\\lambda} = \\sum{j_i O_i} / \\sum{O_i}\\). Test whether the observed values can be described as samples from a Poisson random variable. The probabilities for each possible count are \\[f(j; \\lambda) = \\frac{e^{-\\hat{\\lambda}} \\hat{\\lambda}^j}{j!}.\\] Conditions This is random sampling. The minimum expected frequency was 2, so the data violates the \\(\\ge\\) 5 rule. Lump the last two categories into 4-5. The minimum expected frequency was 6, so now the chi-squared test of independence is valid. Results Compare the expected values to the observed values with the chi-squared goodness of fit test, but in this case \\(df = 5 - 1 - 1\\) because the estimated parameter \\(\\lambda\\) reduces df by 1. You cannot set df in chisq.test(), so perform the test manually. (X2 &lt;- sum((o - e)^2 / e)) ## [1] 7.092968 (p.value &lt;- pchisq(q = X2, df = length(j) - 1 - 1, lower.tail = FALSE)) ## [1] 0.06899286 At this point you can report, Of the 100 families sampled, 19 had no children, 26 had one child, 29 had two children, 13 had three children, and 13 had 4 or 5 children. A chi-square goodness-of-fit test was conducted to determine whether the observed family sizes follow a Poisson distribution. The minimum expected frequency was 13. The chi-square goodness-of-fit test indicated that the number of children was not statistically significantly different from the proportions expected in the Poisson distribution (\\(X^2\\)(3) = 7.093, p = 0.069). 1.5 G-Test The G-test is a likelihood-ratio statistical significance test increasingly used instead of chi-squared tests. The test statistic is defined \\[G^2 = 2 \\sum O_j \\log \\left[ \\frac{O_j}{E_j} \\right]\\] where the 2 multiplier asymptotically aligns with the chi-squared test formula. G is distributed \\(\\sim \\chi^2\\), with the same number of degrees of freedom as in the corresponding chi-squared test. In fact, the chi-squared test statistic is a second order Taylor expansion of the natural logarithm around 1. Returning to the phenotype case study in the chi-squared goodness-of-fit test section, you can calculate the \\(G^2\\) test statistic and probability by hand. (pheno_g2 &lt;- 2 * sum(pheno_obs * log(pheno_obs / pheno_exp))) ## [1] 9.836806 (pchisq(q = pheno_g2, df = length(pheno_type) - 1, lower.tail = FALSE)) ## [1] 0.02000552 This is pretty close to the \\(X^2\\) = 9.547, p = 0.023 using the chi-squared goodness-of-fit test. The DescTools::GTest() function to conducts a G-test. DescTools::GTest(pheno_obs, p = pheno_pi) ## ## Log likelihood ratio (G-test) goodness of fit test ## ## data: pheno_obs ## G = 9.8368, X-squared df = 3, p-value = 0.02001 According to the function documentation, the G-test is not usually used for 2x2 tables. EMT::multinomial.test(o, f, useChisq = TRUE) ## ## Exact Multinomial Test, distance measure: chisquare ## ## Events chi2Obs p.value ## 4598126 7.093 0.1479 chisq.test(o, e) ## Warning in chisq.test(o, e): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: o and e ## X-squared = 15, df = 12, p-value = 0.2414 1.6 One-Sample Poisson Test If \\(X\\) is the number of successes in \\(n\\) (many) trials when the probability of success \\(\\lambda / n\\) is small, then \\(X\\) is a random variable with a Poisson distribution, and the probability of observing \\(X = x\\) successes is \\[f(x;\\lambda) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\hspace{1cm} x \\in (0, 1, ...), \\hspace{2mm} \\lambda &gt; 0\\] with \\(E(X)=\\lambda\\) and \\(Var(X) = \\lambda\\) where \\(\\lambda\\) is estimated by the sample \\(\\hat{\\lambda}\\), \\[\\hat{\\lambda} = \\sum_{i=1}^N x_i / n.\\] Poisson sampling is used to model counts of events that occur randomly over a fixed period of time. You can use the Poisson distribution to perform an exact test on a Poisson random variable. Example You are analyzing goal totals from a sample consisting of the 95 matches in the first round of the 2002 World Cup. The average match produced a mean/sd of 1.38 \\(\\pm\\) 1.28 goals, lower than the 1.5 historical average. Should you reject the null hypothesis that the sample is representative of typical values? Conditions The events must be independent of each other. In this case, the goal-count in one match has no effect on goal-counts in other matches. The expected value of each event must be the same (homogeneity). In this case, the expected goal-count of each match is the same regardless of which teams are playing. This assumption is often dubious, causing the distribution variance to be larger than the mean, a conditional called over-dispersion. You might also check whether the data is consistent with a Poisson model. This is random sampling, but the data violates the \\(\\ge\\) 5 rule because the minimum expected frequency was 0. To comply with the minimum frequency rule, lump the last six categories into 3-8. The minimum expected frequency was 15, so now the chi-squared test of independence is valid. Compare the expected values to the observed values with the chi-squared goodness of fit test, but in this case \\(df = 4 - 1 - 1\\) because the estimated parameter \\(\\lambda\\) reduces the df by 1. You cannot set df in chisq.test(), so perform the test manually. (X2 &lt;- sum((o - e)^2 / e)) ## [1] 0.8618219 (p.value &lt;- pchisq(q = X2, df = length(j) - 1 - 1, lower.tail = FALSE)) ## [1] 0.6499168 Of the 95 World Cup matches, 23 had no goals, 37 had one goal, 20 had two goals, and 15 had 3-8 goals. A chi-square goodness-of-fit test was conducted to determine whether the observed goal counts follow a Poisson distribution. The minimum expected frequency was 15. The chi-square goodness-of-fit test indicated that the number of goals scored was not statistically significantly different from the frequencies expected from a Poisson distribution (\\(X^2\\)(2) = 0.862, p = 0.650). Results The conditions for the exact Poisson test were met, so go ahead and run the test. (pois_val &lt;- poisson.test( x = sum(dat_pois$goals * dat_pois$freq), T = sum(dat_pois$freq), r = 1.5) ) ## ## Exact Poisson test ## ## data: sum(dat_pois$goals * dat_pois$freq) time base: sum(dat_pois$freq) ## number of events = 131, time base = 95, p-value = 0.3567 ## alternative hypothesis: true event rate is not equal to 1.5 ## 95 percent confidence interval: ## 1.152935 1.636315 ## sample estimates: ## event rate ## 1.378947 Construct a plot showing the 95% CI around the hypothesized value. For a Poisson distribution, I built the distribution around the expected value, \\(n\\lambda\\), not the rate, \\(\\lambda\\). I think you could report these results like this. A one-sample exact Poisson test was run to determine whether the number of goals scored in the first round of the 2002 World Cup was different from past World Cups, 1.5. A chi-square goodness-of-fit test indicated that the number of goals was not statistically significantly different from the counts expected in the Poisson distribution (\\(X^2\\)(2) = 0.862, p = 0.650). Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Mean goals scored (1.38 \\(\\pm\\) 1.28) was lower than the historical mean of 1.50, but was not statistically significantly different (95% CI, 1.15 to 1.64), p = 0.357. 1.7 One-Sample Binomial Test The Clopper-Pearson exact binomial test is precise, but theoretically complicated in that it inverts two single-tailed binomial tests. No theoretical knowledge here - I just rely on the software. Use the exact binomial test when small sample sizes and/or extreme success probabilities invalidate the chi-square and G tests. The exact binomial test has two conditions: independence, and at least \\(n\\pi \\ge 5\\) successes or \\(n(1\\pi)\\ge 5\\) failures. You can use this test for multinomial variables too, but the test only compares a single levels proportion to a hypothesized value. Example A pharmaceutical company claims its drug reduces fever in &gt;60% of cases. In a random sample of n = 40 cases the drug reduces fever in 20 cases. Do you reject the claim? Conditions You are testing \\(P(x \\le 20)\\) in n = 40 trials when p = 60%, a one-tail test. The sample is a random assignment experiment with 20 successes and 20 failures, so it meets the conditions for the exact binomial test. Results pbinom(q = 20, size = 40, p = 0.6, lower.tail = TRUE) ## [1] 0.1297657 binom.test(20, 40, p = 0.6, alternative = &quot;less&quot;) ## ## Exact binomial test ## ## data: 20 and 40 ## number of successes = 20, number of trials = 40, p-value = 0.1298 ## alternative hypothesis: true probability of success is less than 0.6 ## 95 percent confidence interval: ## 0.0000000 0.6389083 ## sample estimates: ## probability of success ## 0.5 The exact binomial test uses the method of small p-values, in which the probability of observing a proportion \\(p\\) as far or further from \\(\\pi_0\\) is the sum of all \\(P(X=p_i)\\) where \\(p_i &lt;= p\\). map_dbl(dbinom(0:20, 40, 0.6), ~if_else(. &lt;= 0.5, ., 0)) %&gt;% sum() ## [1] 0.1297657 You could have used the chi-squared goodness-of-fit test, however, it is not performing a one-tail test. chisq.test(x = c(20, 20), p = c(0.6, 0.4), correct = FALSE) ## ## Chi-squared test for given probabilities ## ## data: c(20, 20) ## X-squared = 1.6667, df = 1, p-value = 0.1967 You should study the construction of the confidence interval on Wikipedia and explain it here. 1.8 One-Sample Proportion z Test The z-test uses the sample proportion of group \\(j\\), \\(p_j\\), as an estimate of the population proportion \\(\\pi_j\\) to evaluate an hypothesized population proportion \\(\\pi_{0j}\\) and/or construct a \\((1\\alpha)\\%\\) confidence interval around \\(p_j\\) to estimate \\(\\pi_j\\) within a margin of error \\(\\epsilon\\). The z-test is intuitive to learn, but it only applies when the central limit theorem conditions hold: the sample is independently drawn, meaning random assignment (experiments), or random sampling without replacement from &lt;10% of the population (observational studies), there are at least 5 successes and 5 failures, the sample size is &gt;=30, and the expected probability of success is not extreme, between 0.2 and 0.8. If these conditions hold, the sampling distribution of \\(\\pi\\) is normally distributed around \\(p\\) with standard error \\(se_p = \\frac{s_p}{\\sqrt{n}} = \\frac{\\sqrt{p(1p)}}{\\sqrt{n}}\\). The measured values \\(p\\) and \\(s_p\\) approximate the population values \\(\\pi\\) and \\(\\sigma_\\pi\\). You can define a \\((1  \\alpha)\\%\\) confidence interval as \\(p \\pm z_{\\alpha / 2}se_p\\). Test the hypothesis of \\(\\pi = \\pi_0\\) with test statistic \\(z = \\frac{p  \\pi_0}{se_{\\pi_0}}\\) where \\(se_{\\pi_0} = \\frac{s_{\\pi_0}}{\\sqrt{n}} = \\frac{\\sqrt{{\\pi_0}(1{\\pi_0})}}{\\sqrt{n}}\\). Example A machine is supposed to randomly churn out prizes in 60% of boxes. In a random sample of n = 40 boxes there are prizes in 20 boxes. Is the machine flawed? prop.test(20, 40, 0.6, &quot;two.sided&quot;, correct = FALSE) ## ## 1-sample proportions test without continuity correction ## ## data: 20 out of 40, null probability 0.6 ## X-squared = 1.6667, df = 1, p-value = 0.1967 ## alternative hypothesis: true p is not equal to 0.6 ## 95 percent confidence interval: ## 0.3519953 0.6480047 ## sample estimates: ## p ## 0.5 The first thing youll notice is that prop.test() performs a chi-squared goodness-of-fit test, not a one-proportion Z-test! chisq.test(c(20, 40-20), p = c(.6, .4), correct = FALSE) ## ## Chi-squared test for given probabilities ## ## data: c(20, 40 - 20) ## X-squared = 1.6667, df = 1, p-value = 0.1967 It turns out \\(P(\\chi^2 &gt; X^2)\\) equals \\(2 \\cdot P(Z &gt; z).\\) Here is the manual calculation of the chi-squared test statistic \\(X^2\\) and resulting p-value on 1 dof. pi_0 &lt;- .6 p &lt;- 20 / 40 observed &lt;- c(p, 1-p) * 40 expected &lt;- c(pi_0, 1-pi_0) * 40 X2 &lt;- sum((observed - expected)^2 / expected) pchisq(X2, 1, lower.tail = FALSE) ## [1] 0.1967056 And here is the manual calculation of the Z-test statistic \\(z\\) and resulting p-value. se &lt;- sqrt(pi_0*(1-pi_0)) / sqrt(40) z &lt;- (p - pi_0) / se pnorm(z, lower.tail = TRUE) * 2 ## [1] 0.1967056 The 95% CI presented by prop.test() is also not the \\(p \\pm z_{\\alpha / 2}se_p\\) Wald interval; it is the Wilson interval! DescTools::BinomCI(20, 40, method = &quot;wilson&quot;) ## est lwr.ci upr.ci ## [1,] 0.5 0.3519953 0.6480047 There are a lot of methods (see ?DescTools::BinomCI), and Wilson is the one Agresti-Coull recommends. If you want Wald, use DescTools::BinomCI() with method = \"wald\". DescTools::BinomCI(20, 40, method = &quot;wald&quot;) ## est lwr.ci upr.ci ## [1,] 0.5 0.3450512 0.6549488 This matches the manual calculation below. z_crit = qnorm(1 - .05/2) se &lt;- sqrt(p*(1-p)) / sqrt(40) (CI &lt;- c(p - z_crit*se, p + z_crit*se)) ## [1] 0.3450512 0.6549488 prop.test() (and chissq.test()) reported a p-value of 0.1967056, so you cannot reject the null hypothesis that \\(\\pi = 0.6\\). Its good practice to plot this out to make sure your head is on straight. Incidentally, if you have a margin of error requirement, you can back into the required sample size to achieve it. Just solve the margin of error equation \\(\\epsilon = z_{\\alpha/2}^2 = \\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}\\) for \\(n = \\frac{z_{\\alpha/2}^2 \\pi_0(1-\\pi_0)}{\\epsilon^2}.\\) 1.9 1 sample t Test for Categorical Var This test applies when you do not know the population variance. 1.10 Wilcoxon 1-Sample Median Test for Categorical Var This test applies when the variable is not normally distributed. The t-test returns nearly the same result as the z-test when the CLT holds, so in practice no one bothers with the z-test except as an aid to teach the t-test. "],["two-group-comparison-tests.html", "Chapter 2 Two-Group Comparison Tests 2.1 Independent Samples t Test 2.2 Paired Samples t Test 2.3 Mann-Whitney U Test for Numeric Vars 2.4 Wilcoxon Paired-Sample Test for Numeric Vars 2.5 Pearsons Correlation for Numeric Vars 2.6 Spearmans Ranked Correlation for Numeric Vars 2.7 2 Sample Independent t Test for Categorical Vars 2.8 2 Sample Welchs t Test for Categorical Vars 2.9 Paired Sample t Test for Categorical Vars 2.10 Mann-Whitney U Test for Categorical Vars 2.11 Wilcoxon Paired-Sample Test for Categorical Vars 2.12 Pearsons Correlation for Categorical Vars 2.13 Spearmans Ranked Correlation for Categorical Vars 2.14 Fishers Exact Test", " Chapter 2 Two-Group Comparison Tests Use independent samples tests to either describe a variables frequency or central tendency difference between two independent groups, or to compare the difference to a hypothesized value. If the data generating process produces continuous outcomes (interval or ratio) and the outcomes are symmetrically distributed, the difference in the sample means, \\(\\hat{d} = \\bar{x} - \\bar{y}\\), is a random variable centered at the population difference, \\(d = \\mu_X - \\mu_Y\\). You can use a theoretical distribution (normal or student t) to estimate a 95% confidence interval (CI) around \\(d\\), or compare \\(\\hat{d}\\) to an hypothesized population difference, \\(d_0\\). If you (somehow) know the sampling distribution variances \\(\\sigma^2_X\\) and \\(\\sigma^2_Y\\), or the Central Limit Theorem (CLT) conditions hold, you can assume the random variable is normally distributed and use the z-test, otherwise assume the random variable has a student t distribution and use the t-test.2 If the data generating process produces continuous outcomes that are not symmetrically distributed, use a non-parametric test like the Mann-Whitney U test. If the data generating process produces discrete outcomes (counts), the sample count, \\(x\\), is a random variable from a Poisson, binomial, normal, or multinomial distribution, or a random variable from a theoretical outcome. For two independent samples, the data can be organized into a two-way table - a frequency table for two categorical variables. If you have a single categorical predictor variable, you can test whether the joint frequency counts differ from the expected frequency counts in the saturated model. You analyze a two-way table one of two ways. If you only care about comparing two levels (like when the response variable is binary), conduct a proportion difference z-test or a Fisher exact test. If you want to compare the joint frequency counts to expected frequency counts under the independence model (the model of independent explanatory variables), conduct a Pearsons chi-squared independence test, or a G-test. 2.1 Independent Samples t Test If a population measure X is normally distributed with mean \\(\\mu_X\\) and variance \\(\\sigma_X^2\\), and population measure Y is normally distributed with mean \\(\\mu_Y\\) and variance \\(\\sigma_Y^2\\), then their difference is normally distributed with mean \\(d = \\mu_X - \\mu_Y\\) and variance \\(\\sigma_{XY}^2 = \\sigma_X^2 + \\sigma_Y^2\\). By the CLT, as the sample sizes grow, non-normally distributed X and Y will approach normality, and so will their difference. The independent samples t-test uses the difference in sample means \\(\\hat{d} = \\bar{x} - \\bar{y}\\) as an estimate of \\(d\\) to evaluate an hypothesized difference, \\(d_0\\). The null hypothesis is \\(d = d_0\\). Alternatively, you can construct a \\((1 - \\alpha)\\%\\) confidence interval around \\(\\hat{d}\\) to estimate \\(d\\) within a margin of error, \\(\\epsilon\\). In principal, you can test the difference between independent means with either a z test or a t test. Both require independent samples and approximately normal sampling distributions. The sampling distributions are normal if the underlying populations are normally distributed, or if the sample sizes are large (\\(n_X\\) and \\(n_Y\\) \\(\\ge\\) 30). However, the z-test additionally requires known sampling distribution variances \\(\\sigma^2_X\\) and \\(\\sigma^2_Y\\). These variances are never known, so always use the t-test. The z-test assumes \\(d\\) has a normal distribution centered at \\(\\hat{d} = d\\) with standard error \\(se = \\sqrt{\\frac{\\sigma_X^2}{n_X} + \\frac{\\sigma_Y^2}{n_Y}}.\\) Test \\(H_0: d = d_0\\) with test statistic \\(Z = \\frac{\\hat{d} - d_0}{se}\\) or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(d = \\hat{d} \\pm z_{(1 - \\alpha {/} 2)} se\\). The t-test assumes \\(d\\) has a t distribution centered at \\(\\hat{d} = d\\) with standard error \\(se = \\sqrt{\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}}.\\) Test \\(H_0: d = d_0\\) with test statistic \\(T = \\frac{\\hat{d} - d_0}{se}\\), or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(d = \\hat{d} \\pm t_{(1 - \\alpha / 2), (n_X + n_Y - 2)} se\\). However, there is an issue with the t test degrees of freedom. If the sample sizes are small, and the standard deviations from each population are similar (the ratios of \\(s_X\\) and \\(s_Y\\) are &lt;2), you can pool the variances \\(s_p^2 = \\frac{(n_X - 1) s_X^2 + (n_Y-1) s_Y^2}{n_X + n_Y-2}\\) so that \\(se = s_p \\sqrt{\\frac{1}{n_X} + \\frac{1}{n_Y}}\\) and \\(df = n_X + n_Y -2\\). This is call the pooled variances t-test. Otherwise, \\(se = \\sqrt{\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}}\\), but you must reduce the degrees of freedom using the Welch-Satterthwaite correction, \\(df = \\frac{\\left(\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}\\right)^2}{\\frac{s_X^4}{n_X^2\\left(N_X-1\\right)} + \\frac{s_Y^4}{n_Y^2\\left(N_Y-1\\right)}}.\\) This is called the separate variance t-test, or Welchs t-test. Example A company shows an advertisement to \\(n_M\\) = 20 males and \\(n_F\\) = 20 females, then measures their engagement with a survey. Do the mean engagement scores differ between the groups? engage_gt &lt;- engage %&gt;% gtsummary::tbl_summary(by = gender, statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) engage_gt html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #rjxfqxphtf .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rjxfqxphtf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rjxfqxphtf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rjxfqxphtf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #rjxfqxphtf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rjxfqxphtf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rjxfqxphtf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rjxfqxphtf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rjxfqxphtf .gt_column_spanner_outer:first-child { padding-left: 0; } #rjxfqxphtf .gt_column_spanner_outer:last-child { padding-right: 0; } #rjxfqxphtf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #rjxfqxphtf .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #rjxfqxphtf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rjxfqxphtf .gt_from_md > :first-child { margin-top: 0; } #rjxfqxphtf .gt_from_md > :last-child { margin-bottom: 0; } #rjxfqxphtf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rjxfqxphtf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #rjxfqxphtf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rjxfqxphtf .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #rjxfqxphtf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rjxfqxphtf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rjxfqxphtf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rjxfqxphtf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rjxfqxphtf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rjxfqxphtf .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #rjxfqxphtf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rjxfqxphtf .gt_sourcenote { font-size: 90%; padding: 4px; } #rjxfqxphtf .gt_left { text-align: left; } #rjxfqxphtf .gt_center { text-align: center; } #rjxfqxphtf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rjxfqxphtf .gt_font_normal { font-weight: normal; } #rjxfqxphtf .gt_font_bold { font-weight: bold; } #rjxfqxphtf .gt_font_italic { font-style: italic; } #rjxfqxphtf .gt_super { font-size: 65%; } #rjxfqxphtf .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Male, N = 201 Female, N = 201 engagement 5.56 (0.29) 5.30 (0.39) 1 Statistics presented: Mean (SD) You can report the following initially. There were 20 male and 20 female participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. The advertisement was more engaging to male viewers, 5.56 (0.29), than female viewers, 5.30 (0.39). Conditions The independent samples t test applies when the variable is continuous, partitioned into two independent samples, and the observations are independent. Additionally, there are three conditions related to the data distribution. If any condition fails, try the suggested work-around or use the non-parametric Mann-Whitney U Test instead. Outliers. There should be no outliers in either group because they exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Values should be nearly normally distributed (nearly because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data. Homogeneous Variances. If variances are homogenous, you can use the pooled-variances method; otherwise you use the separate variance method. Test with Levenes test of equality of variances. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. There are no outliers is this plot. Report this as There were no outliers in the data, as assessed by inspection of a boxplot. If the outliers are data entry errors or measurement errors, fix or discard them. If the outliers are genuine, you have a couple options before reverting to the Mann-Whitney U test. Leave it in if it doesnt affect the conclusion (compared to taking it out). Transform the variable. Dont do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult. Normality Assume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still dont feel confident about normality, run a Mann-Whitney U Test. The data set has \\(n_M\\) = 20 male and \\(n_F\\) = 20 female observations, so you need to test normality. The QQ plot indicates normality. engage %&gt;% ggplot(aes(sample = engagement, group = gender, color = fct_rev(gender))) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + theme(legend.position = &quot;top&quot;) + labs(title = &quot;Normal Q-Q Plot&quot;, color = NULL) Both Shapiro-Wilk normality tests (males and females) fail to reject the normality assumption. Report this as Engagement scores for each level of gender were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05). split(engage, engage$gender) %&gt;% map(~shapiro.test(.$engagement)) ## $Male ## ## Shapiro-Wilk normality test ## ## data: .$engagement ## W = 0.98344, p-value = 0.9705 ## ## ## $Female ## ## Shapiro-Wilk normality test ## ## data: .$engagement ## W = 0.96078, p-value = 0.5595 If the data is not normally distributed, you still have a couple options before reverting to the Mann-Whitney U test. Transform the dependent variable. Carry on regardless - the independent samples t-test is fairly robust to deviations from normality. Homogenous Variances Use the pooled-variances method if variances are homogeneous; otherwise use the separate variance method. A rule of thumb is that homogeneous variances have a ratio of standard deviations between 0.5 and 2.0: sd(engage %&gt;% filter(gender == &quot;Male&quot;) %&gt;% pull(engagement)) / sd(engage %&gt;% filter(gender == &quot;Female&quot;) %&gt;% pull(engagement)) ## [1] 0.7419967 You can also use the F test to compare the ratio of the sample variances \\(\\hat{r} = s_X^2 / s_Y^2\\) to an hypothesized ratio of population variances \\(r_0 = \\sigma_X^2 / \\sigma_Y^2 = 1.\\) var.test(engage %&gt;% filter(gender == &quot;Female&quot;) %&gt;% pull(engagement), engage %&gt;% filter(gender == &quot;Male&quot;) %&gt;% pull(engagement)) ## ## F test to compare two variances ## ## data: engage %&gt;% filter(gender == &quot;Female&quot;) %&gt;% pull(engagement) and engage %&gt;% filter(gender == &quot;Male&quot;) %&gt;% pull(engagement) ## F = 1.8163, num df = 19, denom df = 19, p-value = 0.2025 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.7189277 4.5888826 ## sample estimates: ## ratio of variances ## 1.816336 Bartletts test is a second option. bartlett.test(engage$engagement, engage$gender) ## ## Bartlett test of homogeneity of variances ## ## data: engage$engagement and engage$gender ## Bartlett&#39;s K-squared = 1.6246, df = 1, p-value = 0.2024 Levenes test is a third option. Levenes is less sensitive to departures from normality than Bartlett. engage_report$levene &lt;- with(engage, car::leveneTest(engagement, gender, center = &quot;mean&quot;)) engage_report$levene ## Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) ## Df F value Pr(&gt;F) ## group 1 1.922 0.1737 ## 38 Report these results as There was homogeneity of variances for engagement scores for males and females, as assessed by Levenes test for equality of variances (p = 0.174). Results Conduct the t-test. To get a 95% CI around the difference (instead of around the estimate), run the test using the difference, \\(\\mu_0 - \\bar{x}\\), and leave mu at its default of 0. (engage_95ci &lt;- t.test(engagement ~ gender, data = engage, var.equal = TRUE)) ## ## Two Sample t-test ## ## data: engagement by gender ## t = 2.3645, df = 38, p-value = 0.02327 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.03725546 0.48074454 ## sample estimates: ## mean in group Male mean in group Female ## 5.558875 5.299875 engage_gt html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #uaduocsclp .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #uaduocsclp .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uaduocsclp .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #uaduocsclp .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #uaduocsclp .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uaduocsclp .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uaduocsclp .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #uaduocsclp .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #uaduocsclp .gt_column_spanner_outer:first-child { padding-left: 0; } #uaduocsclp .gt_column_spanner_outer:last-child { padding-right: 0; } #uaduocsclp .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #uaduocsclp .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #uaduocsclp .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #uaduocsclp .gt_from_md > :first-child { margin-top: 0; } #uaduocsclp .gt_from_md > :last-child { margin-bottom: 0; } #uaduocsclp .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #uaduocsclp .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #uaduocsclp .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uaduocsclp .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #uaduocsclp .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uaduocsclp .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #uaduocsclp .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #uaduocsclp .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uaduocsclp .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uaduocsclp .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #uaduocsclp .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uaduocsclp .gt_sourcenote { font-size: 90%; padding: 4px; } #uaduocsclp .gt_left { text-align: left; } #uaduocsclp .gt_center { text-align: center; } #uaduocsclp .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #uaduocsclp .gt_font_normal { font-weight: normal; } #uaduocsclp .gt_font_bold { font-weight: bold; } #uaduocsclp .gt_font_italic { font-style: italic; } #uaduocsclp .gt_super { font-size: 65%; } #uaduocsclp .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Male, N = 201 Female, N = 201 engagement 5.56 (0.29) 5.30 (0.39) 1 Statistics presented: Mean (SD) Report this as: There was a statistically significant difference in mean engagement score between males and females, with males scoring higher than females, 0.26 (95% CI, 0.04 to 0.48), t(38) = 2.365, p = 0.023. The effect size, called Cohens d, is defined as \\(d = |M_D| / s\\), where \\(|M_D| = \\bar{x} - \\bar{y}\\), and \\(s\\) is the pooled sample standard deviation, \\(s_p = \\sqrt{\\frac{(n_X - 1) s_X^2 + (n_Y-1) s_Y^2}{n_X + n_Y-2}}\\). \\(d &lt;.2\\) is considered trivial, \\(.2 \\le d &lt; .5\\) small, and \\(.5 \\le d &lt; .8\\) large. (d &lt;- effectsize::cohens_d(engagement ~ gender, data = engage, pooled_sd = TRUE)) ## Cohen&#39;s d | 95% CI ## ------------------------ ## 0.75 | [0.10, 1.39] ## - Estimate using pooled SD Always construct a plot, just to make sure your head is on straight. Now you are ready to report the results. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. There were 20 male and 20 female participants. An independent-samples t-test was run to determine if there were differences in engagement to an advertisement between males and females. There were no outliers in the data, as assessed by inspection of a boxplot. Engagement scores for each level of gender were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05), and there was homogeneity of variances, as assessed by Levenes test for equality of variances (p = 0.174). There were 20 male and 20 female participants. The advertisement was more engaging to male viewers (5.56 \\(\\pm\\) = 0.29) than female viewers (5.30 \\(\\pm\\) = 0.39), a statistically significant difference of 0.26 (95% CI, 0.04 to 0.48), t(38) = 2.365, p = 0.023, d = 0.75. 2.2 Paired Samples t Test The paired two-sample test uses the mean of sampled paired differences \\(\\bar{d} = \\sum_{i = 1}^n (x_i - y_i) {/} n\\) as an estimate of the mean of the population paired differences \\(\\delta\\) to evaluate the hypothesized mean of population paired differences \\(\\delta_0\\). Test \\(H_0: \\delta = \\delta_0\\) with test statistic \\(T = \\frac{\\bar{d} - \\delta_0}{se}\\), or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\delta = \\bar{d} \\pm t_{1 - \\alpha / 2, n - 1} se\\). The paired t-test is really just a single mean t-test operating on variable that is defined as the difference between two variables. Example \\(n\\) = 20 athletes consume a carb-only or carb+protein drink prior to running as far as possible in 2 hours and a researcher measures their distances under both conditions. Does the mean differences in scores differ from 0? drink_gt &lt;- drink %&gt;% gtsummary::tbl_summary(statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) drink_gt html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xdrqkugqtb .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xdrqkugqtb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xdrqkugqtb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xdrqkugqtb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #xdrqkugqtb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xdrqkugqtb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xdrqkugqtb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xdrqkugqtb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xdrqkugqtb .gt_column_spanner_outer:first-child { padding-left: 0; } #xdrqkugqtb .gt_column_spanner_outer:last-child { padding-right: 0; } #xdrqkugqtb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #xdrqkugqtb .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xdrqkugqtb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xdrqkugqtb .gt_from_md > :first-child { margin-top: 0; } #xdrqkugqtb .gt_from_md > :last-child { margin-bottom: 0; } #xdrqkugqtb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xdrqkugqtb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xdrqkugqtb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xdrqkugqtb .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xdrqkugqtb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xdrqkugqtb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xdrqkugqtb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xdrqkugqtb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xdrqkugqtb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xdrqkugqtb .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xdrqkugqtb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xdrqkugqtb .gt_sourcenote { font-size: 90%; padding: 4px; } #xdrqkugqtb .gt_left { text-align: left; } #xdrqkugqtb .gt_center { text-align: center; } #xdrqkugqtb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xdrqkugqtb .gt_font_normal { font-weight: normal; } #xdrqkugqtb .gt_font_bold { font-weight: bold; } #xdrqkugqtb .gt_font_italic { font-style: italic; } #xdrqkugqtb .gt_super { font-size: 65%; } #xdrqkugqtb .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 201 carb 11.17 (0.73) carb_protein 11.30 (0.71) difference 0.14 (0.10) 1 Statistics presented: Mean (SD) You can report the following initially. There were 20 male and 20 female participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. The advertisement was more engaging to male viewers, 5.56 (0.29), than female viewers, 5.30 (0.39). Conditions The paired samples t test applies when the variable is continuous and a partitioned into dependent pairs, Additionally, there are two conditions related to the data distribution. If either condition fails, try the suggested work-around or use the non-parametric Wilcoxon Paired Sample Test instead. Outliers. There should be no outliers in differences because they exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Differences should be nearly normally distributed (nearly because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data. There are two common study designs that employ a paired samples t test to compare two related groups. One relates the groups as two time points for the same subjects. The second relates the groups as two tests of the same subjects, e.g. comparing reaction time under two lighting conditions. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. The boxplot shows no outliers, although two points are actually right on the 1.5*IQR cusp. Report inconsequential outliers as &gt; Two outliers were detected that were more than 1.5 box-lengths from the edge of the box in a boxplot. Inspection of their values did not reveal them to be extreme and they were kept in the analysis. or if there are no outliers, report as &gt;There were no outliers in the data, as assessed by inspection of a boxplot. If the outliers are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you have a couple options before reverting to Wilcoxon. Transform the variable. Dont do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult. Leave it in if it doesnt affect the conclusion (compared to taking it out). Normality Assume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still dont feel confident about normality, run a [Shapiro-Wilk Test]. The data set has n = 20 observations, so you cannot assume normality. The QQ plot indicates normality. drink %&gt;% ggplot(aes(sample = difference)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) The Shapiro-Wilk normality test fails to reject the null hypothesis of a normally distributed population. drink_report$shapiro &lt;- shapiro.test(drink$difference) drink_report$shapiro ## ## Shapiro-Wilk normality test ## ## data: drink$difference ## W = 0.97119, p-value = 0.7797 Report this as &gt; The differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were normally distributed, as assessed by Shapiro-Wilks test (p = 0.780). If the data is not normally distributed, you still have a couple options before reverting to Wilcoxon. Transform the dependent variable. Carry on regardless - the one-sample t-test is fairly robust to deviations from normality. 2.3 Mann-Whitney U Test for Numeric Vars This test applies when the variable distributions are non-normally. 2.4 Wilcoxon Paired-Sample Test for Numeric Vars This test applies when the variable distributions are non-normally distributed and samples are paired. 2.5 Pearsons Correlation for Numeric Vars 2.6 Spearmans Ranked Correlation for Numeric Vars 2.7 2 Sample Independent t Test for Categorical Vars This test applies when you know the population variance. 2.8 2 Sample Welchs t Test for Categorical Vars This test applies when the variable variances are unequal. 2.9 Paired Sample t Test for Categorical Vars This test applies when you have paired samples. 2.10 Mann-Whitney U Test for Categorical Vars This test applies when the variable distributions are non-normally. 2.11 Wilcoxon Paired-Sample Test for Categorical Vars This test applies when the variable distributions are non-normally distributed and samples are paired. 2.12 Pearsons Correlation for Categorical Vars 2.13 Spearmans Ranked Correlation for Categorical Vars 2.14 Fishers Exact Test Use Fishers Exact Test to test whether the observed frequencies of a single discrete dichotomous variable are equal. Suppose you have a treatment and control, and a binary outcome with two levels, sick and cured. The observed frequency counts, \\(O_j\\), of the \\(J\\) levels of a categorical variable differ from the expected frequency counts, \\(E_j\\). \\(H_0\\) is \\(O_j = E_j\\). The p-value from the test is computed as if the margins of the table are fixed. This leads under a null hypothesis of independence to a hypergeometric distribution of the numbers in the cells of the table The test is applicable in situations where the row totals \\(n_{i+}\\) and the column totals \\(n_+j\\) are fixed by study design (rarely applies), and the expected values of &gt;20% of cells (at least 1 cell in a 2x2 table) have expected cell counts &gt;5, and no expected cell count is &lt;1. In practice, it appears that researchers use Fishers exact test for 2x2 tables with small (n &lt; 1,000) sample sizes. It is more accurate than the chi-square and G tests. ([Wikipedial(https://en.wikipedia.org/wiki/Fisher%27s_exact_test)). Fishers exact test is useful for small n-size samples where the chi-squared distribution assumption of the chi-squared and G-test tests fails. Fishers exact test is overly conservative (p values too high) for large n-sizes. The t-test returns nearly the same result as the z-test when the CLT holds, so in practice no one bothers with the z-test except as an aid to teach the t-test. "],["multi-group-comparison-tests.html", "Chapter 3 Multi-Group Comparison Tests 3.1 Independent t-Test 3.2 Paired t-Test 3.3 Sign est 3.4 Wilcoxon Rank-Sum Test 3.5 Wilcoxon Signed-Rank Test 3.6 ANOVA 3.7 KruskalWallis Test 3.8 pairwise.prop.test", " Chapter 3 Multi-Group Comparison Tests Comparison tests look for differences among group means. They can be used to test the effect of a categorical variable on the mean value of some other characteristic. T-tests are used when comparing the means of precisely two groups (e.g. the average heights of men and women). ANOVA and MANOVA tests are used when comparing the means of more than two groups (e.g. the average heights of children, teenagers, and adults). Quantitative ~ Categorical 3.1 Independent t-Test 3.2 Paired t-Test 3.3 Sign est 3.4 Wilcoxon Rank-Sum Test 3.5 Wilcoxon Signed-Rank Test 3.6 ANOVA Most of these notes are gleaned from PSU STAT-502 Analysis of Variance and Design of Experiments covers ANOVA. Laerd Statistics is useful for writing up your results for reports. Classic analysis of variance (ANOVA) compares the mean responses from experimental studies. However, ANOVA also compares the mean responses from observational studies, but conclusions are just less rigorous. 3.6.1 One-Way ANOVA Use the one-way ANOVA test to compare the mean response of a continuous dependent variable among the levels of a factor variable. Here is a case study. Researchers compare the plant growth among three fertilizers and a control group. Data set greenhouse contains 6 observations per each of the k = 4 treatment levels (N = 24) - a balanced design. All three fertilizers produced more growth than the control group. Fertilizers F1 and F3 appear to be about tied for most growth, but it is unclear if the fertilizers are significantly different from each other. Treated Control(N=6) F1(N=6) F2(N=6) F3(N=6) All treated(N=18) Overall(N=24) Growth (cm) Mean (SD) 21.0 (1.00) 28.6 (2.44) 25.9 (1.90) 29.2 (1.29) 27.9 (2.35) 26.2 (3.69) Median [Min, Max] 21.0 [19.5, 22.5] 28.3 [25.0, 32.0] 26.3 [22.5, 28.0] 29.4 [27.5, 31.0] 28.0 [22.5, 32.0] 27.3 [19.5, 32.0] greenhouse_desc &lt;- greenhouse %&gt;% group_by(group) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), mean = mean(growth), sd = sd(growth)) Data is presented as mean \\(\\pm\\) standard deviation. Plant growth (growth) increased from the control (n = 6, 21 \\(\\pm\\) 1.0), to fertilizer 1 (n = 6, 28.6 \\(\\pm\\) 2.4), fertilizer 2 (n = 6, 25.8666667 \\(\\pm\\) 1.9), and fertilizer 3 (n = 6, 29.2 \\(\\pm\\) 1.3) fertilizer groups. ANOVA decomposes the deviation of observation \\(Y_{ij}\\) around the overall mean \\(\\bar{Y}_{..}\\) into two parts: the deviation of the observations around their treatment means, \\(SSE\\), and the deviation of the treatment means around the overall mean, \\(SSR\\). Their ratio, \\(F = SSR/SSE\\) follows an F-distribution with \\(k-1\\) numerator dof and \\(N-k\\) denominator dof. The more observation variance captured by the treatments, the large is \\(F\\), and the less likely that the null hypothesis, \\(H_0 = \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\) is true. Table 3.1: ANOVA Table Source SS df MS F SSR \\(\\sum{n_i(\\bar{Y}_{i.} - \\bar{Y}_{..})^2}\\) \\(k - 1\\) \\({SSR}/{(k - 1)}\\) \\({MSR}/{MSE}\\) SSE \\(\\sum(Y_{ij} - \\bar{Y}_{i.})^2\\) \\(N - k\\) \\({SSE}/{(N - k)}\\) SST \\(\\sum(Y_{ij} - \\bar{Y}_{..})^2\\) \\(N - 1\\) Run an ANOVA test in R like this: greenhouse_aov &lt;- aov(growth ~ group, data = greenhouse) greenhouse_anova &lt;- anova(greenhouse_aov) greenhouse_anova %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.8, layout = &quot;autofit&quot;) %&gt;% colformat_num(j = c(3, 4, 5), digits = 1) %&gt;% colformat_num(j = 6, digits = 4) %&gt;% set_caption(&quot;Results of ANOVA for Growth vs Fertilizer Group&quot;) .cl-feaefbcc{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-feaefbcd{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-feaefbce{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-feaf22d2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-feaf22d3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-feaf22d4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-feaf22d5{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-feaf22d6{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-feaf22d7{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.2: Results of ANOVA for Growth vs Fertilizer Group termdfsumsqmeansqstatisticp.valuegroup3251.483.827.50.0000Residuals2061.03.1 The one-way ANOVA indicates amount of growth was statistically significantly different for different levels of fertilizer group, F(3, 20) = 27.5, p &lt; .0001. BTW, it is worth noting the relationship with linear regression. The regression model intercept is the overall mean and the coefficient estimators indirectly indicate the group means. The analysis of variance table in a regression model shows how much of the overall variance is explained by those coefficient estimators. Its the same thing. You may also want to report the \\(\\omega^2\\) effect size, \\[\\omega^2 = \\frac{SSR - df_R \\cdot MSE}{MSE + SST}\\] greenhouse_omega &lt;- sjstats::anova_stats(greenhouse_anova) %&gt;% filter(term == &quot;group&quot;) %&gt;% pull(omegasq) ## Registered S3 methods overwritten by &#39;lme4&#39;: ## method from ## cooks.distance.influence.merMod car ## influence.merMod car ## dfbeta.influence.merMod car ## dfbetas.influence.merMod car \\(\\omega^2\\) ranges from -1 to +1. In this example, \\(\\omega^2\\) is 0.768. 3.6.1.1 ANOVA Conditions The ANOVA test applies when the dependent variable is continuous, the independent variable is categorical, and the observations are independent within groups. Independent means the observations should be from a random sample, or from an experiment using random assignment. Each groups size should be less than 10% of its population size. The groups must also be independent of each other (non-paired, and non-repeated measures). Additionally, there are three conditions related to the data distribution. If any condition does not hold, and the suggested work-arounds do not work switch to the non-parametric [Kruskal-Wallis Test]. No outliers. There should be no significant outliers in the groups. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Each groups values should be nearly normally distributed (nearly because ANOVA is considered robust to the normality assumption). This condition is especially important with small sample sizes. Test with the Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform your response variable. Equal Variances. The group variances should be roughly equal. This condition is especially important when sample sizes differ. Test with a box plot, rule of thumb, or one of the formal homogeneity of variance (external) tests such as Bartlett, and Levene. If the variances are very different, use a Games-Howell post hoc test instead of the Tukey post hoc test. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. Our example includes an outlier in fertilizer group F2. Outliers might occur from data entry errors or measurement errors, so investigate and fix or throw them out. However, if the outlier is a genuine extreme value, you still have a couple options before reverting to Kruskal-Wallis. Transform the dependent variable. Dont do this unless the data is also non-normal. It also has the downside of making interpretation more difficult. Leave it in if it doesnt affect the conclusion (compared to taking it out). Lets try removing the outlier (id# 13). greenhouse_aov2 &lt;- aov(growth ~ group, data = greenhouse %&gt;% filter(!id == 13)) greenhouse_anova2 &lt;- anova(greenhouse_aov2) .cl-ff2db7c8{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-ff2db7c9{font-family:'Arial';font-size:7px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-ff2db7ca{font-family:'Arial';font-size:6px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-ff2db7cb{font-family:'Arial';font-size:10px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ff2db7cc{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ff2db7cd{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ff2db7ce{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:0;padding-top:0;padding-left:0;padding-right:0;line-height: 1.00;background-color:transparent;}.cl-ff2e04da{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff2e04db{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff2e04dc{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff2e04dd{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff2e04de{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(255, 255, 255, 0.00);border-top: 1.00px solid rgba(255, 255, 255, 0.00);border-left: 1.00px solid rgba(255, 255, 255, 0.00);border-right: 1.00px solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff2e04df{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff2e04e0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.3: Results of ANOVA for Growth vs Fertilizer Group termdfsumsqmeansqstatisticp.valuegroup3251.083.733.50.0000Residuals1947.42.5Note: One outlier in group F2 removed. The conclusion is the same, so leaving it in is fine! Normality You can assume the populations are normally distributed if \\(n_j &gt;= 30\\). Otherwise, try the Q-Q plot, or skewness and kurtosis values, or histograms. If you still dont feel confident about normality, run a [Shapiro-Wilk Test] or Kolmogorov-Smirnov Test. If \\(n_j &gt;= 50\\), stick with graphical methods because at larger sample sizes Shapiro-Wilk flags even minor deviations from normality. The QQ plots below appear to be approximately normal. greenhouse %&gt;% ggplot(aes(sample = growth)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + facet_wrap(~group) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) The Shapiro-Wilk test corroborates this conclusion - it fails to reject the null hypothesis of normally distributed populations. x &lt;- by(greenhouse, greenhouse$group, function(x) shapiro.test(x$growth) %&gt;% tidy()) x[1:4] %&gt;% bind_rows() %&gt;% mutate(group = names(x)) %&gt;% dplyr::select(group, everything(), - method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Shapiro-Wilk Normality Test&quot;) .cl-ff75d5a8{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-ff75fc9a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ff75fc9b{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ff7623f0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff7623f1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff7623f2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff7623f3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff7623f4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff7623f5{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.4: Shapiro-Wilk Normality Test groupstatisticp.valueControl0.97648960.9328373F10.98032330.9531535F20.92569450.5472862F30.97059600.8964141 If the data is not normally distributed, you still have a couple options before reverting to Kruskal-Wallis. Transform the dependent variable. Transformations will generally only work when the distribution of scores in all groups are the same shape. They also have the drawback of making the data less interpretable. carry on regardless. One-way ANOVA is fairly robust to deviations from normality, particularly if the sample sizes are nearly equal. Equal Variances The equality of sample variances condition is less critical when sample sizes are similar among the groups. One rule of thumb is that no groups standard deviation should be more than double that of any other. In this case F1 is more than double Control. .cl-ff8bbc06{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-ff8be2da{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ff8be2db{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ff8c09cc{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff8c09cd{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff8c09ce{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff8c09cf{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff8c09d0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ff8c09d1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}groupsdControl1.000000F12.437212F21.899123F31.288410 There are two other common tests, Bartlett and Levene. NIST has a good write-up for Levene and for Bartlett. Levene is less sensitive than Bartlett to departures from normality, so if you know your data is normally distributed, then use Bartlett. Levenes test fails to reject the null hypothesis of equality of variance. greenhouse_levene &lt;- car::leveneTest(growth ~ group, data = greenhouse) greenhouse_levene %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Levene&#39;s Test for Homogeneity of Variance&quot;) .cl-ffa1d536{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-ffa1fb9c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ffa1fb9d{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ffa2496c{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ffa2496d{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ffa2496e{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ffa2496f{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ffa24970{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ffa24971{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.5: Levenes Test for Homogeneity of Variance termdfstatisticp.valuegroup31.0491160.392603820NANA So does Bartlett. bartlett.test(growth ~ group, data = greenhouse) %&gt;% tidy() %&gt;% dplyr::select(-method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Bartlett&#39;s Test for Homogeneity of Variance&quot;) .cl-ffb48988{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-ffb48989{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-ffb4afda{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ffb4afdb{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.6: Bartletts Test for Homogeneity of Variance statisticp.valueparameter4.1143420.2493793 Heterogeneity is a common problem in ANOVA. Transforming the response variable can often remove the heterogeneity. The Box-Cox procedure can help find a good transformation. The MASS::boxcox() function calculates a profile of log-likelihoods for a power transformation of the response variable \\(Y^\\lambda\\). \\(\\lambda\\) \\(Y^\\lambda\\) Transformation 2 \\(Y^2\\) Square 1 \\(Y^1\\) (no transformation) .5 \\(Y^{.5}\\) Square Root 0 \\(\\ln(Y)\\) Log -.5 \\(Y^{-.5}\\) Inverse Square Root -1 \\(Y^{-1}\\) Inverse The Box-Cox procedure does not recommend any particular transformation of the data in this case. MASS::boxcox(greenhouse_aov, plotit = TRUE) 3.6.1.2 Custom Contrasts Taking this route is appropriate if you have specific hypotheses about the differences between the groups of your independent variable. For example, we might want to test whether the mean of the treatments differ from the control group, \\(H_0: \\sum_i^K{c_i u_i} = 0\\) where \\(c_i = (1, -1/3, -1/3, -1/3)\\). You can test a constrast using the multcomp package. greenhouse_glht &lt;- glht(greenhouse_aov, linfct = mcp(group = c(-1, 1/3, 1/3, 1/3))) greenhouse_glht_smry &lt;- summary(greenhouse_glht) greenhouse_confint &lt;- confint(greenhouse_glht) greenhouse_glht_smry ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: User-defined Contrasts ## ## ## Fit: aov(formula = growth ~ group, data = greenhouse) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 1 == 0 6.8889 0.8235 8.365 5.81e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) Growth was statistically significantly higher in the fertilizer groups (mean of 27.9) compared to the sedentary group (21 \\(\\pm\\) 1), a mean difference of 6.8888889 (95% CI, 5.1711032 to 8.6066746), p = 5.806853710^{-8}. 3.6.1.3 Tukey Post Hoc Test The F test does not indicate which populations cause the rejection of \\(H_0\\). For this, use one of the post-hoc tests: Tukey, Fishers Least Significant Difference (LSD), Bonferroni, Scheffe, or Dunnett. Post hoc tests are appropriate if you are investigating all possible pairwise comparisons with no specific hypotheses about specific groups differing from others. Here is the Tukey test. As expected, all three fertilizer factor levels differ from the control. F3 differed from F2, but F1 was not significantly different from either F2 or F3. greenhouse_tukey &lt;- TukeyHSD(greenhouse_aov) greenhouse_tukey %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.8, layout = &quot;autofit&quot;) %&gt;% colformat_num(j = c(4:6), digits = 1) %&gt;% colformat_num(j = 7, digits = 3) %&gt;% set_caption(&quot;Tukey multiple comparisons of means&quot;) %&gt;% footnote(i = 1, j = c(1), value = as_paragraph( paste0(&quot;95% family-wise confidence level\\n&quot;, &quot;Fit: aov(formula = growth ~ group, data = greenhouse)&quot;)), ref_symbols = c(&quot;&quot;), part = &quot;header&quot;) .cl-fff22e28{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-fff22e29{font-family:'Arial';font-size:7px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-fff22e2a{font-family:'Arial';font-size:6px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-fff22e2b{font-family:'Arial';font-size:10px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-fff2551a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-fff2551b{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-fff2551c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:0;padding-top:0;padding-left:0;padding-right:0;line-height: 1.00;background-color:transparent;}.cl-fff27c0c{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fff27c0d{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fff27c0e{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fff27c0f{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fff27c10{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(255, 255, 255, 0.00);border-top: 1.00px solid rgba(255, 255, 255, 0.00);border-left: 1.00px solid rgba(255, 255, 255, 0.00);border-right: 1.00px solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fff27c11{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fff27c12{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.7: Tukey multiple comparisons of means termcontrastnull.valueestimateconf.lowconf.highadj.p.valuegroupF1-Control07.64.810.40.000groupF2-Control04.92.07.70.001groupF3-Control08.25.411.00.000groupF2-F10-2.7-5.60.10.060groupF3-F100.6-2.23.40.932groupF3-F203.30.56.20.01795% family-wise confidence levelFit: aov(formula = growth ~ group, data = greenhouse) Data are mean \\(\\pm\\) standard deviation. There was an increase in growth from 21 \\(\\pm\\) 1 in the control group to 28.6 \\(\\pm\\) 2.4 in the group with fertilizer F1, an increase of 7.6 (95% CI, 4.8 to 10.4), which was statistically significant (p &lt; .0001) etc. 3.6.1.4 Reporting a One-Way ANOVA Report like this. A one-way ANOVA was conducted to determine if plant growth was different for groups with different fertilizer types. Plants were classified into four groups: control (n = 6), fertilizer 1 (n = 6), fertilizer 2 (n = 6), and fertilizer 3 (n = 6). There was a single outlier, as assessed by boxplot, and was retained because it did not change the conclusions; data was normally distributed for each group, as assessed by Shapiro-Wilk test (p &gt; .05); and there was homogeneity of variances, as assessed by Levenes test of homogeneity of variances (p = 0.393). Data is presented as mean \\(\\pm\\) standard deviation. Plant growth was statistically significantly different between different fertilizer groups, F(3, 20) = 27.465, p &lt; .0005, \\(\\omega^2\\) = 0.768. Plant growth increased from the control (21 \\(\\pm\\) 1.0), to fertilizer F1 (28.6 \\(\\pm\\) 2.4), fertilizer F2 (25.9 \\(\\pm\\) 1.9), and fertilizer F3 (29.2 \\(\\pm\\) 1.3) fertilizer groups. Tukey post hoc analysis revealed statistically significant increases from control to F1 (7.6, 95% CI (4.8 to 10.4), p = 1.6e-06), control to F2 (4.9, 95% CI (2.0 to 7.7), p = 0.00055), and control to F3 (8.2, 95% CI (5.4 to 11.0), p = 5.1e-07), as well as the increase from F2 to F3 (3.3, 95% CI (0.51 to 6.2), p = 0.017), but there were no statistically significant group differences between F1 and F2 or F1 and F3. 3.6.2 Welchs ANOVA w/Games-Howell Welchs ANOVA test is an alternative to the one-way ANOVA test in cases where the equality of variances assumption is violated. Here is a case study. Researchers compare the force (in newtons) generated in three steps. Data set newton contains 30 observations per each of the k = 3 step levels (N = 90) - a balanced design. A(N=30) B(N=30) C(N=30) Overall(N=90) Force (newtons) Mean (SD) 429 (88.7) 527 (97.6) 649 (145) 535 (144) Median [Min, Max] 415 [306, 692] 499 [417, 759] 615 [437, 939] 498 [306, 939] newton_desc &lt;- newton %&gt;% group_by(step) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), mean = mean(newtons), sd = sd(newtons)) Data is presented as mean \\(\\pm\\) standard deviation. Force (newtons) increased from step 1 (n = 30, 429 \\(\\pm\\) 88.7), to step 2 (n = 30, 527 \\(\\pm\\) 97.6), to step 3 (n = 30, 649 \\(\\pm\\) 145). Start by running the standard ANOVA test: newton_aov &lt;- aov(newtons ~ step, data = newton) newton_anova &lt;- anova(newton_aov) newton_anova %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.8, layout = &quot;autofit&quot;) %&gt;% colformat_num(j = c(3, 4, 5), digits = 1) %&gt;% colformat_num(j = 6, digits = 4) %&gt;% set_caption(&quot;Results of ANOVA for Force vs Step&quot;) .cl-0038dbde{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-0038dbdf{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-0038dbe0{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-003929ae{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-003929af{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-003929b0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-003929b1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-003929b2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-003929b3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.8: Results of ANOVA for Force vs Step termdfsumsqmeansqstatisticp.valuestep2727,295.0363,647.528.40.0000Residuals871,113,208.112,795.5 The one-way ANOVA indicates amount of force was statistically significantly different for different levels of step, F(2, 87) = 28.4, p &lt; .0001. 3.6.2.1 ANOVA Conditions Check the three ANOVA conditions: no outliers, normality, and equal variances. Outliers Assess outliers with a box plot. Our example includes an outlier in step A. You can either transform the dependent variable, see if taking it out changes your conclusion, or use a non-parametric test. Lets try removing the outlier (id# 13). newton2 &lt;- newton %&gt;% mutate(id = row_number()) newton_aov2 &lt;- aov(newtons ~ step, data = newton2 %&gt;% filter(!id == 7)) newton_anova2 &lt;- anova(newton_aov2) .cl-0083c7ac{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-0083c7ad{font-family:'Arial';font-size:7px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-0083c7ae{font-family:'Arial';font-size:6px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-0083c7af{font-family:'Arial';font-size:10px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0083c7b0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-0083c7b1{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-0083c7b2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:0;padding-top:0;padding-left:0;padding-right:0;line-height: 1.00;background-color:transparent;}.cl-0083ee80{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0083ee81{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0083ee82{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0083ee83{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0083ee84{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(255, 255, 255, 0.00);border-top: 1.00px solid rgba(255, 255, 255, 0.00);border-left: 1.00px solid rgba(255, 255, 255, 0.00);border-right: 1.00px solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0083ee85{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0083ee86{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.9: Results of ANOVA for Force vs Step termdfsumsqmeansqstatisticp.valuestep2773,863.5386,931.731.90.0000Residuals861,041,642.712,112.1Note: One outlier in step A removed. The conclusion is the same, so leaving it in is fine! Normality You can assume the populations are normally distributed if \\(n_j &gt;= 30\\), but Ill examine the Q-Q plot and run a [Shapiro-Wilk Test] anyway. The QQ plots below appear to be approximately normal newton %&gt;% ggplot(aes(sample = newtons)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + facet_wrap(~step) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) but the Shapiro-Wilk test fails for step A and B  evidence of its sensitivity for large n. I will ignore this violation. x &lt;- by(newton, newton$step, function(x) shapiro.test(x$newtons) %&gt;% tidy()) x[1:3] %&gt;% bind_rows() %&gt;% mutate(group = names(x)) %&gt;% dplyr::select(group, everything(), - method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Shapiro-Wilk Normality Test&quot;) .cl-00c71a5c{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-00c741a8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-00c741a9{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-00c76566{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00c76567{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00c76568{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00c76569{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00c7656a{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00c7656b{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.10: Shapiro-Wilk Normality Test groupstatisticp.valueA0.92548620.03730756B0.90524050.01130931C0.94660730.13705759 Equal Variances The equality of sample variances condition is less critical when sample sizes are similar among the groups. Following the rule of thumb that no groups standard deviation be more than double that of any other, we look okay. .cl-00dae0d2{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-00db074c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-00db074d{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-00db2e3e{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00db2e3f{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00db2e40{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00db2e41{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00db2e42{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00db2e43{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}stepsdA88.66137B97.58970C144.92031 However, Levenes test rejects the null hypothesis of equality of variance. newton_levene &lt;- car::leveneTest(newtons ~ step, data = newton) newton_levene %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Levene&#39;s Test for Homogeneity of Variance&quot;) .cl-00f0ed96{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-00f11442{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-00f11443{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-00f13b5c{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00f13b5d{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00f13b5e{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00f13b5f{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00f13b60{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-00f13b61{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.11: Levenes Test for Homogeneity of Variance termdfstatisticp.valuegroup23.9707430.0223743487NANA So does Bartlett. bartlett.test(newtons ~ step, data = newton) %&gt;% tidy() %&gt;% dplyr::select(-method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Bartlett&#39;s Test for Homogeneity of Variance&quot;) .cl-01079d3e{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-01079d3f{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-0107c430{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0107c431{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.12: Bartletts Test for Homogeneity of Variance statisticp.valueparameter8.1969350.016598092 We could transform the response variable to remove the heterogeneity. The Box-Cox procedure suggests an inverse square root transformation. \\(\\lambda\\) \\(Y^\\lambda\\) Transformation 2 \\(Y^2\\) Square 1 \\(Y^1\\) (no transformation) .5 \\(Y^{.5}\\) Square Root 0 \\(\\ln(Y)\\) Log -.5 \\(Y^{-.5}\\) Inverse Square Root -1 \\(Y^{-1}\\) Inverse The Box-Cox procedure does not recommend any particular transformation of the data in this case. MASS::boxcox(newton_aov, plotit = TRUE) newton3 &lt;- newton %&gt;% mutate(newtons_isr = newtons^(-0.5)) newton_levene3 &lt;- car::leveneTest(newtons_isr ~ step, data = newton3) newton_levene3 %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Levene&#39;s Test for Homogeneity of Variance&quot;) .cl-013121b8{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-013121b9{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-013121ba{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-013148a0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-013148a1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-013148a2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-013148a3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-013148a4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-013148a5{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.13: Levenes Test for Homogeneity of Variance termdfstatisticp.valuegroup20.52340380.594354287NANA Huzzah - it worked! Before we continue on, we should backtrack and re-test the outliers and normality conditions. However, because the point of this section is to try Welchs ANOVA, Im going use it instead of transforming the response variable. Use oneway.test(..., var.equal = FALSE) to run a Welchs ANOVA. newton_anova &lt;- oneway.test(newtons ~ step, data = newton, var.equal = FALSE) newton_anova ## ## One-way analysis of means (not assuming equal variances) ## ## data: newtons and step ## F = 26.19, num df = 2.000, denom df = 56.184, p-value = 9.196e-09 Welchs ANOVA indicates amount of force was statistically significantly different for different steps, F(2, 56.2) = 26.2, p &lt; .0001. I dont think you can calculate \\(\\omega^2\\) for a Welchs ANOVA object. 3.6.2.2 Games-Howell Post Hoc Test Use the PMCMRplus::gamesHowellTest() to run the Games-Howell post hoc test. As expected, the three steps differ from each other. newton_games_howell &lt;- rstatix::games_howell_test(newton, newtons ~ step) newton_games_howell %&gt;% flextable() %&gt;% autofit() %&gt;% set_caption(&quot;Games-Howell Post Hoc Test&quot;) .cl-01613902{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-01613903{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-01613904{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-01615ff4{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ff5{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ff6{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ff7{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ff8{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ff9{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ffa{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ffb{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ffc{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ffd{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-01615ffe{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186dc{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186dd{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186de{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186df{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e0{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e1{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e2{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e3{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e4{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e5{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-016186e6{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0161adc4{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0161adc5{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.14: Games-Howell Post Hoc Test .y.group1group2estimateconf.lowconf.highp.adjp.adj.signifnewtonsAB97.6486739.73284155.56454.41e-04***newtonsAC219.74333144.72971294.75701.62e-08****newtonsBC122.0946745.08372199.10561.00e-03*** 3.6.2.3 Reporting a Welchs ANOVA A Welchs ANOVA was conducted to determine if force was different for different steps. Measurements were classified into three groups: A (n = 30), B (n = 30), and C (n = 30). There was a single outlier, as assessed by boxplot, and was retained because it did not change the conclusions; data was normally distributed for each group, as assessed by Q-Q plot. ; Homogeneity of variances was violated, as assessed by Levenes Test of Homogeneity of Variance (p = 0.022). Data is presented as mean \\(\\pm\\) standard deviation. Force was statistically significantly different between different steps, F(2, 56.1842568) = 26.19, p &lt; .0005. Force increased from A (429.1793333 \\(\\pm\\) 88.66137), to B (526.828 \\(\\pm\\) 97.6), to C (648.9226667 \\(\\pm\\) 144.9). Games-Howell post hoc analysis revealed statistically significant increases from A to B, (97.6, 95% CI (39.7 to 39.7), p = 4e-04), A to C (219.7, 95% CI (144.7 to 144.7), p = 2e-08), and B to C (122.1, 95% CI (45.1 to 45.1), p = 0.001). 3.6.3 MANOVA Multi-factor ANOVA (MANOVA) is a method to compare mean responses by treatment factor level of two or more treatments applied in combination. The null hypotheses are \\(H_0: \\mu_{1.} = \\mu_{2.} = \\dots = \\mu_{a.}\\) for the \\(a\\) levels of factor 1, \\(H_0: \\mu_{.1} = \\mu_{.2} = \\dots = \\mu_{.b}\\) for the \\(b\\) levels of factor 2, etc. for all the factors in the experiment, and $H_0: $ no interaction for all the factor interactions. There are two equivalent ways to state the MANOVA model: \\[Y_{ijk} = \\mu_{ij} + \\epsilon_{ijk}\\] In this notation \\(Y_{ijk}\\) refers to the \\(k^{th}\\) observation in the \\(j^{th}\\) level of factor two and the \\(i^{th}\\) level of factor 1. Potentially there could be additional factors. This model formulation decomposes the response into a cell mean and an error term. The second makes the factor effect more explicit and is thus more common: \\[Y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\epsilon_{ijk}\\] 3.6.4 Multiple Variance Comparison F Test 3.6.5 Example A study investigates the relationship between oxygen update and two explanatory variables: smoking, and type of stress test. A sample of \\(n = 27\\) persons, 9 non-smoking, 9 moderately-smoking, and 9 heavy-smoking are divided into three stress tests, bicycle, treadmill, and steps and their oxygen uptake was measured. Is oxygen uptake related to smoking status and type of stress test? Is there an interaction effect between smoking status and type of stress test? library(dplyr) library(ggplot2) library(nortest) # for Anderson-Darling test library(stats) # for anova smoker &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3) stress &lt;- c(1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3) oxytime &lt;- c(12.8, 13.5, 11.2, 16.2, 18.1, 17.8, 22.6, 19.3, 18.9, 10.9, 11.1, 9.8, 15.5, 13.8, 16.2, 20.1, 21.0, 15.9, 8.7, 9.2, 7.5, 14.7, 13.2, 8.1, 16.2, 16.1, 17.8) oxy &lt;- data.frame(oxytime, smoker, stress) oxy$smoker &lt;- ordered(oxy$smoker, levels = c(1, 2, 3), labels = c(&quot;non-smoker&quot;, &quot;moderate&quot;, &quot;heavy&quot;)) oxy$stress &lt;- factor(oxy$stress, labels = c(&quot;bicycle&quot;, &quot;treadmill&quot;, &quot;steps&quot;)) lm_oxy &lt;- lm(oxytime~smoker+stress+smoker*stress, data = oxy) anova(lm_oxy) ## Analysis of Variance Table ## ## Response: oxytime ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## smoker 2 84.899 42.449 12.8967 0.0003348 *** ## stress 2 298.072 149.036 45.2793 9.473e-08 *** ## smoker:stress 4 2.815 0.704 0.2138 0.9273412 ## Residuals 18 59.247 3.291 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 SFU BIO710 3.6.6 Repeated Measures 3.6.7 Two-Way 3.6.8 Randomized Blocks 3.6.9 ANCOVA 3.7 KruskalWallis Test 3.8 pairwise.prop.test library(tidyverse) M &lt;- 3573 F &lt;- 4177 dat &lt;- tribble( ~gender, ~src, ~Y, ~N, &quot;Male&quot;, &quot;Indeed&quot;, 1699, M-1699, &quot;Male&quot;, &quot;LinkedIn&quot;, 1755, M-1755, &quot;Male&quot;, &quot;Google&quot;, 1578, M-1578, &quot;Female&quot;, &quot;Indeed&quot;, 2554, F-2554, &quot;Female&quot;, &quot;LinkedIn&quot;, 1914, F-1914, &quot;Female&quot;, &quot;Google&quot;, 1694, F-1694 ) prop.test(x = dat$Y, n = dat$Y + dat$N) ## ## 6-sample test for equality of proportions without continuity ## correction ## ## data: dat$Y out of dat$Y + dat$N ## X-squared = 412.66, df = 5, p-value &lt; 2.2e-16 ## alternative hypothesis: two.sided ## sample estimates: ## prop 1 prop 2 prop 3 prop 4 prop 5 prop 6 ## 0.4755108 0.4911839 0.4416457 0.6114436 0.4582236 0.4055542 pairwise.prop.test(x = dat$Y, n = dat$Y + dat$N) ## ## Pairwise comparisons using Pairwise comparison of proportions ## ## data: dat$Y out of dat$Y + dat$N ## ## 1 2 3 4 5 ## 2 0.40250 - - - - ## 3 0.02026 0.00021 - - - ## 4 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - - ## 5 0.40250 0.02026 0.40250 &lt; 2e-16 - ## 6 6.3e-09 4.8e-13 0.00873 &lt; 2e-16 1.1e-05 ## ## P value adjustment method: holm "],["applications.html", "Chapter 4 Applications 4.1 Example one 4.2 Example two", " Chapter 4 Applications Some significant applications are demonstrated in this chapter. 4.1 Example one 4.2 Example two "],["final-words.html", "Chapter 5 Final Words 5.1 Pearson 5.2 Chi-Square 5.3 Spearman", " Chapter 5 Final Words We have finished a nice book. 5.1 Pearson 5.2 Chi-Square 5.3 Spearman "],["final-words-1.html", "Chapter 6 Final Words 6.1 Linear 6.2 Generalized Linear", " Chapter 6 Final Words We have finished a nice book. 6.1 Linear 6.2 Generalized Linear "],["Probablity.html", "Chapter 7 Probability 7.1 Bayesian Inference 7.2 Stochastic Processes", " Chapter 7 Probability 7.1 Bayesian Inference The Bayesian model for inference adds to the statistical model \\(\\{f_\\theta : \\theta \\in \\Omega\\}\\) a prior probability measure \\(\\Pi\\) for \\(\\theta\\). For example, suppose \\(\\theta\\) is the probability a flipping a coin to heads, with \\(\\Omega = [0,1]\\). The statisticians conservative believe \\(\\pi\\) may be a wide bell curve centered on \\(\\theta=0.5\\), or maybe the statistician is quite confident, so \\(\\pi\\) is a daring narrow bell curve around \\(\\theta=0.5\\). By the law of total probability, the probability of event \\(s\\) is a joint distribution, \\(\\pi(\\theta)f_\\theta(s)\\). The marginal distribution of \\(s\\) is \\(m(s) = \\int_\\Omega \\pi(\\theta)f_\\theta(s)d\\theta.\\) After \\(s\\) is observed the posterior distribution of \\(\\theta\\) is the conditional distribution of \\(\\theta\\) given \\(s\\) is \\[\\pi(\\theta|s) = \\frac{\\pi(\\theta)f_\\theta(s)}{m(s)}\\] Suppose you observe a sample from a Bernoulli distribution with an unknown success probability, \\(\\theta \\in [0,1].\\) You take a uniform prior, \\(\\pi= Beta(\\alpha, \\beta) = Beta(1,1).\\). Your sample of \\(n = 40\\) includes \\(n\\bar{x} = 10\\) successes. Then the posterior of \\(\\theta\\) is \\(Beta(11,31):\\) The likelihood \\(\\theta^{n\\bar{x}}\\left(1-\\theta\\right)^{n(1-\\bar{x})}\\) times the prior \\(B^{-1}(\\alpha, \\beta)\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\\) 7.2 Stochastic Processes Stochastic processes are proceed randomly over time. The simplest version is the random walk. A random walk is a sequence \\(\\{X_n\\}\\) of random variables, with \\(X_0\\) = 1 and \\(P\\left(X_{n+1} = X_n + 1 \\right) = p\\) where \\(p\\) is the probability of success and its complement is \\(q= 1-p\\). It follows that, given an initial value \\(a\\), \\(P\\left(X_n = a + k\\right) = \\binom{n}{\\frac{n+k}{2}} p^{(n+k)/2}q^{(n-k)/2}\\) for \\(k = -n, -n+2, -n+4, \\dots,n\\), and \\(E\\left(X_n\\right) = a + n(2p-1)\\). 7.2.1 Markov Chains A Markov chain is the random motion of an object. Given a state space \\(S\\) of all places an object can go, and a set of transition probabilities \\(\\{p_{ij}: i,j \\in S\\}\\) to move from state \\(i\\) to \\(j\\), and a probability \\(u_i = P\\left(X_0 = i\\right)\\) that the object starts at state \\(i\\), then \\(P\\left(X_{n+1} = j|X_n =i\\right)=p_{ij}\\) ?? "],["references.html", "References", " References "]]
