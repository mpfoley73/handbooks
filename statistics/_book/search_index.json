[["one-group-inference-tests.html", "Chapter 2 One-Group Inference Tests 2.1 One-Group Inference with Numeric Variable 2.2 One-Group Inference with Categorical Variable", " Chapter 2 One-Group Inference Tests One-group refers to a single population whose metric you are trying to measure. In the case of a quantitative metric, you are typically measuring its mean value. In the case of a count variable, you are typically measuring its proportion. 2.1 One-Group Inference with Numeric Variable The tests in this section use the sample mean, \\(\\bar{x}\\), as an estimate of the population mean, \\(\\mu\\). The tests apply when the data is independent. Using the normal or student-t distribution, you can create a confidence interval around the estimate, or evaluate an hypothesized population mean, \\(\\mu_0\\). Which test you use depends on what you know about the population distribution (normal vs non-normal) and its variance (known or unknown): Normal Distribution Non-Normal Known Variance z-test Wilcoxon Median Unknown Variance t-test Wilcoxon Median 2.1.1 1 Sample z Test for Numeric Var The z test is also called the normal approximation z test. It only applies when the sampling distribution of the population mean is normally distributed with known variance, and there are no significant outliers. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. The t test returns similar results, plus it is valid when the variance is unknown, and that is pretty much always. For that reason, you probably will never use this test. Under the normal approximation method, the measured mean \\(\\bar{x}\\) approximates the population mean \\(\\mu\\), and the sampling distribution has a normal distribution centered at \\(\\mu\\) with standard error \\(se_\\mu = \\frac{\\sigma}{\\sqrt{n}}\\) where \\(\\sigma\\) is the standard deviation of the underlying population. Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm z_{(1 - \\alpha) {/} 2} se_\\mu\\), or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}\\). Example The mtcars data set is a sample of n = 32 cars. The mean fuel economy is \\(\\bar{x} \\pm s\\) = 20.1 \\(\\pm\\) 6.0 mpg. The prior measured overall fuel economy for vehicles was \\(\\mu_0 \\pm \\sigma\\) = 18.0 \\(\\pm\\) 6.0 mpg. Has fuel economy improved? The sample size is \\(\\ge\\) 30, so the sampling distribution of the population mean is normally distributed. The population variance is known, so use the z test. \\(H_0: \\mu = 16.0\\), and \\(H_a: \\mu &gt; 16.0\\) - a right-tail test. The test statistic is \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}=\\) 1.97 where \\(se_{\\mu_0} = \\frac{\\mu_0}{\\sqrt{n}} =\\) 1.06. \\(P(z &gt; Z) =\\) 0.0244, so reject \\(H_0\\) at the \\(\\alpha =\\) 0.05 level of significance. The 95% confidence interval for \\(\\mu\\) is \\(\\bar{x} \\pm z_{(1 - \\alpha){/}2} se_\\mu\\) where \\(z_{(1 - \\alpha){/}2} =\\) 1.96. \\(\\mu =\\) 20.09 \\(\\pm\\) 2.08 (95% CI 18.01 to 22.17). 2.1.2 1 sample t Test for Numeric Var The one-sample t test applies when the sampling distribution of the population mean is normally distributed and there are no significant outliers. Unlike the z test, the population variance can be unknown. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. Under the t test method, the measured mean \\(\\bar{x}\\) approximates the population mean \\(\\mu\\). The sample standard deviation, \\(s\\), estimates the (always) unknown \\(\\sigma\\). The resulting sampling distribution has a t-distribution centered at \\(\\mu\\) with standard error \\(se_\\bar{x} = \\frac{s}{\\sqrt{n}}\\). Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} se_\\bar{x}\\), or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(T = \\frac{\\bar{x} - \\mu_0}{se_\\bar{x}}\\). Here is a case study. A researcher recruits a random sample of 40 participants to take part in the study about depression intervention. The researcher measures the participants depression levels prior to the study and compares it to the normal level - 4.0. The null hypothesis is that the sample is representative of the overall population. Mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population normal depression score of (4.00. dep %&gt;% gtsummary::tbl_summary(statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #kipwjfidaa .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kipwjfidaa .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kipwjfidaa .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kipwjfidaa .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #kipwjfidaa .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kipwjfidaa .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kipwjfidaa .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kipwjfidaa .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kipwjfidaa .gt_column_spanner_outer:first-child { padding-left: 0; } #kipwjfidaa .gt_column_spanner_outer:last-child { padding-right: 0; } #kipwjfidaa .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #kipwjfidaa .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #kipwjfidaa .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kipwjfidaa .gt_from_md > :first-child { margin-top: 0; } #kipwjfidaa .gt_from_md > :last-child { margin-bottom: 0; } #kipwjfidaa .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kipwjfidaa .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #kipwjfidaa .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kipwjfidaa .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #kipwjfidaa .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kipwjfidaa .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kipwjfidaa .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kipwjfidaa .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kipwjfidaa .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kipwjfidaa .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #kipwjfidaa .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kipwjfidaa .gt_sourcenote { font-size: 90%; padding: 4px; } #kipwjfidaa .gt_left { text-align: left; } #kipwjfidaa .gt_center { text-align: center; } #kipwjfidaa .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kipwjfidaa .gt_font_normal { font-weight: normal; } #kipwjfidaa .gt_font_bold { font-weight: bold; } #kipwjfidaa .gt_font_italic { font-style: italic; } #kipwjfidaa .gt_super { font-size: 65%; } #kipwjfidaa .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 401 dep_score 3.72 (0.74) 1 Statistics presented: Mean (SD) Conditions The one-sample t test applies when the dependent variable is continuous and the observations are independent. Additionally, there are two conditions related to the data distribution. If any condition does not hold, and the suggested work-arounds do not work switch to the non-parametric Wilcoxon 1-Sample Median Test for Numeric Var. No outliers. There should be no significant outliers in the groups. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Each groups values should be nearly normally distributed (nearly because ANOVA is considered robust to the normality assumption). This condition is especially important with small sample sizes. Test with the Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform your response variable. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. Our example includes an outlier in fertilizer group F2. There were no outliers in the data, as assessed by inspection of a boxplot. Outliers might occur from data entry errors or measurement errors, so investigate and fix or throw them out. However, if the outlier is a genuine extreme value, you still have a couple options before reverting to Wilcoxon. Transform the dependent variable. Dont do this unless the data is also non-normal. It also has the downside of making interpretation more difficult. Leave it in if it doesnt affect the conclusion (compared to taking it out). Normality You can assume the populations are normally distributed if \\(n_j &gt;= 30\\). Otherwise, try the Q-Q plot, or skewness and kurtosis values, or histograms. If you still dont feel confident about normality, run a [Shapiro-Wilk Test] or Kolmogorov-Smirnov Test. If \\(n_j &gt;= 50\\), stick with graphical methods because at larger sample sizes Shapiro-Wilk flags even minor deviations from normality. The QQ plot below appears to be approximately normal. dep %&gt;% ggplot(aes(sample = dep_score)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) The Shapiro-Wilk test corroborates this conclusion - it fails to reject the null hypothesis of normally distributed populations. shapiro.test(dep$dep_score) %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Shapiro-Wilk Normality Test&quot;) .cl-121f2878{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-121f4cc2{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-121f4cc3{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-121f73a0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-121f73a1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-121f73a2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-121f73a3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2.1: Shapiro-Wilk Normality Test statisticp.valuemethod0.98445810.8473922Shapiro-Wilk normality test Depression scores were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05). If the data is not normally distributed, you still have a couple options before reverting to Wilcoxon. Transform the dependent variable. Carry on regardless. One-sample t tests are fairly robust to deviations from normality. Results Conduct the t-test. The p-value is less than .05, so reject \\(H_0\\). To get the 95% CI around the difference, run the test using the difference, \\(\\mu_0 - \\bar{x}\\). (dep_95ci &lt;- t.test(x = mu_0 - dep$dep_score, alternative = &quot;two.sided&quot;, conf.level = .95)) ## ## One Sample t-test ## ## data: mu_0 - dep$dep_score ## t = 2.3811, df = 39, p-value = 0.02224 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.04176615 0.51323385 ## sample estimates: ## mean of x ## 0.2775 Depression score was statistically significantly lower by 0.28 (95% CI, 0.04 to 0.51) than a normal depression score of 4.0, t(39) = 2.381, p = 0.022. # lrr = mu_0 + qt(p = alpha, df = n - 1, lower.tail = TRUE) * se # urr = mu_0 + qt(p = alpha, df = n - 1, lower.tail = FALSE) * se # data.frame(mu = 1000:1250 / 10) %&gt;% # mutate(t = (mu - mu_0) / se) %&gt;% # mutate(prob = dt(x = t, df = n - 1)) %&gt;% # mutate(rr = ifelse(mu &lt; lrr | mu &gt; urr, prob, 0)) %&gt;% # ggplot() + # geom_line(aes(x = mu, y = prob)) + # geom_area(aes(x = mu, y = rr), fill = &quot;red&quot;, alpha = 0.3) + # geom_vline(aes(xintercept = mu_0), color = &quot;black&quot;) + # geom_vline(aes(xintercept = x_bar), color = &quot;blue&quot;) + # labs(title =&quot;Two-Tail Hypothesis Test&quot;, # subtitle = bquote(&quot;mu_0=&quot; ~ .(mu_0) ~ # &quot;, x_bar =&quot; ~ .(round(x_bar, 1)) ~ # &quot;, p-value =&quot; ~ .(round(t.test.result$p.value, 4))), # x = &quot;mu&quot;, # y = &quot;Probability&quot;) + # theme(legend.position=&quot;none&quot;, # axis.text.y = element_blank(), # axis.ticks.y = element_blank()) 2.1.2.1 Calculating Sample Size Determine the sample size required for a maximum error \\(\\epsilon\\) in the estimate by solving the confidence interval equation for \\(n=\\frac{{t_{\\alpha/2,n-1}^2se^2}}{{\\epsilon^2}}\\) . Unfortunately, \\(t_{\\alpha/2,n-1}^2\\) is dependent on \\(n\\), so replace it with \\(z_{\\alpha/2}^2\\). What about \\(s^2\\)? Estimate it from the literature, a pilot study, or using the empirical rule of \\(95%\\) of range falling within two standard deviations, \\(s=\\frac{{range}}{{4}}\\). 2.1.2.1.1 Example If the maximum tolerable error is \\(\\epsilon=3\\), and the sample variance is \\(s^2 = 10^2\\), what sample size provides an \\(\\alpha=0.05\\) conidence level? alpha = 0.05 s = 10 epsilon = 3 z_crit = qnorm(p = 1 - alpha / 2, mean = 0, sd = 1, lower.tail = TRUE) (n = ceiling(z_crit^2 * s^2 / epsilon^2)) ## [1] 43 \\(n\\) varies with confidence level and maximum error. library(tidyr) # for spread alpha &lt;- c(.10, .10, .10, .05, .05, .05, .01, .01, .01) epsilon &lt;- c(1, 3, 5, 1, 3, 5, 1, 3, 5) dataframe &lt;- data.frame(alpha, epsilon) dataframe &lt;- dataframe %&gt;% mutate(z_crit = qnorm(p = 1 - alpha / 2, mean = 0, sd = 1, lower.tail = TRUE), n = ceiling(z_crit^2 * s^2 / epsilon^2)) dataframe$z_crit &lt;- NULL spread(dataframe, key = epsilon, n) %&gt;% knitr::kable() alpha 1 3 5 0.01 664 74 27 0.05 385 43 16 0.10 271 31 11 2.1.3 Wilcoxon 1-Sample Median Test for Numeric Var This test applies when the variable is not normally distributed. 2.2 One-Group Inference with Categorical Variable 2.2.1 1 Sample z Test for Categorical Var This test applies when you know the population variance. 2.2.2 1 sample t Test for Categorical Var This test applies when you do not know the population variance. 2.2.3 Wilcoxon 1-Sample Median Test for Categorical Var This test applies when the variable is not normally distributed. "]]
