[["index.html", "Statistics Handbook Statistics handbook for a data analyst Introduction", " Statistics Handbook Statistics handbook for a data analyst Michael Foley 2021-04-11 Introduction These notes mostly self-education from books, online classes, tutorials, vignettes, etc. They probably have a lot of mistakes, are poorly organized, and shaky on fundamentals. I hope over time this document grows and improves in quality along with my own mastery of data analysis, but thats all I can say for it. If you found this from an internet search, use at your own risk! The focus of this handbook is statistical inference, including population estimates, group comparisons, and regression modeling. Not included in this handbook is foundational knowledge of probability and statistics, machine learning, text mining, survey analysis, or survival analysis. All these subjects frequently arise at work, but seem distinct and large enough to warrant separate handbooks. "],["one-sample.html", "Chapter 1 One-Sample 1.1 One-Sample Mean z Test 1.2 One-Sample Mean t Test 1.3 One-Sample Median Wilcoxon Test 1.4 Chi-Squared Goodness-of-Fit Test 1.5 G-Test 1.6 One-Sample Poisson Test 1.7 One-Sample Binomial Test 1.8 One-Sample Proportion z Test 1.9 1 sample t Test for Categorical Var 1.10 Wilcoxon 1-Sample Median Test for Categorical Var", " Chapter 1 One-Sample Use one-sample tests to either describe a single variables frequency or central tendency, or to compare the frequency or central tendency to a hypothesized distribution or value. If the data generating process produces continuous outcomes (interval or ratio), and the outcomes are symmetrically distributed, the sample mean, \\(\\bar{x}\\), is a random variable centered at the population mean, \\(\\mu\\). You can then use a theoretical distribution (normal or student t) to estimate a 95% confidence interval (CI) around \\(\\mu\\), or compare \\(\\bar{x}\\) to an hypothesized population mean, \\(\\mu_0\\). If you (somehow) know the population variance, or the Central Limit Theorem (CLT) conditions hold, you can assume the random variable is normally distributed and use the z-test, otherwise assume the random variable has student t distribution and use the t-test.1 If the data generating process produces continuous outcomes that are not symmetrically distributed, use a non-parametric test like the Wilcoxon median test. If the data generating process produces discrete outcomes (counts), the sample count, \\(x\\), is a random variable from a Poisson, binomial, normal, or multinomial distribution, or a random variable from a theoretical outcome. For counts over a fixed time or space, treat the count as a random variable from a Poisson distribution with expected value \\(\\lambda\\) and variance \\(\\lambda\\). For counts within a fixed total that are then classified into two levels (usually yes/no), then treat the count as a random variable from a binomial distribution with expected value \\(n\\pi\\) and variance \\(n\\pi(1-\\pi)\\). For binomial distributions where \\(n\\ge30\\) and the frequency counts of both levels is \\(\\ge\\) 5, treat the proportion as a random variable from the normal distribution with expected valued \\(\\pi\\) and variance \\(\\frac{\\pi(1-\\pi)}{n}\\). For counts within a fixed total that are then classified into three or more levels, treat the count as a random variable from the multinomial distribution with expected value \\(n\\pi_j\\) and variance \\(n\\pi_j(1-\\pi_j)\\). Whatever the source of the expected values, you use either the chi-squared goodness-of-fit test or G test to test whether the observed values fit the expected values from the distribution. In the special case of binary outcomes with small (n &lt; 1,000), you can use Fishers exact test instead. The discrete variable tests are discussed in PSU STATS 504. 1.1 One-Sample Mean z Test The z test is also called the normal approximation z test. It only applies when the sampling distribution of the population mean is normally distributed with known variance, and there are no significant outliers. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. The t test returns similar results, plus it is valid when the variance is unknown, and that is pretty much always. For that reason, you probably will never use this test. Under the normal approximation method, the measured mean \\(\\bar{x}\\) approximates the population mean \\(\\mu\\), and the sampling distribution has a normal distribution centered at \\(\\mu\\) with standard error \\(se_\\mu = \\frac{\\sigma}{\\sqrt{n}}\\) where \\(\\sigma\\) is the standard deviation of the underlying population. Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm z_{(1 - \\alpha) {/} 2} se_\\mu\\), or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}\\). Example The mtcars data set is a sample of n = 32 cars. The mean fuel economy is \\(\\bar{x} \\pm s\\) = 20.1 \\(\\pm\\) 6.0 mpg. The prior measured overall fuel economy for vehicles was \\(\\mu_0 \\pm \\sigma\\) = 18.0 \\(\\pm\\) 6.0 mpg. Has fuel economy improved? The sample size is \\(\\ge\\) 30, so the sampling distribution of the population mean is normally distributed. The population variance is known, so use the z test. \\(H_0: \\mu = 16.0\\), and \\(H_a: \\mu &gt; 16.0\\) - a right-tail test. The test statistic is \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}=\\) 1.97 where \\(se_{\\mu_0} = \\frac{\\mu_0}{\\sqrt{n}} =\\) 1.06. \\(P(z &gt; Z) =\\) 0.0244, so reject \\(H_0\\) at the \\(\\alpha =\\) 0.05 level of significance. The 95% confidence interval for \\(\\mu\\) is \\(\\bar{x} \\pm z_{(1 - \\alpha){/}2} se_\\mu\\) where \\(z_{(1 - \\alpha){/}2} =\\) 1.96. \\(\\mu =\\) 20.09 \\(\\pm\\) 2.08 (95% CI 18.01 to 22.17). 1.2 One-Sample Mean t Test The one-sample t test applies when the sampling distribution of the population mean is normally distributed and there are no significant outliers. Unlike the z test, the population variance can be unknown. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. Under the t test method, the measured mean, \\(\\bar{x}\\), approximates the population mean, \\(\\mu\\). The sample standard deviation, \\(s\\), estimates the unknown population standard deviation, \\(\\sigma\\). The resulting sampling distribution has a t distribution centered at \\(\\mu\\) with standard error \\(se_\\bar{x} = \\frac{s}{\\sqrt{n}}\\). Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} se_\\bar{x}\\) and/or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(T = \\frac{\\bar{x} - \\mu_0}{se_\\bar{x}}\\). Example A researcher recruits a random sample of n = 40 people to participate in a study about depression intervention. The researcher measures the participants depression level prior to the study. The mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population normal depression score of 4.0. The null hypothesis is that the sample is representative of the overall population. Should you reject \\(H_0\\)? dep %&gt;% gtsummary::tbl_summary(statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #trrkounsnu .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #trrkounsnu .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #trrkounsnu .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #trrkounsnu .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #trrkounsnu .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #trrkounsnu .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #trrkounsnu .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #trrkounsnu .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #trrkounsnu .gt_column_spanner_outer:first-child { padding-left: 0; } #trrkounsnu .gt_column_spanner_outer:last-child { padding-right: 0; } #trrkounsnu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #trrkounsnu .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #trrkounsnu .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #trrkounsnu .gt_from_md > :first-child { margin-top: 0; } #trrkounsnu .gt_from_md > :last-child { margin-bottom: 0; } #trrkounsnu .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #trrkounsnu .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #trrkounsnu .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #trrkounsnu .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #trrkounsnu .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #trrkounsnu .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #trrkounsnu .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #trrkounsnu .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #trrkounsnu .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #trrkounsnu .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #trrkounsnu .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #trrkounsnu .gt_sourcenote { font-size: 90%; padding: 4px; } #trrkounsnu .gt_left { text-align: left; } #trrkounsnu .gt_center { text-align: center; } #trrkounsnu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #trrkounsnu .gt_font_normal { font-weight: normal; } #trrkounsnu .gt_font_bold { font-weight: bold; } #trrkounsnu .gt_font_italic { font-style: italic; } #trrkounsnu .gt_super { font-size: 65%; } #trrkounsnu .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 401 dep_score 3.72 (0.74) 1 Statistics presented: Mean (SD) Conditions The one-sample t test applies when the variable is continuous and the observations are independent. Additionally, there are two conditions related to the data distribution. If either condition fails, try the suggested work-arounds or use the non-parametric [Wilcoxon 1-Sample Median Test for Numeric Var] instead. Outliers. There should be no significant outliers. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Values should be nearly normally distributed (nearly because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. The boxplot shows no outliers. If the outliers might are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you have a couple options before reverting to Wilcoxon. Transform the variable. Dont do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult. Leave it in if it doesnt affect the conclusion (compared to taking it out). Normality Assume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still dont feel confident about normality, run a [Shapiro-Wilk Test]. The data set has n = 40 observations, so you can assume normality. Here is a QQ plot anyway. The QQ plot indicates normality. dep %&gt;% ggplot(aes(sample = dep_score)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) Here is the Shapiro-Wilk normality test. It fails to reject the null hypothesis of a normally distributed population. shapiro.test(dep$dep_score) ## ## Shapiro-Wilk normality test ## ## data: dep$dep_score ## W = 0.98446, p-value = 0.8474 If the data is not normally distributed, you still have a couple options before reverting to Wilcoxon. Transform the dependent variable. Carry on regardless - the one-sample t-test is fairly robust to deviations from normality. Results Conduct the t-test. To get a 95% CI around the difference (instead of around the estimate), run the test using the difference, \\(\\mu_0 - \\bar{x}\\), and leave mu at its default of 0. (dep_95ci &lt;- t.test(x = mu_0 - dep$dep_score, alternative = &quot;two.sided&quot;, conf.level = .95)) ## ## One Sample t-test ## ## data: mu_0 - dep$dep_score ## t = 2.3811, df = 39, p-value = 0.02224 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.04176615 0.51323385 ## sample estimates: ## mean of x ## 0.2775 The difference is statistically different from 0 at the p = .05 level. The effect size, called Cohens d, is defined as \\(d = |M_D| / s\\), where \\(|M_D| = \\bar{x} - \\mu_0\\), and \\(s\\) is the sample standard deviation. \\(d &lt;.2\\) is considered trivial, \\(.2 \\le d &lt; .5\\) small, and \\(.5 \\le d &lt; .8\\) large. (d &lt;- rstatix::cohens_d(dep, dep_score ~ 1, mu = 4) %&gt;% pull(effsize) %&gt;% abs()) ## Cohen&#39;s d ## 0.3764788 Cohens d is 0.38, a small effect. Make a habit of constructing a plot, just to make sure your head is on straight. Now you are ready to report the results. A one-sample t-test was run to determine whether depression score in recruited subjects was different from normal, as defined as a depression score of 4.0. Depression scores were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05) and there were no outliers in the data, as assessed by inspection of a boxplot. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population normal depression score of 4.00, a statistically significant difference of 0.28 (95% CI, 0.04 to 0.51), t(39) = 2.38, p = 0.022, d = 0.38. Appendix: Deciding Sample Size Determine the sample size required for a maximum error \\(\\epsilon\\) in the estimate by solving the confidence interval equation, \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} \\frac{s}{\\sqrt{n}}\\) for \\(n=\\frac{{t_{\\alpha/2,n-1}^2se^2}}{{\\epsilon^2}}\\) . Unfortunately, \\(t_{\\alpha/2,n-1}^2\\) is dependent on \\(n\\), so replace it with \\(z_{\\alpha/2}^2\\). What about \\(s^2\\)? Estimate it from the literature, a pilot study, or using the empirical rule that 95% of the range falls within two standard deviations, \\(s=range / 4\\). For example, if the maximum tolerable error is* \\(\\epsilon\\) = 3, and \\(s\\) is approximately 10, what sample size produces an \\(\\alpha\\) =0.05 confidence level? ceiling(qnorm(.975)^2 * 10^2 / 3^2) ## [1] 43 1.3 One-Sample Median Wilcoxon Test The Wilcoxon one-sample median test (aka Wilcoxon signed rank test) is a non-parametric alternative to the t-test for cases when the the sampling distribution of the population mean is not normally distributed, but is at least symmetric. Under the Wilcoxon test, the measured median, \\(\\eta_x\\), approximates the population median, \\(\\eta\\). The method calculates the difference between each value and the hypothesized median, \\(\\eta_0\\), ranks the difference magnitudes, then sums the ranks for the negative and the positive differences, \\(W+\\) and \\(W-\\). The test compares the smaller of the two sums to a table of critical values. Here is a case study. A store claims their checkout wait times are \\(\\le\\) 4 minutes. You challenge the claim by sampling 6 checkout experiences. The mean wait time was 4.6, but the data may violate normality. data.frame(wait = wait) %&gt;% ggplot(aes(sample = wait)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) Shapiro-Wilk rejects the null hypothesis of a normally distributed population. shapiro.test(wait) ## ## Shapiro-Wilk normality test ## ## data: wait ## W = 0.75105, p-value = 0.0204 Use the Wilcoxon test instead. (wt &lt;- wilcox.test(wait, mu = 4, alternative = &quot;greater&quot;)) ## Warning in wilcox.test.default(wait, mu = 4, alternative = &quot;greater&quot;): cannot ## compute exact p-value with ties ## ## Wilcoxon signed rank test with continuity correction ## ## data: wait ## V = 14.5, p-value = 0.2309 ## alternative hypothesis: true location is greater than 4 A Wilcoxon Signed-Ranks Test indicated that wait times were not statistically significantly higher than the 4-minute claim, z = 14.5, p = 0.231. 1.4 Chi-Squared Goodness-of-Fit Test Use the chi-squared goodness-of-fit test to test whether the observed frequency counts, \\(O_j\\), of the \\(J\\) levels of a categorical variable differ from the expected frequency counts, \\(E_j\\). \\(H_0\\) is \\(O_j = E_j\\). You can use this test for dichotomous, nominal, or ordinal variables. There are only two conditions to use this test: the observations are independent, meaning either random assignment or random sampling without replacement from &lt;10% of the population, and the expected frequency in each group is &gt;=5. The Pearson goodness-of-fit test statistic is \\[X^2 = \\sum \\frac{(O_j - E_j)^2}{E_j}\\] where \\(O_j = p_j n\\) and \\(E_j = \\pi_j n\\). The sampling distribution of \\(X^2\\) approaches the \\(\\chi_{J-1}^2\\) as the sample size \\(n \\rightarrow \\infty\\). The assumption that \\(X^2\\) is distributed \\(\\sim \\chi^2\\) is not quite correct, so you will see researchers subtract .5 from the differences to increase the p-value, the so-called Yates Continuity Correction. \\[X^2 = \\sum \\frac{(O_j - E_j - 0.5)^2}{E_j}\\] \\(X^2 \\rightarrow 0\\) as the saturated model (the observed data represent the fit of the saturated model, the most complex model possible with the data) proportions approach the expected proportions, \\(p_j \\rightarrow \\pi_j\\). The chi-squared test calculates the probability of the occurrence of \\(X^2\\) at least as extreme given that it is a chi-squared random variable with degrees of freedom equal to the number of levels of the variable minus one, \\(J-1\\). Example with Theoretical Values A researcher crosses tall cut-leaf tomatoes with dwarf potato-leaf tomatoes, then classifies the n = 1,611 offsprings phenotype. The four phenotypes should occur with relative frequencies 9:3:3:1. The observed frequencies constitute a one-way table. If you only care about one level (or if the variable is binary) of if, conduct a one-proportion Z-test or an exact binomial test. Otherwise, conduct an exact multinomial test (recommended when n &lt;= 1,000), Pearsons chi-squared goodness-of-fit test, or a G-test. Conditions This is a randomized experiment. The minimum expected frequency was 100, so the chi-squared test of independence is valid. Had the data violated the \\(\\ge\\) 5 condition, you could run an exact test (like the binomial, or in this case, the multinomial), or lump some factor levels together. Results You can calculate \\(X^2\\) by hand, and find the probability of a test statistic at least as extreme using the \\(\\chi^2\\) distribution with 4-1 = 3 degrees of freedom. (pheno_x2 &lt;- sum((pheno_obs - pheno_exp)^2 / pheno_exp)) ## [1] 9.54652 (pheno_p &lt;- pchisq(q = pheno_x2, df = length(pheno_type) - 1, lower.tail = FALSE)) ## [1] 0.02284158 That is what chisq.test() does. The function applies the Yates continuity correction by default, so I had to specify correct = FALSE to exclude it. In this case, setting it to TRUE has almost no effect because the sample size is large. (pheno_chisq_test &lt;- chisq.test(pheno_obs, p = pheno_pi, correct = FALSE)) ## ## Chi-squared test for given probabilities ## ## data: pheno_obs ## X-squared = 9.5465, df = 3, p-value = 0.02284 As always, plot the distribution. At this point you can report, Of the 1,611 offspring produced from the cross-fertiliation, 956 were tall cut-leaf, 258 were tall potato-leaf, 293 where dwarf cut-leaf, and 104 were dwarf potato-leaf. A chi-square goodness-of-fit test was conducted to determine whether the offspring had the same proportion of phenotypes as the theoretical distribution. The minimum expected frequency was 101. The chi-square goodness-of-fit test indicated that the number of tall cut-leaf, tall potato-leaf, dwarf cut-leaf, and dwarf potato-leaf offspring was statistically significantly different from the proportions expected in the theoretical distribution (\\(X^2\\)(3) = 9.547, p = 0.023). If you reject \\(H_0\\), inspect the residuals to learn which differences contribute most to the rejection. Notice how \\(X^2\\) is a sum of squared standardized cell differences, or Pearson residuals, \\[r_i = \\frac{o_j - e_j}{\\sqrt{e_j}}\\] Cells with the largest \\(|r|\\) contribute the most to the total \\(X^2\\). pheno_chisq_test$residuals^2 / pheno_chisq_test$statistic ## tall cut-leaf tall potato-leaf dwarf cut-leaf dwarf potato-leaf ## 0.28682269 0.67328098 0.02848093 0.01141540 The two tall cells contributed over 95% of the \\(X^2\\) test statistic, with the tall potato-leaf accounting for 67%. This aligns with what youd expect from the bar plot. Example with Theoretical Distribution You need to reduce the degrees of freedom (df) in the chi-squared goodness-of-fit test by 1 if you test whether the data conform to a particular distribution instead of a set of theoretical values. j &lt;- c(0:5) o &lt;- c(19, 26, 29, 13, 10, 3) childr_n &lt;- as.character(0:5) Suppose you sample n = 100 families and count the number of children. The count of children is a Poisson random variable, \\(J\\), with maximum likelihood estimate \\(\\hat{\\lambda} = \\sum{j_i O_i} / \\sum{O_i}\\). Test whether the observed values can be described as samples from a Poisson random variable. The probabilities for each possible count are \\[f(j; \\lambda) = \\frac{e^{-\\hat{\\lambda}} \\hat{\\lambda}^j}{j!}.\\] Conditions This is random sampling. The minimum expected frequency was 2, so the data violates the \\(\\ge\\) 5 rule. Lump the last two categories into 4-5. The minimum expected frequency was 6, so now the chi-squared test of independence is valid. Results Compare the expected values to the observed values with the chi-squared goodness of fit test, but in this case \\(df = 5 - 1 - 1\\) because the estimated parameter \\(\\lambda\\) reduces df by 1. You cannot set df in chisq.test(), so perform the test manually. (X2 &lt;- sum((o - e)^2 / e)) ## [1] 7.092968 (p.value &lt;- pchisq(q = X2, df = length(j) - 1 - 1, lower.tail = FALSE)) ## [1] 0.06899286 At this point you can report, Of the 100 families sampled, 19 had no children, 26 had one child, 29 had two children, 13 had three children, and 13 had 4 or 5 children. A chi-square goodness-of-fit test was conducted to determine whether the observed family sizes follow a Poisson distribution. The minimum expected frequency was 13. The chi-square goodness-of-fit test indicated that the number of children was not statistically significantly different from the proportions expected in the Poisson distribution (\\(X^2\\)(3) = 7.093, p = 0.069). 1.5 G-Test The G-test is a likelihood-ratio statistical significance test increasingly used instead of chi-squared tests. The test statistic is defined \\[G^2 = 2 \\sum O_j \\log \\left[ \\frac{O_j}{E_j} \\right]\\] where the 2 multiplier asymptotically aligns with the chi-squared test formula. G is distributed \\(\\sim \\chi^2\\), with the same number of degrees of freedom as in the corresponding chi-squared test. In fact, the chi-squared test statistic is a second order Taylor expansion of the natural logarithm around 1. Returning to the phenotype case study in the chi-squared goodness-of-fit test section, you can calculate the \\(G^2\\) test statistic and probability by hand. (pheno_g2 &lt;- 2 * sum(pheno_obs * log(pheno_obs / pheno_exp))) ## [1] 9.836806 (pchisq(q = pheno_g2, df = length(pheno_type) - 1, lower.tail = FALSE)) ## [1] 0.02000552 This is pretty close to the \\(X^2\\) = 9.547, p = 0.023 using the chi-squared goodness-of-fit test. The DescTools::GTest() function to conducts a G-test. DescTools::GTest(pheno_obs, p = pheno_pi) ## ## Log likelihood ratio (G-test) goodness of fit test ## ## data: pheno_obs ## G = 9.8368, X-squared df = 3, p-value = 0.02001 According to the function documentation, the G-test is not usually used for 2x2 tables. EMT::multinomial.test(o, f, useChisq = TRUE) ## ## Exact Multinomial Test, distance measure: chisquare ## ## Events chi2Obs p.value ## 4598126 7.093 0.1479 chisq.test(o, e) ## Warning in chisq.test(o, e): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: o and e ## X-squared = 15, df = 12, p-value = 0.2414 1.6 One-Sample Poisson Test If \\(X\\) is the number of successes in \\(n\\) (many) trials when the probability of success \\(\\lambda / n\\) is small, then \\(X\\) is a random variable with a Poisson distribution, and the probability of observing \\(X = x\\) successes is \\[f(x;\\lambda) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\hspace{1cm} x \\in (0, 1, ...), \\hspace{2mm} \\lambda &gt; 0\\] with \\(E(X)=\\lambda\\) and \\(Var(X) = \\lambda\\) where \\(\\lambda\\) is estimated by the sample \\(\\hat{\\lambda}\\), \\[\\hat{\\lambda} = \\sum_{i=1}^N x_i / n.\\] Poisson sampling is used to model counts of events that occur randomly over a fixed period of time. You can use the Poisson distribution to perform an exact test on a Poisson random variable. Example You are analyzing goal totals from a sample consisting of the 95 matches in the first round of the 2002 World Cup. The average match produced a mean/sd of 1.38 \\(\\pm\\) 1.28 goals, lower than the 1.5 historical average. Should you reject the null hypothesis that the sample is representative of typical values? Conditions The events must be independent of each other. In this case, the goal-count in one match has no effect on goal-counts in other matches. The expected value of each event must be the same (homogeneity). In this case, the expected goal-count of each match is the same regardless of which teams are playing. This assumption is often dubious, causing the distribution variance to be larger than the mean, a conditional called over-dispersion. You might also check whether the data is consistent with a Poisson model. This is random sampling, but the data violates the \\(\\ge\\) 5 rule because the minimum expected frequency was 0. To comply with the minimum frequency rule, lump the last six categories into 3-8. The minimum expected frequency was 15, so now the chi-squared test of independence is valid. Compare the expected values to the observed values with the chi-squared goodness of fit test, but in this case \\(df = 4 - 1 - 1\\) because the estimated parameter \\(\\lambda\\) reduces the df by 1. You cannot set df in chisq.test(), so perform the test manually. (X2 &lt;- sum((o - e)^2 / e)) ## [1] 0.8618219 (p.value &lt;- pchisq(q = X2, df = length(j) - 1 - 1, lower.tail = FALSE)) ## [1] 0.6499168 Of the 95 World Cup matches, 23 had no goals, 37 had one goal, 20 had two goals, and 15 had 3-8 goals. A chi-square goodness-of-fit test was conducted to determine whether the observed goal counts follow a Poisson distribution. The minimum expected frequency was 15. The chi-square goodness-of-fit test indicated that the number of goals scored was not statistically significantly different from the frequencies expected from a Poisson distribution (\\(X^2\\)(2) = 0.862, p = 0.650). Results The conditions for the exact Poisson test were met, so go ahead and run the test. (pois_val &lt;- poisson.test( x = sum(dat_pois$goals * dat_pois$freq), T = sum(dat_pois$freq), r = 1.5) ) ## ## Exact Poisson test ## ## data: sum(dat_pois$goals * dat_pois$freq) time base: sum(dat_pois$freq) ## number of events = 131, time base = 95, p-value = 0.3567 ## alternative hypothesis: true event rate is not equal to 1.5 ## 95 percent confidence interval: ## 1.152935 1.636315 ## sample estimates: ## event rate ## 1.378947 Construct a plot showing the 95% CI around the hypothesized value. For a Poisson distribution, I built the distribution around the expected value, \\(n\\lambda\\), not the rate, \\(\\lambda\\). I think you could report these results like this. A one-sample exact Poisson test was run to determine whether the number of goals scored in the first round of the 2002 World Cup was different from past World Cups, 1.5. A chi-square goodness-of-fit test indicated that the number of goals was not statistically significantly different from the counts expected in the Poisson distribution (\\(X^2\\)(2) = 0.862, p = 0.650). Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Mean goals scored (1.38 \\(\\pm\\) 1.28) was lower than the historical mean of 1.50, but was not statistically significantly different (95% CI, 1.15 to 1.64), p = 0.357. 1.7 One-Sample Binomial Test The Clopper-Pearson exact binomial test is precise, but theoretically complicated in that it inverts two single-tailed binomial tests. No theoretical knowledge here - I just rely on the software. Use the exact binomial test when small sample sizes and/or extreme success probabilities invalidate the chi-square and G tests. The exact binomial test has two conditions: independence, and at least \\(n\\pi \\ge 5\\) successes or \\(n(1\\pi)\\ge 5\\) failures. You can use this test for multinomial variables too, but the test only compares a single levels proportion to a hypothesized value. Example A pharmaceutical company claims its drug reduces fever in &gt;60% of cases. In a random sample of n = 40 cases the drug reduces fever in 20 cases. Do you reject the claim? Conditions You are testing \\(P(x \\le 20)\\) in n = 40 trials when p = 60%, a one-tail test. The sample is a random assignment experiment with 20 successes and 20 failures, so it meets the conditions for the exact binomial test. Results pbinom(q = 20, size = 40, p = 0.6, lower.tail = TRUE) ## [1] 0.1297657 binom.test(20, 40, p = 0.6, alternative = &quot;less&quot;) ## ## Exact binomial test ## ## data: 20 and 40 ## number of successes = 20, number of trials = 40, p-value = 0.1298 ## alternative hypothesis: true probability of success is less than 0.6 ## 95 percent confidence interval: ## 0.0000000 0.6389083 ## sample estimates: ## probability of success ## 0.5 The exact binomial test uses the method of small p-values, in which the probability of observing a proportion \\(p\\) as far or further from \\(\\pi_0\\) is the sum of all \\(P(X=p_i)\\) where \\(p_i &lt;= p\\). map_dbl(dbinom(0:20, 40, 0.6), ~if_else(. &lt;= 0.5, ., 0)) %&gt;% sum() ## [1] 0.1297657 You could have used the chi-squared goodness-of-fit test, however, it is not performing a one-tail test. chisq.test(x = c(20, 20), p = c(0.6, 0.4), correct = FALSE) ## ## Chi-squared test for given probabilities ## ## data: c(20, 20) ## X-squared = 1.6667, df = 1, p-value = 0.1967 You should study the construction of the confidence interval on Wikipedia and explain it here. 1.8 One-Sample Proportion z Test The z-test uses the sample proportion of group \\(j\\), \\(p_j\\), as an estimate of the population proportion \\(\\pi_j\\) to evaluate an hypothesized population proportion \\(\\pi_{0j}\\) and/or construct a \\((1\\alpha)\\%\\) confidence interval around \\(p_j\\) to estimate \\(\\pi_j\\) within a margin of error \\(\\epsilon\\). The z-test is intuitive to learn, but it only applies when the central limit theorem conditions hold: the sample is independently drawn, meaning random assignment (experiments), or random sampling without replacement from &lt;10% of the population (observational studies), there are at least 5 successes and 5 failures, the sample size is &gt;=30, and the expected probability of success is not extreme, between 0.2 and 0.8. If these conditions hold, the sampling distribution of \\(\\pi\\) is normally distributed around \\(p\\) with standard error \\(se_p = \\frac{s_p}{\\sqrt{n}} = \\frac{\\sqrt{p(1p)}}{\\sqrt{n}}\\). The measured values \\(p\\) and \\(s_p\\) approximate the population values \\(\\pi\\) and \\(\\sigma_\\pi\\). You can define a \\((1  \\alpha)\\%\\) confidence interval as \\(p \\pm z_{\\alpha / 2}se_p\\). Test the hypothesis of \\(\\pi = \\pi_0\\) with test statistic \\(z = \\frac{p  \\pi_0}{se_{\\pi_0}}\\) where \\(se_{\\pi_0} = \\frac{s_{\\pi_0}}{\\sqrt{n}} = \\frac{\\sqrt{{\\pi_0}(1{\\pi_0})}}{\\sqrt{n}}\\). Example A machine is supposed to randomly churn out prizes in 60% of boxes. In a random sample of n = 40 boxes there are prizes in 20 boxes. Is the machine flawed? prop.test(20, 40, 0.6, &quot;two.sided&quot;, correct = FALSE) ## ## 1-sample proportions test without continuity correction ## ## data: 20 out of 40, null probability 0.6 ## X-squared = 1.6667, df = 1, p-value = 0.1967 ## alternative hypothesis: true p is not equal to 0.6 ## 95 percent confidence interval: ## 0.3519953 0.6480047 ## sample estimates: ## p ## 0.5 The first thing youll notice is that prop.test() performs a chi-squared goodness-of-fit test, not a one-proportion Z-test! chisq.test(c(20, 40-20), p = c(.6, .4), correct = FALSE) ## ## Chi-squared test for given probabilities ## ## data: c(20, 40 - 20) ## X-squared = 1.6667, df = 1, p-value = 0.1967 It turns out \\(P(\\chi^2 &gt; X^2)\\) equals \\(2 \\cdot P(Z &gt; z).\\) Here is the manual calculation of the chi-squared test statistic \\(X^2\\) and resulting p-value on 1 dof. pi_0 &lt;- .6 p &lt;- 20 / 40 observed &lt;- c(p, 1-p) * 40 expected &lt;- c(pi_0, 1-pi_0) * 40 X2 &lt;- sum((observed - expected)^2 / expected) pchisq(X2, 1, lower.tail = FALSE) ## [1] 0.1967056 And here is the manual calculation of the Z-test statistic \\(z\\) and resulting p-value. se &lt;- sqrt(pi_0*(1-pi_0)) / sqrt(40) z &lt;- (p - pi_0) / se pnorm(z, lower.tail = TRUE) * 2 ## [1] 0.1967056 The 95% CI presented by prop.test() is also not the \\(p \\pm z_{\\alpha / 2}se_p\\) Wald interval; it is the Wilson interval! DescTools::BinomCI(20, 40, method = &quot;wilson&quot;) ## est lwr.ci upr.ci ## [1,] 0.5 0.3519953 0.6480047 There are a lot of methods (see ?DescTools::BinomCI), and Wilson is the one Agresti-Coull recommends. If you want Wald, use DescTools::BinomCI() with method = \"wald\". DescTools::BinomCI(20, 40, method = &quot;wald&quot;) ## est lwr.ci upr.ci ## [1,] 0.5 0.3450512 0.6549488 This matches the manual calculation below. z_crit = qnorm(1 - .05/2) se &lt;- sqrt(p*(1-p)) / sqrt(40) (CI &lt;- c(p - z_crit*se, p + z_crit*se)) ## [1] 0.3450512 0.6549488 prop.test() (and chissq.test()) reported a p-value of 0.1967056, so you cannot reject the null hypothesis that \\(\\pi = 0.6\\). Its good practice to plot this out to make sure your head is on straight. Incidentally, if you have a margin of error requirement, you can back into the required sample size to achieve it. Just solve the margin of error equation \\(\\epsilon = z_{\\alpha/2}^2 = \\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}\\) for \\(n = \\frac{z_{\\alpha/2}^2 \\pi_0(1-\\pi_0)}{\\epsilon^2}.\\) 1.9 1 sample t Test for Categorical Var This test applies when you do not know the population variance. 1.10 Wilcoxon 1-Sample Median Test for Categorical Var This test applies when the variable is not normally distributed. The t-test returns nearly the same result as the z-test when the CLT holds, so in practice no one bothers with the z-test except as an aid to teach the t-test. "],["two-group-differences.html", "Chapter 2 Two-Group Differences 2.1 Independent Samples (Continuous) 2.2 Paired Samples (Continuous) 2.3 Independent Samples (Discrete) 2.4 Paired Samples (Discrete)", " Chapter 2 Two-Group Differences Use independent samples tests to either describe a variables frequency or central tendency difference between two independent groups, or to compare the difference to a hypothesized value. If the data generating process produces continuous outcomes (interval or ratio) and the outcomes are symmetrically distributed, the difference in the sample means, \\(\\hat{d} = \\bar{x} - \\bar{y}\\), is a random variable centered at the population difference, \\(d = \\mu_X - \\mu_Y\\). You can use a theoretical distribution (normal or student t) to estimate a 95% confidence interval (CI) around \\(d\\), or compare \\(\\hat{d}\\) to an hypothesized population difference, \\(d_0\\). If you (somehow) know the sampling distribution variances \\(\\sigma^2_X\\) and \\(\\sigma^2_Y\\), or the Central Limit Theorem (CLT) conditions hold, you can assume the random variable is normally distributed and use the z-test, otherwise assume the random variable has a student t distribution and use the t-test.2 If the data generating process produces continuous outcomes that are not symmetrically distributed, use a non-parametric test like the Mann-Whitney U test. If the data generating process produces discrete outcomes (counts), the sample count, \\(x\\), is a random variable from a Poisson, binomial, normal, or multinomial distribution, or a random variable from a theoretical outcome. For two independent samples, the data can be organized into a two-way table - a frequency table for two categorical variables. If you have a single categorical predictor variable, you can test whether the joint frequency counts differ from the expected frequency counts in the saturated model. You analyze a two-way table one of two ways. If you only care about comparing two levels (like when the response variable is binary), conduct a proportion difference z-test or a Fisher exact-test. If you want to compare the joint frequency counts to expected frequency counts under the independence model (the model of independent explanatory variables), conduct a Pearsons chi-squared independence test, or a G-test. 2.1 Independent Samples (Continuous) Independent Samples t-Test If a population measure X is normally distributed with mean \\(\\mu_X\\) and variance \\(\\sigma_X^2\\), and population measure Y is normally distributed with mean \\(\\mu_Y\\) and variance \\(\\sigma_Y^2\\), then their difference is normally distributed with mean \\(d = \\mu_X - \\mu_Y\\) and variance \\(\\sigma_{XY}^2 = \\sigma_X^2 + \\sigma_Y^2\\). By the CLT, as the sample sizes grow, non-normally distributed X and Y will approach normality, and so will their difference. The independent samples t-test uses the difference in sample means \\(\\hat{d} = \\bar{x} - \\bar{y}\\) as an estimate of \\(d\\) to evaluate an hypothesized difference, \\(d_0\\). The null hypothesis is \\(d = d_0\\). Alternatively, you can construct a \\((1 - \\alpha)\\%\\) confidence interval around \\(\\hat{d}\\) to estimate \\(d\\) within a margin of error, \\(\\epsilon\\). In principal, you can test the difference between independent means with either a z test or a t-test. Both require independent samples and approximately normal sampling distributions. The sampling distributions are normal if the underlying populations are normally distributed, or if the sample sizes are large (\\(n_X\\) and \\(n_Y\\) \\(\\ge\\) 30). However, the z-test additionally requires known sampling distribution variances \\(\\sigma^2_X\\) and \\(\\sigma^2_Y\\). These variances are never known, so always use the t-test. The z-test assumes \\(d\\) has a normal distribution centered at \\(\\hat{d} = d\\) with standard error \\(se = \\sqrt{\\frac{\\sigma_X^2}{n_X} + \\frac{\\sigma_Y^2}{n_Y}}.\\) Test \\(H_0: d = d_0\\) with test statistic \\(Z = \\frac{\\hat{d} - d_0}{se}\\) or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(d = \\hat{d} \\pm z_{(1 - \\alpha {/} 2)} se\\). The t-test assumes \\(d\\) has a t distribution centered at \\(\\hat{d} = d\\) with standard error \\(se = \\sqrt{\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}}.\\) Test \\(H_0: d = d_0\\) with test statistic \\(T = \\frac{\\hat{d} - d_0}{se}\\), or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(d = \\hat{d} \\pm t_{(1 - \\alpha / 2), (n_X + n_Y - 2)} se\\). However, there is an issue with the t test degrees of freedom. If the sample sizes are small, and the standard deviations from each population are similar (the ratios of \\(s_X\\) and \\(s_Y\\) are &lt;2), you can pool the variances \\(s_p^2 = \\frac{(n_X - 1) s_X^2 + (n_Y-1) s_Y^2}{n_X + n_Y-2}\\) so that \\(se = s_p \\sqrt{\\frac{1}{n_X} + \\frac{1}{n_Y}}\\) and \\(df = n_X + n_Y -2\\). This is call the pooled variances t-test. Otherwise, \\(se = \\sqrt{\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}}\\), but you must reduce the degrees of freedom using the Welch-Satterthwaite correction, \\(df = \\frac{\\left(\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}\\right)^2}{\\frac{s_X^4}{n_X^2\\left(N_X-1\\right)} + \\frac{s_Y^4}{n_Y^2\\left(N_Y-1\\right)}}.\\) This is called the separate variance t-test, or Welchs t-test. Mann-Whitney U Test The Mann-Whitney U test is a nonparametric alternative to the independent-samples t-test for cases in which the samples are non-normally distributed or are ordinal rather than continuous. If the two distributions have a different shape, the Mann-Whitney U test determines whether there are differences in the distributions. It does this by ranking all the values and comparing the mean ranks between the two groups. From this you can decide whether the dependent variable differs (lt, gt, or ne) between the groups. If the two distributions are the same shape, the Mann-Whitney U test determine whether there are differences in the medians. This is a more specific description of the difference. The test statistic is the minimum of \\(U_1\\) and \\(U_2\\) where \\(U_1 = n_1 n_2 \\frac{(n_1 (n_1 + 1))}{2} - R_1\\) and \\(U_2 = n_1 n_2 \\frac{(n_2 (n_2 + 1))}{2} - R_2\\) and \\(R_1\\) and \\(R_2\\) are the respective rank sums. \\(U = 0\\) if there is complete separation between the groups, and \\(U = n_1 n_2\\) if there is complete overlap, so you reject \\(H_0\\) of equal populations for small values of \\(U\\). Case Study A company shows an advertisement to \\(n_M\\) = 20 males and \\(n_F\\) = 20 females, then measures their engagement with a survey. Do the mean engagement scores differ between the groups? Laerd has two data sets for this example. One meets the conditions for a t-test, and the other fails the normality test, forcing us to use Mann-Whitney. The t-test data set has the following summary statistics. (ind_num$t_gt &lt;- ind_num$t_dat %&gt;% gtsummary::tbl_summary(by = c(gender), statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;))) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xdzrdzcgfh .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xdzrdzcgfh .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xdzrdzcgfh .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xdzrdzcgfh .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #xdzrdzcgfh .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xdzrdzcgfh .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xdzrdzcgfh .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xdzrdzcgfh .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xdzrdzcgfh .gt_column_spanner_outer:first-child { padding-left: 0; } #xdzrdzcgfh .gt_column_spanner_outer:last-child { padding-right: 0; } #xdzrdzcgfh .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #xdzrdzcgfh .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xdzrdzcgfh .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xdzrdzcgfh .gt_from_md > :first-child { margin-top: 0; } #xdzrdzcgfh .gt_from_md > :last-child { margin-bottom: 0; } #xdzrdzcgfh .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xdzrdzcgfh .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xdzrdzcgfh .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xdzrdzcgfh .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xdzrdzcgfh .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xdzrdzcgfh .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xdzrdzcgfh .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xdzrdzcgfh .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xdzrdzcgfh .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xdzrdzcgfh .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xdzrdzcgfh .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xdzrdzcgfh .gt_sourcenote { font-size: 90%; padding: 4px; } #xdzrdzcgfh .gt_left { text-align: left; } #xdzrdzcgfh .gt_center { text-align: center; } #xdzrdzcgfh .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xdzrdzcgfh .gt_font_normal { font-weight: normal; } #xdzrdzcgfh .gt_font_bold { font-weight: bold; } #xdzrdzcgfh .gt_font_italic { font-style: italic; } #xdzrdzcgfh .gt_super { font-size: 65%; } #xdzrdzcgfh .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Male, N = 201 Female, N = 201 engagement 5.56 (0.29) 5.30 (0.39) 1 Statistics presented: Mean (SD) There were 20 male and 20 female participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. The advertisement was more engaging to male viewers, 5.56 (0.29), than female viewers, 5.30 (0.39). The Mann-Whitney data set has the following summary statistics. (ind_num$mw_gt &lt;- ind_num$mw_dat %&gt;% gtsummary::tbl_summary(by = c(gender), statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;))) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #okobomebmm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #okobomebmm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #okobomebmm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #okobomebmm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #okobomebmm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #okobomebmm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #okobomebmm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #okobomebmm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #okobomebmm .gt_column_spanner_outer:first-child { padding-left: 0; } #okobomebmm .gt_column_spanner_outer:last-child { padding-right: 0; } #okobomebmm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #okobomebmm .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #okobomebmm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #okobomebmm .gt_from_md > :first-child { margin-top: 0; } #okobomebmm .gt_from_md > :last-child { margin-bottom: 0; } #okobomebmm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #okobomebmm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #okobomebmm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #okobomebmm .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #okobomebmm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #okobomebmm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #okobomebmm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #okobomebmm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #okobomebmm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #okobomebmm .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #okobomebmm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #okobomebmm .gt_sourcenote { font-size: 90%; padding: 4px; } #okobomebmm .gt_left { text-align: left; } #okobomebmm .gt_center { text-align: center; } #okobomebmm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #okobomebmm .gt_font_normal { font-weight: normal; } #okobomebmm .gt_font_bold { font-weight: bold; } #okobomebmm .gt_font_italic { font-style: italic; } #okobomebmm .gt_super { font-size: 65%; } #okobomebmm .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Male, N = 201 Female, N = 201 engagement 5.56 (0.35) 5.43 (0.53) 1 Statistics presented: Mean (SD) There were 20 male and 20 female participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. The advertisement was more engaging to male viewers, 5.56 (0.35), than female viewers, 5.43 (0.53). Conditions The independent samples t test and Mann-Whitney U test apply when 1) the response variable is continuous, 2) the independent variable is binomial, and 3) the observations are independent. The decision between the t test and Mann-Whitney stems from two additional conditions related to the data distribution - if both conditions hold, use the t test; otherwise use Mann-Whitney. Outliers. There should be no outliers in either group. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Values should be nearly normally distributed. The t-test is robust to normality, but this condition is important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data. If the data passes the two conditions, use the t test, but now you need to check a third condition related to the variances to determine which flavor of the t test to use. Homogeneous Variances. Use pooled-variances if the variances are homogeneous; otherwise use the separate variances method. Test with Levenes test of equality of variances. If the data does not pass the two conditions, use Mann-Whitney, but now you need to check a third condition here as well. The condition does not affect how to perform the test, but rather how to interpret the results. Distribution shape. If the distributions have the same shape, interpret the Mann-Whitney result as a comparison of the medians; otherwise interpret the result as a comparison of the mean ranks. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. For the t test data set, There were no outliers in the data, as assessed by inspection of a boxplot. and for the Mann-Whitney data set, There was one outlier in the data, as assessed by inspection of a boxplot. If the outliers are data entry errors or measurement errors, fix or discard them. If the outliers are genuine, you have a couple options before reverting to the Mann-Whitney U test. Leave it in if it doesnt affect the conclusion (compared to taking it out). Transform the variable. Dont do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult. Normality Assume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, assess a Q-Q plot, skewness and kurtosis values, or a histogram. If you still dont feel confident about normality, run a Shapiro-Wilk test. There are only \\(n_M\\) = 20 male and \\(n_F\\) = 20 female observations, so you need to test normality. The QQ plot indicates normality in the t-test data set, but not in the Mann-Whitney data set. bind_rows( `t-test` = ind_num$t_dat, `Mann-Whitney` = ind_num$mw_dat, .id = &quot;set&quot; ) %&gt;% ggplot(aes(sample = engagement, group = gender, color = fct_rev(gender))) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + theme_minimal() + theme(legend.position = &quot;top&quot;) + facet_wrap(~fct_rev(set)) + labs(title = &quot;Normal Q-Q Plot&quot;, color = NULL) Run Shapiro-Wilk separately for the males and for the females. Since we are looking at two data sets in tandem, there are four tests below. For the t-test data set, (ind_num$t_shapiro &lt;- split(ind_num$t_dat, ind_num$t_dat$gender) %&gt;% map(~shapiro.test(.$engagement)) ) ## $Male ## ## Shapiro-Wilk normality test ## ## data: .$engagement ## W = 0.98344, p-value = 0.9705 ## ## ## $Female ## ## Shapiro-Wilk normality test ## ## data: .$engagement ## W = 0.96078, p-value = 0.5595 Engagement scores for each level of gender were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05). For the Mann-Whitney data set, (ind_num$mw_shapiro &lt;- split(ind_num$mw_dat, ind_num$mw_dat$gender) %&gt;% map(~shapiro.test(.$engagement)) ) ## $Male ## ## Shapiro-Wilk normality test ## ## data: .$engagement ## W = 0.98807, p-value = 0.9946 ## ## ## $Female ## ## Shapiro-Wilk normality test ## ## data: .$engagement ## W = 0.8354, p-value = 0.003064 Engagement scores for each level of gender were not normally distributed for the Female sample, as assessed by Shapiro-Wilks test (p = 0.003). If the data is not normally distributed, you still have a couple options before reverting to the Mann-Whitney U test. Transform the dependent variable. Carry on regardless - the independent samples t-test is fairly robust to deviations from normality. Homogenous Variances If the data passed the outliers and normality tests, you will use the t-test, so now you need to test the variances to see which version (pooled-variances method if variances are homogeneous; separate variances method otherwise). A rule of thumb is that homogeneous variances have a ratio of standard deviations between 0.5 and 2.0: sd(ind_num$t_dat %&gt;% filter(gender == &quot;Male&quot;) %&gt;% pull(engagement)) / sd(ind_num$t_dat %&gt;% filter(gender == &quot;Female&quot;) %&gt;% pull(engagement)) ## [1] 0.7419967 You can also use the F test to compare the ratio of the sample variances \\(\\hat{r} = s_X^2 / s_Y^2\\) to an hypothesized ratio of population variances \\(r_0 = \\sigma_X^2 / \\sigma_Y^2 = 1.\\) var.test(ind_num$t_dat %&gt;% filter(gender == &quot;Female&quot;) %&gt;% pull(engagement), ind_num$t_dat %&gt;% filter(gender == &quot;Male&quot;) %&gt;% pull(engagement)) ## ## F test to compare two variances ## ## data: ind_num$t_dat %&gt;% filter(gender == &quot;Female&quot;) %&gt;% pull(engagement) and ind_num$t_dat %&gt;% filter(gender == &quot;Male&quot;) %&gt;% pull(engagement) ## F = 1.8163, num df = 19, denom df = 19, p-value = 0.2025 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.7189277 4.5888826 ## sample estimates: ## ratio of variances ## 1.816336 Bartletts test is a second option. bartlett.test(ind_num$t_dat$engagement, ind_num$t_dat$gender) ## ## Bartlett test of homogeneity of variances ## ## data: ind_num$t_dat$engagement and ind_num$t_dat$gender ## Bartlett&#39;s K-squared = 1.6246, df = 1, p-value = 0.2024 Levenes test is a third option. Levenes is less sensitive to departures from normality than Bartlett. (ind_num$levene &lt;- with(ind_num$t_dat, car::leveneTest(engagement, gender, center = &quot;mean&quot;)) ) ## Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) ## Df F value Pr(&gt;F) ## group 1 1.922 0.1737 ## 38 There was homogeneity of variances for engagement scores for males and females, as assessed by Levenes test for equality of variances (p = 0.174). Similar Distributions If the data passed the outliers and normality tests, you use the Mann-Whitney test, so now you need to test the distributions to determine how you can interpret its results. If the distributions are similarly shaped, you can interpret the Mann-Whitney U test as inferences about differences in medians between the two groups. If the distributions look dissimilar, interpret the test as inferences about the distributions, lower/higher scores and/or mean ranks. Distributions of the engagement scores for males and females were similar, as assessed by visual inspection. Test Conduct the t-test or the Mann-Whitney U test. (ind_num$t_test &lt;- t.test(engagement ~ gender, data = ind_num$t_dat, var.equal = TRUE)) ## ## Two Sample t-test ## ## data: engagement by gender ## t = 2.3645, df = 38, p-value = 0.02327 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.03725546 0.48074454 ## sample estimates: ## mean in group Male mean in group Female ## 5.558875 5.299875 There was a statistically significant difference in mean engagement score between males and females, with males scoring higher than females, 0.26 (95% CI, 0.04 to 0.48), t(38) = 2.365, p = 0.023. The effect size, Cohens d, is defined as \\(d = |M_D| / s\\), where \\(|M_D| = \\bar{x} - \\bar{y}\\), and \\(s\\) is the pooled sample standard deviation, \\(s_p = \\sqrt{\\frac{(n_X - 1) s_X^2 + (n_Y-1) s_Y^2}{n_X + n_Y-2}}\\). \\(d &lt;.2\\) is considered trivial, \\(.2 \\le d &lt; .5\\) small, and \\(.5 \\le d &lt; .8\\) large. (d &lt;- effectsize::cohens_d(engagement ~ gender, data = ind_num$t_dat, pooled_sd = TRUE)) ## Cohen&#39;s d | 95% CI ## ------------------------ ## 0.75 | [0.10, 1.39] ## - Estimate using pooled SD You are about to reject the null hypothesis. Construct a plot as a sanity check on your reasoning. The Mann-Whitney U test is the same as the Wilcoxon test, but for two variables. (ind_num$mw_test &lt;- wilcox.test(engagement ~ gender, data = ind_num$mw_dat, exact = TRUE, correct = FALSE)) ## ## Wilcoxon rank sum exact test ## ## data: engagement by gender ## W = 255, p-value = 0.1417 ## alternative hypothesis: true location shift is not equal to 0 Unfortunately, wilcox.test() does not report U or the standardized test statistic \\(z = \\frac{U - m_U}{\\sigma_U}\\) where \\(m_U = \\frac{n_1 n_2}{2}\\) and \\(\\sigma_U = \\sqrt{\\frac{n_1 n_2(n_1 + n_2 + 1)}{12}}\\), so you have to calculate that yourself. ind_num$mw_test_manual &lt;- ind_num$mw_dat %&gt;% mutate(R = rank(engagement)) %&gt;% group_by(gender) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), R = sum(R)) %&gt;% pivot_wider(names_from = gender, values_from = c(n, R)) %&gt;% mutate( U_Male = n_Male * n_Female + n_Male*(n_Male + 1)/2 - R_Male, U_Female = n_Male * n_Female + n_Female*(n_Female + 1)/2 - R_Female, U = min(U_Male, U_Female), m_U = n_Male * n_Female / 2, s_U = sqrt((n_Male * n_Female * (n_Male + n_Female + 1)) / 12), z = (U - m_U) / s_U, mean_rank_Male = R_Male / n_Male, mean_rank_Female = R_Female / n_Female, ) ind_num$mw_test_manual %&gt;% flextable::flextable() %&gt;% flextable::autofit() .cl-5591f2a6{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-55921d1c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-55924468{width:44px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55924469{width:118px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5592446a{width:106px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5592446b{width:69px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5592446c{width:57px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5592446d{width:71px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5592446e{width:58px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5592446f{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55924470{width:39px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55924471{width:70px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55924472{width:44px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b1e{width:118px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b1f{width:106px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b20{width:69px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b21{width:57px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b22{width:71px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b23{width:58px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b24{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b25{width:39px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-55926b26{width:70px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}n_Malen_FemaleR_MaleR_FemaleU_MaleU_FemaleUm_Us_Uzmean_rank_Malemean_rank_Female202046535514525514520036.96846-1.48775523.2517.75 Median engagement score was not statistically significantly different between males and females, U = 145, z = -1.488, p = 0.142, using an exact sampling distribution for U. Now you are ready to report the results. Here is how you would report the t test. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. There were 20 male and 20 female participants. An independent-samples t-test was run to determine if there were differences in engagement to an advertisement between males and females. There were no outliers in the data, as assessed by inspection of a boxplot. Engagement scores for each level of gender were normally distributed, as assessed by Shapiro-Wilks test (p &gt; .05), and there was homogeneity of variances, as assessed by Levenes test for equality of variances (p = 0.174). The advertisement was more engaging to male viewers (5.56 \\(\\pm\\) = 0.29) than female viewers (5.30 \\(\\pm\\) = 0.39), a statistically significant difference of 0.26 (95% CI, 0.04 to 0.48), t(38) = 2.365, p = 0.023, d = 0.75. Here is how you would report the Mann-Whitney U-Test. A Mann-Whitney U test was run to determine if there were differences in engagement score between males and females. Distributions of the engagement scores for males and females were similar, as assessed by visual inspection. Median engagement score for males (5.58) and females (5.38) was not statistically significantly different, U = 145, z = -1.488, p = 0.142, using an exact sampling distribution for U. Had the distributions differed, you would report the Mann-Whitney like this: A Mann-Whitney U test was run to determine if there were differences in engagement score between males and females. Distributions of the engagement scores for males and females were not similar, as assessed by visual inspection. Engagement scores for males (mean rank = 23.25) and females (mean rank = 17.75) were not statistically significantly different, U = 145, z = -1.488, p = 0.142, using an exact sampling distribution for U. 2.2 Paired Samples (Continuous) There are two common study designs that employ a paired samples t-test to compare two related groups. One relates the groups as two time points for the same subjects. The second relates the groups as two tests of the same subjects, e.g. comparing reaction time under two lighting conditions. Paired Samples t-Test The paired samples t-test uses the mean of sampled paired differences \\(\\bar{d}\\) as an estimate of the mean of the population paired differences \\(\\delta\\) to evaluate an hypothesized mean \\(\\delta_0\\). Test \\(H_0: \\delta = \\delta_0\\) with test statistic \\(T = \\frac{\\bar{d} - \\delta_0}{se}\\), or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\delta = \\bar{d} \\pm t_{1 - \\alpha / 2, n - 1} se\\). The paired t-test is really just a one-sample mean t-test operating on variable that is defined as the difference between two variables. The paired samples t test applies when the sampling distribution of the mean of the population paired differences is normally distributed and there are no significant outliers. Wilcoxon Signed-Rank Test The Wilcoxon signed-rank test is a nonparametric alternative to the paired-samples t-test for cases in which the paired differences fails the normality condition, but is at least symmetrically distributed. The test statistic is the sum product of the difference signs (-1, +1) and the rank of the difference absolute values, \\(W = \\sum_{i=1}^n sign (d_i) \\cdot R_i\\). The more differences that are of one sign, or of extreme magnitude, the larger \\(W\\) is likely to be, and the more likely to reject \\(H_0\\) of equality of medians. Sign Test The sign test is an alternative to the Wilcoxon signed-rank test for cases in which the paired differences fails the symmetrical distribution condition. The test statistic is the count of pairs whose difference is positive, \\(W = cnt(d_i &gt; 0)\\). \\(W \\sim b(n, 0.5)\\), so the sign test is really just an exact binomial test (exact sign test), or for large n-size, the normal approximation to the binomial (sign test). Case Study \\(n\\) = 20 athletes consume a carb-only or carb+protein drink prior to running as far as possible in 2 hours and a researcher records their distances under each condition. Do the distances differ from 0? Laerd has three data sets for this example. One meets the conditions for a t-test. The second fails the normality condition, but is symmetric and meets the conditions for the Wilcoxon test. The third fails the symmetry condition and requires the sign test. t-test data set (drink$t_gt &lt;- drink$t_dat %&gt;% gtsummary::tbl_summary(statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #kzkqicyjiw .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kzkqicyjiw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kzkqicyjiw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kzkqicyjiw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #kzkqicyjiw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kzkqicyjiw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kzkqicyjiw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kzkqicyjiw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kzkqicyjiw .gt_column_spanner_outer:first-child { padding-left: 0; } #kzkqicyjiw .gt_column_spanner_outer:last-child { padding-right: 0; } #kzkqicyjiw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #kzkqicyjiw .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #kzkqicyjiw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kzkqicyjiw .gt_from_md > :first-child { margin-top: 0; } #kzkqicyjiw .gt_from_md > :last-child { margin-bottom: 0; } #kzkqicyjiw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kzkqicyjiw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #kzkqicyjiw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kzkqicyjiw .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #kzkqicyjiw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kzkqicyjiw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kzkqicyjiw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kzkqicyjiw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kzkqicyjiw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kzkqicyjiw .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #kzkqicyjiw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kzkqicyjiw .gt_sourcenote { font-size: 90%; padding: 4px; } #kzkqicyjiw .gt_left { text-align: left; } #kzkqicyjiw .gt_center { text-align: center; } #kzkqicyjiw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kzkqicyjiw .gt_font_normal { font-weight: normal; } #kzkqicyjiw .gt_font_bold { font-weight: bold; } #kzkqicyjiw .gt_font_italic { font-style: italic; } #kzkqicyjiw .gt_super { font-size: 65%; } #kzkqicyjiw .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 201 carb 11.17 (0.73) carb_protein 11.30 (0.71) diff 0.14 (0.10) 1 Statistics presented: Mean (SD) There were 20 participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.30 (0.71) km, than the carbohydrate-only drink, 11.17 (0.73) km. Wilcoxon data set Once you learn you need Wilcoxon or the sign-test, show the median and IQR summary statistics instead. (drink$wilcoxon_gt &lt;- drink$wilcoxon_dat %&gt;% gtsummary::tbl_summary() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xnwnbkolld .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xnwnbkolld .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xnwnbkolld .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xnwnbkolld .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #xnwnbkolld .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xnwnbkolld .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xnwnbkolld .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xnwnbkolld .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xnwnbkolld .gt_column_spanner_outer:first-child { padding-left: 0; } #xnwnbkolld .gt_column_spanner_outer:last-child { padding-right: 0; } #xnwnbkolld .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #xnwnbkolld .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xnwnbkolld .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xnwnbkolld .gt_from_md > :first-child { margin-top: 0; } #xnwnbkolld .gt_from_md > :last-child { margin-bottom: 0; } #xnwnbkolld .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xnwnbkolld .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xnwnbkolld .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xnwnbkolld .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xnwnbkolld .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xnwnbkolld .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xnwnbkolld .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xnwnbkolld .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xnwnbkolld .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xnwnbkolld .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xnwnbkolld .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xnwnbkolld .gt_sourcenote { font-size: 90%; padding: 4px; } #xnwnbkolld .gt_left { text-align: left; } #xnwnbkolld .gt_center { text-align: center; } #xnwnbkolld .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xnwnbkolld .gt_font_normal { font-weight: normal; } #xnwnbkolld .gt_font_bold { font-weight: bold; } #xnwnbkolld .gt_font_italic { font-style: italic; } #xnwnbkolld .gt_super { font-size: 65%; } #xnwnbkolld .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 201 carb 11.28 (10.43, 11.72) carb_protein 11.37 (10.92, 11.81) diff 0.19 (-0.10, 0.47) 1 Statistics presented: Median (IQR) There were 20 participants. Data are medians and IQR unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.37 (10.92, 11.81) km, than the carbohydrate-only drink, 11.28 (10.43, 11.72) km. Sign data set (drink$sign_gt &lt;- drink$sign_dat %&gt;% gtsummary::tbl_summary() ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #sgckmrggbo .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #sgckmrggbo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #sgckmrggbo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #sgckmrggbo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #sgckmrggbo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #sgckmrggbo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #sgckmrggbo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #sgckmrggbo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #sgckmrggbo .gt_column_spanner_outer:first-child { padding-left: 0; } #sgckmrggbo .gt_column_spanner_outer:last-child { padding-right: 0; } #sgckmrggbo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #sgckmrggbo .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #sgckmrggbo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #sgckmrggbo .gt_from_md > :first-child { margin-top: 0; } #sgckmrggbo .gt_from_md > :last-child { margin-bottom: 0; } #sgckmrggbo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #sgckmrggbo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #sgckmrggbo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #sgckmrggbo .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #sgckmrggbo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #sgckmrggbo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #sgckmrggbo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #sgckmrggbo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #sgckmrggbo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #sgckmrggbo .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #sgckmrggbo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #sgckmrggbo .gt_sourcenote { font-size: 90%; padding: 4px; } #sgckmrggbo .gt_left { text-align: left; } #sgckmrggbo .gt_center { text-align: center; } #sgckmrggbo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #sgckmrggbo .gt_font_normal { font-weight: normal; } #sgckmrggbo .gt_font_bold { font-weight: bold; } #sgckmrggbo .gt_font_italic { font-style: italic; } #sgckmrggbo .gt_super { font-size: 65%; } #sgckmrggbo .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N = 201 carb 11.11 (10.43, 11.49) carb_protein 11.37 (10.92, 11.81) diff 0.23 (0.12, 0.55) 1 Statistics presented: Median (IQR) There were 20 participants. Data are median and IQR unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.37 (10.92, 11.81) km, than the carbohydrate-only drink, 11.11 (10.43, 11.49) km. Conditions The paired samples t test applies when the variable is continuous and partitioned into dependent pairs, Additionally, there are two conditions related to the data distribution. If either condition fails, consider the suggested work-around or move to the non-parametric alternatives. Outliers. There should be no outliers in the differences because they exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them if they do not affect the conclusion, or you can transform the data. Normality. Differences should be nearly normally distributed (nearly because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. There were no outliers in the data, as assessed by inspection of a boxplot. Had there been outliers, you might report X outliers were detected. Inspection of their values did not reveal them to be extreme and they were kept in the analysis. If the outliers are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you can try leaving them in or transforming the data. Normality Assume the population is normally distributed if n \\(\\ge\\) 30. These data sets have n = 20 observations, so you cannot assume normality. Asses a Q-Q plot, skewness and kurtosis values, histogram, or Shapiro-Wilk test. For the t-test data set, (drink$t_shapiro &lt;- shapiro.test(drink$t_dat$diff)) ## ## Shapiro-Wilk normality test ## ## data: drink$t_dat$diff ## W = 0.97119, p-value = 0.7797 The differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were normally distributed, as assessed by Shapiro-Wilks test (p = 0.780). For the Wilcoxon data set, (drink$wilcoxon_shapiro &lt;- shapiro.test(drink$wilcoxon_dat$diff)) ## ## Shapiro-Wilk normality test ## ## data: drink$wilcoxon_dat$diff ## W = 0.87077, p-value = 0.01212 The differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were not normally distributed, as assessed by Shapiro-Wilks test (p = 0.012). For the sign-test data set, (drink$sign_shapiro &lt;- shapiro.test(drink$sign_dat$diff)) ## ## Shapiro-Wilk normality test ## ## data: drink$sign_dat$diff ## W = 0.8968, p-value = 0.03593 The differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were not normally distributed, as assessed by Shapiro-Wilks test (p = 0.036). If the data is normally distributed, use the t-test. If not, you try transforming the dependent variable, or carrying on regardless since the t-test is fairly robust to deviations from normality. Symmetric Distribution If the data passed the outliers test, but failed the normality test, as the Wilcoxon and sign test data sets above did, you will use the Wilcoxon signed-rank test or sign test. Now you need to test the distribution to determine which test. If the distribution is symmetric, use Wilcoxon; otherwise use the sign test. For the Wilcoxon data set, The distribution of the differences between the carbohydrate-protein drink and the carbohydrate-only was symmetric, as assessed by visual inspection. For the sign data set, The distribution of the differences between the carbohydrate-protein drink and the carbohydrate-only was not asymmetric, as assessed by visual inspection. Test t-test (drink$t_t &lt;- t.test(x = drink$t_dat$carb_protein, y = drink$t_dat$carb, paired = TRUE) ) ## ## Paired t-test ## ## data: drink$t_dat$carb_protein and drink$t_dat$carb ## t = 6.3524, df = 19, p-value = 4.283e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.09085492 0.18014508 ## sample estimates: ## mean of the differences ## 0.1355 The carbohydrate-protein drink elicited an increase of 0.135 (95% CI, 0.091 to 0.180) km in the distance run in two hours compared to a carbohydrate-only drink. The effect size, called Cohens d, is the number of standard deviations the measured mean difference is from the hypothesized difference, \\((\\bar{d}-d_0) / s\\), where \\(s\\) is the sample standard deviation. .2 is small, .5 is medium, and .8 is large. This one is large. (drink$t_d &lt;- effectsize::cohens_d(drink$t_dat$diff)) ## Cohen&#39;s d | 95% CI ## ------------------------ ## 1.42 | [0.80, 2.09] ## - Estimate using pooled SD You are about to reject the null hypothesis. Construct a plot as a sanity check on your reasoning. Report the results. A paired-samples t-test was used to determine the effect of a new formula of sports drink on running performance. Instead of the regular, carbohydrate-only drink, the new sports drink contains a new carbohydrate-protein mixture. Twenty participants were recruited to the study who each performed two trials in which they had to run as far as possible in two hours on a treadmill. In one of the trials they drank the carbohydrate-only drink and in the other trial they drank the carbohydrate-protein drink. The order of the trials was counterbalanced and the distance they ran in both trials was recorded. Two outliers were detected that were more than 1.5 box-lengths from the edge of the box in a boxplot. Inspection of their values did not reveal them to be extreme and they were kept in the analysis. The assumption of normality was not violated, as assessed by Shapiro-Wilks test (p = 0.780). Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.30 (0.71) km, than the carbohydrate-only drink, 11.17 (0.73) km, a statistically significant increase of 0.135 (95% CI, 0.091 to 0.180) km, t(19) = 6.352, p = 0.0000, d = 1.42. Wilcoxon Signed-Rank Test From the distribution plot, you can see that most of the signs were positive, and the largest absolute difference values were among the positives, so expect a pretty large test statistic. (drink$wilcoxon_test &lt;- wilcox.test(drink$wilcoxon_dat$carb_protein, drink$wilcoxon_dat$carb, paired = TRUE)) ## ## Wilcoxon signed rank exact test ## ## data: drink$wilcoxon_dat$carb_protein and drink$wilcoxon_dat$carb ## V = 162, p-value = 0.03277 ## alternative hypothesis: true location shift is not equal to 0 The carbohydrate-protein drink elicited a statistically significant median increase in distance run in two hours compared to the carbohydrate-only drink, W = 162, p = 0.033. Report the results. A Wilcoxon signed-rank test was conducted to determine the effect of a new formula of sports drink on running performance. Instead of the regular, carbohydrate-only drink, the new sports drink contains a new carbohydrate-protein mixture. Twenty participants were recruited to the study who each performed two trials in which they had to run as far as possible in two hours on a treadmill. In one of the trials they drank the carbohydrate-only drink and in the other trial they drank the carbohydrate-protein drink. The order of the trials was counterbalanced and the distance they ran in both trials was recorded. The difference scores were approximately symmetrically distributed, as assessed by a histogram with superimposed normal curve. Data are medians unless otherwise stated. Of the 20 participants recruited to the study, the carbohydrate-protein drink elicited an increase in the distance run in 17 participants compared to the carbohydrate-only drink, whereas two participants saw no improvement and one participant did not run as far with the carbohydrate-protein drink. There was a statistically significant median increase in distance run (0.2300 km) when subjects imbibed the carbohydrate-protein drink (11.368 km) compared to the carbohydrate-only drink (11.108 km), W = 162, p = 0.0328. Sign Signed-Rank Test Conduct the exact sign test since the n-size is not so large that we need the normal approximation to the binomial. Notice n is the count of non-zero differences. (drink$sign_test &lt;- binom.test(sum(drink$sign_dat$diff &gt; 0), n = sum(drink$sign_dat$diff != 0))) ## ## Exact binomial test ## ## data: sum(drink$sign_dat$diff &gt; 0) and sum(drink$sign_dat$diff != 0) ## number of successes = 18, number of trials = 18, p-value = 7.629e-06 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.814698 1.000000 ## sample estimates: ## probability of success ## 1 The carbohydrate-protein drink elicited a statistically significant median increase in distance run (0.230 km) compared to the carbohydrate-only drink, p = 0.000. Report the results. An exact sign test was conducted to determine the effect of a new formula of sports drink on running performance. Instead of the regular, carbohydrate-only drink, the new sports drink contains a new carbohydrate-protein mixture. Twenty participants were recruited to the study who each performed two trials in which they had to run as far as possible in two hours on a treadmill. In one of the trials they drank the carbohydrate-only drink and in the other trial they drank the carbohydrate-protein drink. The order of the trials was counterbalanced and the distance they ran in both trials was recorded. An exact sign test was used to determine whether there was a statistically significant median difference between the distance ran when participants drank a carbohydrate-protein drink compared to a carbohydrate-only drink. Data are medians unless otherwise stated. Of the 20 participants recruited to the study, the carbohydrate-protein drink elicited an increase in the distance run in 18 participants compared to the carbohydrate-only drink, whereas 0 participants did not run as far and 2 participant saw no improvement with the carbohydrate-protein drink. There was a statistically significant median increase in distance run (0.2300 km) when subjects imbibed the carbohydrate-protein drink (11.368 km) compared to the carbohydrate-only drink (11.108 km), p = 0.0000. 2.3 Independent Samples (Discrete) There are three common tests: the z-test of two proportions; chi-square test of homogeneity; and Fishers exact test. The z-test and chi-square test produce the same statistical significance result because they are algebraically identical, however the chi-square test is more commonly used. Both tests require large n&gt;30 sample sizes. When this assumption is violated, use Fishers exact. z-Test of Two Proportions The z-test uses the difference in sample proportions \\(\\hat{d} = p_1 - p_2\\) as an estimate of the difference in population proportions \\(\\delta = \\pi_1 - \\pi_2\\) to evaluate an hypothesized difference in population proportions \\(d_0 = \\pi_0 - \\pi_1\\) and/or construct a \\((1\\alpha)\\%\\) confidence interval around \\(\\hat{d}\\) to estimate \\(\\delta\\) within a margin of error \\(\\epsilon\\). The z-test applies when the central limit theorem conditions hold so that the normal distribution approximates the binomial distribution. the sample is independently drawn, meaning random assignment (experiments) or random sampling without replacement from \\(n &lt; 10\\%\\) of the population (observational studies), there are at least \\(n_i p_i &gt;= 5\\) successes and \\(n_i (1 - p_i) &gt;= 5\\) failures for each group \\(i\\), the sample sizes are both \\(n_i &gt;= 30\\), and the probability of success for each group is not extreme, \\(0.2 &lt; \\pi_i &lt; 0.8\\). If these conditions hold, the sampling distribution of \\(\\delta\\) is normally distributed around \\(\\hat{d}\\) with standard error \\(se_\\hat{d} = \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1  p_2)}{n_2}}\\). The measured values \\(\\hat{d}\\) and \\(se_\\hat{d}\\) approximate the population values \\(\\delta\\) and \\(se_\\delta\\). Define a \\((1  \\alpha)\\%\\) confidence interval as \\(\\hat{d} \\pm z_{\\alpha / 2}se_\\hat{d}\\) or test the hypothesis of \\(d = d_0\\) with test statistic \\(z = \\frac{\\hat{d}  d_0}{se_{d_0}}\\) where \\(se_{d_0} = \\sqrt{p^*(1 - p^*) \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\\) and \\(p^*\\) is the overall success probability. Chi-Square Test of Homogeneity The chi-square test of homogeneity tests whether frequency counts of the R levels of a categorical variable are distributed identically across the C populations. It tests whether observed joint frequency counts \\(O_{ij}\\) differ from expected frequency counts \\(E_{ij}\\) under the independence model (the model of independent explanatory variables, \\(\\pi_{ij} = \\pi_{i+} \\pi_{+j}\\). \\(H_0\\) is \\(O_{ij} = E_{ij}\\). The chi-square homogeneity test can be extended to cases where \\(I\\) and/or \\(J\\) is greater than 2. There are two possible test statistics for this test, Pearson \\(X^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\), and deviance \\(G^2 = 2 \\sum_{ij} O_{ij} \\log \\left( \\frac{O_{ij}}{E_{ij}} \\right)\\). Fishers Exact Test Fishers exact test is an exact test in that the p-value is calculated exactly from the hypergeometric distribution rather than relying on the approximation that the test statistic distribution approaches \\(\\chi^2\\) as \\(n \\rightarrow \\infty\\). The test is applicable in situations where the row totals \\(n_{i+}\\) and the column totals \\(n_+j\\) are fixed by study design (rarely applies), and the expected values of &gt;20% of cells (at least 1 cell in a 2x2 table) have expected cell counts &gt;5, and no expected cell count is &lt;1. The p-value from the test is computed as if the margins of the table are fixed. This leads under a null hypothesis of independence to a hypergeometric distribution of the numbers in the cells of the table (Wikipedia). Fishers exact test is useful for small n-size samples where the chi-squared distribution assumption of the chi-squared and G-test tests fails. Fishers exact test is overly conservative (p values too high) for large n-sizes. The Hypergeometric density function is \\[f_X(k|N, K, n) = \\frac{{{K}\\choose{k}}{{N-K}\\choose{n-k}}}{{N}\\choose{n}}.\\] The density is the exact hypergeometric probability of observing this particular arrangement of the data, assuming the given marginal totals, on the null hypothesis that the conditional probabilities are equal. Case Study The case study below uses a data set from Laerd and a second modified version. The first data set passes the chi-square test of homogeneity requirements. The second (in parentheses), fails the n-sizes test. A researcher recruits 100 (50) patients who have a high classification of cholesterol and who currently have a poor lifestyle. The researcher randomly assigns 50 (25) of them to a drug intervention and 50 (25) to a lifestyle intervention. After six months, a doctor reclassifies the patients as either still having a high classification of cholesterol or now having a normal classification of cholesterol. The chi-sq data set has the following summary statistics. .cl-582cf416{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-582cf417{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-582d1ad6{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1ad7{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1ad8{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1ad9{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1ada{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1adb{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1adc{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1add{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1ade{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1adf{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d1ae0{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-582d3f52{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2.1: Chisq Data Set: Observed vs Expected DatainterventionHighNormalTotalObservedDrug18 (36%)32 (64%) 50 (100%)Lifestyle33 (66%)17 (34%) 50 (100%)Total51 (51%)49 (49%)100 (100%)ExpectedDrug25.5 (51%)24.5 (49%) 50 (100%)Lifestyle25.5 (51%)24.5 (49%) 50 (100%)Total51.0 (51%)49.0 (49%)100 (100%) The Fisher data set has the following summary statistics. .cl-585e88aa{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-585eafba{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-585eafbb{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585eafbc{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585eafbd{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585eafbe{width:71px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585eafbf{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585eafc0{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6ca{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6cb{width:71px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6cc{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6cd{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6ce{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6cf{width:71px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6d0{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6d1{width:74px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6d2{width:77px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-585ed6d3{width:71px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2.2: Fisher Data Set: Observed vs Expected DatainterventionHighNormalTotalObservedDrug 9 (36%)16 (64%)25 (100%)Lifestyle16 (64%) 9 (36%)25 (100%)Total25 (50%)25 (50%)50 (100%)ExpectedDrug12.5 (50%)12.5 (50%)25 (100%)Lifestyle12.5 (50%)12.5 (50%)25 (100%)Total25.0 (50%)25.0 (50%)50 (100%) Conditions n-Size The chi-square test of homogeneity applies with the CLT conditions hold. the sample is independently drawn, there are at least 5 successes (Normal) and failures (High) for each group \\(i\\), the sample sizes for both groups are &gt;=30, and the probability of success for each group is not extreme, \\(0.2 &lt; \\pi_i &lt; 0.8\\). The conditions hold for the chi-sq data set, but not for the Fisher data set. Test Chi-Square (ind_discrete$chisq_test &lt;- ind_discrete$chisq_dat %&gt;% tabyl(intervention, risk_level) %&gt;% chisq.test(correct = FALSE)) ## ## Pearson&#39;s Chi-squared test ## ## data: . ## X-squared = 9.0036, df = 1, p-value = 0.002694 100 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 50 in each intervention. The test of two proportions used was the chi-square test of homogeneity. At the conclusion of the drug intervention, 32 patients (64%) had improved their cholesterol classification from high to normal compared to 17 patients (34%) in the lifestyle intervention, a difference in proportions of 0.30, p = 0.0027. Fisher (ind_discrete$fisher_test &lt;- ind_discrete$fisher_dat %&gt;% tabyl(intervention, risk_level) %&gt;% fisher.test()) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: . ## p-value = 0.08874 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.08497039 1.15362199 ## sample estimates: ## odds ratio ## 0.3241952 50 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 25 in each intervention. At the conclusion of the drug intervention, 16 patients (64%) had improved their cholesterol classification from high to normal compared to 9 patients (36%) in the lifestyle intervention. Due to small sample sizes, Fishers exact test was run. There was a non-statistically significant difference in proportions of 0.28, p = 0.0887. 2.4 Paired Samples (Discrete) McNemars Test This test applies when you have paired samples. Wilcoxon Paired-Sample applies when the variable distributions are non-normally distributed and samples are paired. The t-test returns nearly the same result as the z-test when the CLT holds, so in practice no one bothers with the z-test except as an aid to teach the t-test. "],["multi-group-comparison-tests.html", "Chapter 3 Multi-Group Comparison Tests 3.1 Independent t-Test 3.2 Paired t-Test 3.3 Sign est 3.4 Wilcoxon Rank-Sum Test 3.5 Wilcoxon Signed-Rank Test 3.6 ANOVA 3.7 KruskalWallis Test 3.8 pairwise.prop.test", " Chapter 3 Multi-Group Comparison Tests Comparison tests look for differences among group means. They can be used to test the effect of a categorical variable on the mean value of some other characteristic. T-tests are used when comparing the means of precisely two groups (e.g. the average heights of men and women). ANOVA and MANOVA tests are used when comparing the means of more than two groups (e.g. the average heights of children, teenagers, and adults). Quantitative ~ Categorical 3.1 Independent t-Test 3.2 Paired t-Test 3.3 Sign est 3.4 Wilcoxon Rank-Sum Test 3.5 Wilcoxon Signed-Rank Test 3.6 ANOVA Most of these notes are gleaned from PSU STAT-502 Analysis of Variance and Design of Experiments covers ANOVA. Laerd Statistics is useful for writing up your results for reports. Classic analysis of variance (ANOVA) compares the mean responses from experimental studies. However, ANOVA also compares the mean responses from observational studies, but conclusions are just less rigorous. 3.6.1 One-Way ANOVA Use the one-way ANOVA test to compare the mean response of a continuous dependent variable among the levels of a factor variable. Here is a case study. Researchers compare the plant growth among three fertilizers and a control group. Data set greenhouse contains 6 observations per each of the k = 4 treatment levels (N = 24) - a balanced design. All three fertilizers produced more growth than the control group. Fertilizers F1 and F3 appear to be about tied for most growth, but it is unclear if the fertilizers are significantly different from each other. Treated Control(N=6) F1(N=6) F2(N=6) F3(N=6) All treated(N=18) Overall(N=24) Growth (cm) Mean (SD) 21.0 (1.00) 28.6 (2.44) 25.9 (1.90) 29.2 (1.29) 27.9 (2.35) 26.2 (3.69) Median [Min, Max] 21.0 [19.5, 22.5] 28.3 [25.0, 32.0] 26.3 [22.5, 28.0] 29.4 [27.5, 31.0] 28.0 [22.5, 32.0] 27.3 [19.5, 32.0] greenhouse_desc &lt;- greenhouse %&gt;% group_by(group) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), mean = mean(growth), sd = sd(growth)) Data is presented as mean \\(\\pm\\) standard deviation. Plant growth (growth) increased from the control (n = 6, 21 \\(\\pm\\) 1.0), to fertilizer 1 (n = 6, 28.6 \\(\\pm\\) 2.4), fertilizer 2 (n = 6, 25.8666667 \\(\\pm\\) 1.9), and fertilizer 3 (n = 6, 29.2 \\(\\pm\\) 1.3) fertilizer groups. ANOVA decomposes the deviation of observation \\(Y_{ij}\\) around the overall mean \\(\\bar{Y}_{..}\\) into two parts: the deviation of the observations around their treatment means, \\(SSE\\), and the deviation of the treatment means around the overall mean, \\(SSR\\). Their ratio, \\(F = SSR/SSE\\) follows an F-distribution with \\(k-1\\) numerator dof and \\(N-k\\) denominator dof. The more observation variance captured by the treatments, the large is \\(F\\), and the less likely that the null hypothesis, \\(H_0 = \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\) is true. Table 3.1: ANOVA Table Source SS df MS F SSR \\(\\sum{n_i(\\bar{Y}_{i.} - \\bar{Y}_{..})^2}\\) \\(k - 1\\) \\({SSR}/{(k - 1)}\\) \\({MSR}/{MSE}\\) SSE \\(\\sum(Y_{ij} - \\bar{Y}_{i.})^2\\) \\(N - k\\) \\({SSE}/{(N - k)}\\) SST \\(\\sum(Y_{ij} - \\bar{Y}_{..})^2\\) \\(N - 1\\) Run an ANOVA test in R like this: greenhouse_aov &lt;- aov(growth ~ group, data = greenhouse) greenhouse_anova &lt;- anova(greenhouse_aov) greenhouse_anova %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.8, layout = &quot;autofit&quot;) %&gt;% colformat_num(j = c(3, 4, 5), digits = 1) %&gt;% colformat_num(j = 6, digits = 4) %&gt;% set_caption(&quot;Results of ANOVA for Growth vs Fertilizer Group&quot;) .cl-5920e0da{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-59210d62{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-59210d63{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-592134b8{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-592134b9{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-592134ba{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-592134bb{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-592134bc{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-592134bd{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.2: Results of ANOVA for Growth vs Fertilizer Group termdfsumsqmeansqstatisticp.valuegroup3251.483.827.50.0000Residuals2061.03.1 The one-way ANOVA indicates amount of growth was statistically significantly different for different levels of fertilizer group, F(3, 20) = 27.5, p &lt; .0001. BTW, it is worth noting the relationship with linear regression. The regression model intercept is the overall mean and the coefficient estimators indirectly indicate the group means. The analysis of variance table in a regression model shows how much of the overall variance is explained by those coefficient estimators. Its the same thing. You may also want to report the \\(\\omega^2\\) effect size, \\[\\omega^2 = \\frac{SSR - df_R \\cdot MSE}{MSE + SST}\\] greenhouse_omega &lt;- sjstats::anova_stats(greenhouse_anova) %&gt;% filter(term == &quot;group&quot;) %&gt;% pull(omegasq) ## Registered S3 methods overwritten by &#39;lme4&#39;: ## method from ## cooks.distance.influence.merMod car ## influence.merMod car ## dfbeta.influence.merMod car ## dfbetas.influence.merMod car \\(\\omega^2\\) ranges from -1 to +1. In this example, \\(\\omega^2\\) is 0.768. 3.6.1.1 ANOVA Conditions The ANOVA test applies when the dependent variable is continuous, the independent variable is categorical, and the observations are independent within groups. Independent means the observations should be from a random sample, or from an experiment using random assignment. Each groups size should be less than 10% of its population size. The groups must also be independent of each other (non-paired, and non-repeated measures). Additionally, there are three conditions related to the data distribution. If any condition does not hold, and the suggested work-arounds do not work switch to the non-parametric [Kruskal-Wallis Test]. No outliers. There should be no significant outliers in the groups. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data. Normality. Each groups values should be nearly normally distributed (nearly because ANOVA is considered robust to the normality assumption). This condition is especially important with small sample sizes. Test with the Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform your response variable. Equal Variances. The group variances should be roughly equal. This condition is especially important when sample sizes differ. Test with a box plot, rule of thumb, or one of the formal homogeneity of variance (external) tests such as Bartlett, and Levene. If the variances are very different, use a Games-Howell post hoc test instead of the Tukey post hoc test. Outliers Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. Our example includes an outlier in fertilizer group F2. Outliers might occur from data entry errors or measurement errors, so investigate and fix or throw them out. However, if the outlier is a genuine extreme value, you still have a couple options before reverting to Kruskal-Wallis. Transform the dependent variable. Dont do this unless the data is also non-normal. It also has the downside of making interpretation more difficult. Leave it in if it doesnt affect the conclusion (compared to taking it out). Lets try removing the outlier (id# 13). greenhouse_aov2 &lt;- aov(growth ~ group, data = greenhouse %&gt;% filter(!id == 13)) greenhouse_anova2 &lt;- anova(greenhouse_aov2) .cl-59b96b3e{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-59b96b3f{font-family:'Arial';font-size:7px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-59b96b40{font-family:'Arial';font-size:6px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-59b96b41{font-family:'Arial';font-size:10px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-59b99d02{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-59b99d03{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-59b99d04{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:0;padding-top:0;padding-left:0;padding-right:0;line-height: 1.00;background-color:transparent;}.cl-59b9c82c{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59b9c82d{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59b9c82e{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59b9c82f{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59b9c830{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(255, 255, 255, 0.00);border-top: 1.00px solid rgba(255, 255, 255, 0.00);border-left: 1.00px solid rgba(255, 255, 255, 0.00);border-right: 1.00px solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59b9c831{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59b9c832{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.3: Results of ANOVA for Growth vs Fertilizer Group termdfsumsqmeansqstatisticp.valuegroup3251.083.733.50.0000Residuals1947.42.5Note: One outlier in group F2 removed. The conclusion is the same, so leaving it in is fine! Normality You can assume the populations are normally distributed if \\(n_j &gt;= 30\\). Otherwise, try the Q-Q plot, or skewness and kurtosis values, or histograms. If you still dont feel confident about normality, run a [Shapiro-Wilk Test] or Kolmogorov-Smirnov Test. If \\(n_j &gt;= 50\\), stick with graphical methods because at larger sample sizes Shapiro-Wilk flags even minor deviations from normality. The QQ plots below appear to be approximately normal. greenhouse %&gt;% ggplot(aes(sample = growth)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + facet_wrap(~group) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) The Shapiro-Wilk test corroborates this conclusion - it fails to reject the null hypothesis of normally distributed populations. x &lt;- by(greenhouse, greenhouse$group, function(x) shapiro.test(x$growth) %&gt;% tidy()) x[1:4] %&gt;% bind_rows() %&gt;% mutate(group = names(x)) %&gt;% dplyr::select(group, everything(), - method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Shapiro-Wilk Normality Test&quot;) .cl-5a1634c2{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5a1634c3{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a1634c4{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a165bbe{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a1682b0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a1682b1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a1682b2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a1682b3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a1682b4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.4: Shapiro-Wilk Normality Test groupstatisticp.valueControl0.97648960.9328373F10.98032330.9531535F20.92569450.5472862F30.97059600.8964141 If the data is not normally distributed, you still have a couple options before reverting to Kruskal-Wallis. Transform the dependent variable. Transformations will generally only work when the distribution of scores in all groups are the same shape. They also have the drawback of making the data less interpretable. carry on regardless. One-way ANOVA is fairly robust to deviations from normality, particularly if the sample sizes are nearly equal. Equal Variances The equality of sample variances condition is less critical when sample sizes are similar among the groups. One rule of thumb is that no groups standard deviation should be more than double that of any other. In this case F1 is more than double Control. .cl-5a2ac02c{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5a2aea70{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a2aea71{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a2b1144{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a2b1145{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a2b1146{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a2b1147{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a2b1148{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a2b1149{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}groupsdControl1.000000F12.437212F21.899123F31.288410 There are two other common tests, Bartlett and Levene. NIST has a good write-up for Levene and for Bartlett. Levene is less sensitive than Bartlett to departures from normality, so if you know your data is normally distributed, then use Bartlett. Levenes test fails to reject the null hypothesis of equality of variance. greenhouse_levene &lt;- car::leveneTest(growth ~ group, data = greenhouse) greenhouse_levene %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Levene&#39;s Test for Homogeneity of Variance&quot;) .cl-5a46f3dc{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5a471bd2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a471bd3{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a476a42{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a476a43{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a476a44{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a476a45{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a476a46{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a476a47{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.5: Levenes Test for Homogeneity of Variance termdfstatisticp.valuegroup31.0491160.392603820NANA So does Bartlett. bartlett.test(growth ~ group, data = greenhouse) %&gt;% tidy() %&gt;% dplyr::select(-method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Bartlett&#39;s Test for Homogeneity of Variance&quot;) .cl-5a5fef4a{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5a60165a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5a603d6a{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a603d6b{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.6: Bartletts Test for Homogeneity of Variance statisticp.valueparameter4.1143420.2493793 Heterogeneity is a common problem in ANOVA. Transforming the response variable can often remove the heterogeneity. The Box-Cox procedure can help find a good transformation. The MASS::boxcox() function calculates a profile of log-likelihoods for a power transformation of the response variable \\(Y^\\lambda\\). \\(\\lambda\\) \\(Y^\\lambda\\) Transformation 2 \\(Y^2\\) Square 1 \\(Y^1\\) (no transformation) .5 \\(Y^{.5}\\) Square Root 0 \\(\\ln(Y)\\) Log -.5 \\(Y^{-.5}\\) Inverse Square Root -1 \\(Y^{-1}\\) Inverse The Box-Cox procedure does not recommend any particular transformation of the data in this case. MASS::boxcox(greenhouse_aov, plotit = TRUE) 3.6.1.2 Custom Contrasts Taking this route is appropriate if you have specific hypotheses about the differences between the groups of your independent variable. For example, we might want to test whether the mean of the treatments differ from the control group, \\(H_0: \\sum_i^K{c_i u_i} = 0\\) where \\(c_i = (1, -1/3, -1/3, -1/3)\\). You can test a constrast using the multcomp package. greenhouse_glht &lt;- multcomp::glht(greenhouse_aov, linfct = multcomp::mcp(group = c(-1, 1/3, 1/3, 1/3))) greenhouse_glht_smry &lt;- summary(greenhouse_glht) greenhouse_confint &lt;- confint(greenhouse_glht) greenhouse_glht_smry ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: User-defined Contrasts ## ## ## Fit: aov(formula = growth ~ group, data = greenhouse) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 1 == 0 6.8889 0.8235 8.365 5.81e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) Growth was statistically significantly higher in the fertilizer groups (mean of 27.9) compared to the sedentary group (21 \\(\\pm\\) 1), a mean difference of 6.8888889 (95% CI, 5.1711032 to 8.6066746), p = 5.806853710^{-8}. 3.6.1.3 Tukey Post Hoc Test The F test does not indicate which populations cause the rejection of \\(H_0\\). For this, use one of the post-hoc tests: Tukey, Fishers Least Significant Difference (LSD), Bonferroni, Scheffe, or Dunnett. Post hoc tests are appropriate if you are investigating all possible pairwise comparisons with no specific hypotheses about specific groups differing from others. Here is the Tukey test. As expected, all three fertilizer factor levels differ from the control. F3 differed from F2, but F1 was not significantly different from either F2 or F3. greenhouse_tukey &lt;- TukeyHSD(greenhouse_aov) greenhouse_tukey %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.8, layout = &quot;autofit&quot;) %&gt;% colformat_num(j = c(4:6), digits = 1) %&gt;% colformat_num(j = 7, digits = 3) %&gt;% set_caption(&quot;Tukey multiple comparisons of means&quot;) %&gt;% footnote(i = 1, j = c(1), value = as_paragraph( paste0(&quot;95% family-wise confidence level\\n&quot;, &quot;Fit: aov(formula = growth ~ group, data = greenhouse)&quot;)), ref_symbols = c(&quot;&quot;), part = &quot;header&quot;) .cl-5aa9bf1c{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5aa9bf1d{font-family:'Arial';font-size:7px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-5aa9bf1e{font-family:'Arial';font-size:6px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-5aa9bf1f{font-family:'Arial';font-size:10px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5aa9e62c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5aa9e62d{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5aa9e62e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:0;padding-top:0;padding-left:0;padding-right:0;line-height: 1.00;background-color:transparent;}.cl-5aaa0d3c{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5aaa0d3d{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5aaa0d3e{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5aaa0d3f{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5aaa0d40{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(255, 255, 255, 0.00);border-top: 1.00px solid rgba(255, 255, 255, 0.00);border-left: 1.00px solid rgba(255, 255, 255, 0.00);border-right: 1.00px solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5aaa0d41{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5aaa0d42{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.7: Tukey multiple comparisons of means termcontrastnull.valueestimateconf.lowconf.highadj.p.valuegroupF1-Control07.64.810.40.000groupF2-Control04.92.07.70.001groupF3-Control08.25.411.00.000groupF2-F10-2.7-5.60.10.060groupF3-F100.6-2.23.40.932groupF3-F203.30.56.20.01795% family-wise confidence levelFit: aov(formula = growth ~ group, data = greenhouse) Data are mean \\(\\pm\\) standard deviation. There was an increase in growth from 21 \\(\\pm\\) 1 in the control group to 28.6 \\(\\pm\\) 2.4 in the group with fertilizer F1, an increase of 7.6 (95% CI, 4.8 to 10.4), which was statistically significant (p &lt; .0001) etc. 3.6.1.4 Reporting a One-Way ANOVA Report like this. A one-way ANOVA was conducted to determine if plant growth was different for groups with different fertilizer types. Plants were classified into four groups: control (n = 6), fertilizer 1 (n = 6), fertilizer 2 (n = 6), and fertilizer 3 (n = 6). There was a single outlier, as assessed by boxplot, and was retained because it did not change the conclusions; data was normally distributed for each group, as assessed by Shapiro-Wilk test (p &gt; .05); and there was homogeneity of variances, as assessed by Levenes test of homogeneity of variances (p = 0.393). Data is presented as mean \\(\\pm\\) standard deviation. Plant growth was statistically significantly different between different fertilizer groups, F(3, 20) = 27.465, p &lt; .0005, \\(\\omega^2\\) = 0.768. Plant growth increased from the control (21 \\(\\pm\\) 1.0), to fertilizer F1 (28.6 \\(\\pm\\) 2.4), fertilizer F2 (25.9 \\(\\pm\\) 1.9), and fertilizer F3 (29.2 \\(\\pm\\) 1.3) fertilizer groups. Tukey post hoc analysis revealed statistically significant increases from control to F1 (7.6, 95% CI (4.8 to 10.4), p = 1.6e-06), control to F2 (4.9, 95% CI (2.0 to 7.7), p = 0.00055), and control to F3 (8.2, 95% CI (5.4 to 11.0), p = 5.1e-07), as well as the increase from F2 to F3 (3.3, 95% CI (0.51 to 6.2), p = 0.017), but there were no statistically significant group differences between F1 and F2 or F1 and F3. 3.6.2 Welchs ANOVA w/Games-Howell Welchs ANOVA test is an alternative to the one-way ANOVA test in cases where the equality of variances assumption is violated. Here is a case study. Researchers compare the force (in newtons) generated in three steps. Data set newton contains 30 observations per each of the k = 3 step levels (N = 90) - a balanced design. A(N=30) B(N=30) C(N=30) Overall(N=90) Force (newtons) Mean (SD) 429 (88.7) 527 (97.6) 649 (145) 535 (144) Median [Min, Max] 415 [306, 692] 499 [417, 759] 615 [437, 939] 498 [306, 939] newton_desc &lt;- newton %&gt;% group_by(step) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), mean = mean(newtons), sd = sd(newtons)) Data is presented as mean \\(\\pm\\) standard deviation. Force (newtons) increased from step 1 (n = 30, 429 \\(\\pm\\) 88.7), to step 2 (n = 30, 527 \\(\\pm\\) 97.6), to step 3 (n = 30, 649 \\(\\pm\\) 145). Start by running the standard ANOVA test: newton_aov &lt;- aov(newtons ~ step, data = newton) newton_anova &lt;- anova(newton_aov) newton_anova %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.8, layout = &quot;autofit&quot;) %&gt;% colformat_num(j = c(3, 4, 5), digits = 1) %&gt;% colformat_num(j = 6, digits = 4) %&gt;% set_caption(&quot;Results of ANOVA for Force vs Step&quot;) .cl-5afc0b8c{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5afc0b8d{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5afc0b8e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5afc3292{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5afc3293{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5afc3294{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5afc3295{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5afc3296{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5afc3297{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.8: Results of ANOVA for Force vs Step termdfsumsqmeansqstatisticp.valuestep2727,295.0363,647.528.40.0000Residuals871,113,208.112,795.5 The one-way ANOVA indicates amount of force was statistically significantly different for different levels of step, F(2, 87) = 28.4, p &lt; .0001. 3.6.2.1 ANOVA Conditions Check the three ANOVA conditions: no outliers, normality, and equal variances. Outliers Assess outliers with a box plot. Our example includes an outlier in step A. You can either transform the dependent variable, see if taking it out changes your conclusion, or use a non-parametric test. Lets try removing the outlier (id# 13). newton2 &lt;- newton %&gt;% mutate(id = row_number()) newton_aov2 &lt;- aov(newtons ~ step, data = newton2 %&gt;% filter(!id == 7)) newton_anova2 &lt;- anova(newton_aov2) .cl-5b4bdb6c{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5b4bdb6d{font-family:'Arial';font-size:7px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-5b4bdb6e{font-family:'Arial';font-size:6px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3px;}.cl-5b4bdb6f{font-family:'Arial';font-size:10px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5b4c027c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5b4c027d{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5b4c027e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:0;padding-top:0;padding-left:0;padding-right:0;line-height: 1.00;background-color:transparent;}.cl-5b4c5740{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b4c5741{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b4c5742{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b4c5743{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b4c5744{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 1.00px solid rgba(255, 255, 255, 0.00);border-top: 1.00px solid rgba(255, 255, 255, 0.00);border-left: 1.00px solid rgba(255, 255, 255, 0.00);border-right: 1.00px solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b4c5745{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b4c5746{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.9: Results of ANOVA for Force vs Step termdfsumsqmeansqstatisticp.valuestep2773,863.5386,931.731.90.0000Residuals861,041,642.712,112.1Note: One outlier in step A removed. The conclusion is the same, so leaving it in is fine! Normality You can assume the populations are normally distributed if \\(n_j &gt;= 30\\), but Ill examine the Q-Q plot and run a [Shapiro-Wilk Test] anyway. The QQ plots below appear to be approximately normal newton %&gt;% ggplot(aes(sample = newtons)) + stat_qq() + stat_qq_line(col = &quot;goldenrod&quot;) + facet_wrap(~step) + theme_minimal() + labs(title = &quot;Normal Q-Q Plot&quot;) but the Shapiro-Wilk test fails for step A and B  evidence of its sensitivity for large n. I will ignore this violation. x &lt;- by(newton, newton$step, function(x) shapiro.test(x$newtons) %&gt;% tidy()) x[1:3] %&gt;% bind_rows() %&gt;% mutate(group = names(x)) %&gt;% dplyr::select(group, everything(), - method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Shapiro-Wilk Normality Test&quot;) .cl-5b976ca8{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5b976ca9{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5b976caa{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5b9790d4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b9790d5{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b9790d6{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b9790d7{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b9790d8{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5b9790d9{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.10: Shapiro-Wilk Normality Test groupstatisticp.valueA0.92548620.03730756B0.90524050.01130931C0.94660730.13705759 Equal Variances The equality of sample variances condition is less critical when sample sizes are similar among the groups. Following the rule of thumb that no groups standard deviation be more than double that of any other, we look okay. .cl-5bad0450{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5bad2ce6{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5bad2ce7{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5bad50e0{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bad50e1{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bad50e2{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bad50e3{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bad50e4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bad50e5{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}stepsdA88.66137B97.58970C144.92031 However, Levenes test rejects the null hypothesis of equality of variance. newton_levene &lt;- car::leveneTest(newtons ~ step, data = newton) newton_levene %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Levene&#39;s Test for Homogeneity of Variance&quot;) .cl-5bd25926{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5bd25927{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5bd25928{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5bd281f8{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bd281f9{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bd281fa{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bd281fb{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bd281fc{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5bd281fd{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.11: Levenes Test for Homogeneity of Variance termdfstatisticp.valuegroup23.9707430.0223743487NANA So does Bartlett. bartlett.test(newtons ~ step, data = newton) %&gt;% tidy() %&gt;% dplyr::select(-method) %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Bartlett&#39;s Test for Homogeneity of Variance&quot;) .cl-5be6f476{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5be71b7c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5be790d4{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5be790d5{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.12: Bartletts Test for Homogeneity of Variance statisticp.valueparameter8.1969350.016598092 We could transform the response variable to remove the heterogeneity. The Box-Cox procedure suggests an inverse square root transformation. \\(\\lambda\\) \\(Y^\\lambda\\) Transformation 2 \\(Y^2\\) Square 1 \\(Y^1\\) (no transformation) .5 \\(Y^{.5}\\) Square Root 0 \\(\\ln(Y)\\) Log -.5 \\(Y^{-.5}\\) Inverse Square Root -1 \\(Y^{-1}\\) Inverse The Box-Cox procedure does not recommend any particular transformation of the data in this case. # MASS::boxcox(newton_aov, plotit = TRUE) newton3 &lt;- newton %&gt;% mutate(newtons_isr = newtons^(-0.5)) newton_levene3 &lt;- car::leveneTest(newtons_isr ~ step, data = newton3) newton_levene3 %&gt;% tidy() %&gt;% flextable() %&gt;% set_table_properties(width = 0.6, layout = &quot;autofit&quot;) %&gt;% set_caption(&quot;Levene&#39;s Test for Homogeneity of Variance&quot;) .cl-5c06b734{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5c06b735{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5c06ddc2{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5c070504{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c070505{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c070506{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c070507{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c070508{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c070509{width:54px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.13: Levenes Test for Homogeneity of Variance termdfstatisticp.valuegroup20.52340380.594354287NANA Huzzah - it worked! Before we continue on, we should backtrack and re-test the outliers and normality conditions. However, because the point of this section is to try Welchs ANOVA, Im going use it instead of transforming the response variable. Use oneway.test(..., var.equal = FALSE) to run a Welchs ANOVA. newton_anova &lt;- oneway.test(newtons ~ step, data = newton, var.equal = FALSE) newton_anova ## ## One-way analysis of means (not assuming equal variances) ## ## data: newtons and step ## F = 26.19, num df = 2.000, denom df = 56.184, p-value = 9.196e-09 Welchs ANOVA indicates amount of force was statistically significantly different for different steps, F(2, 56.2) = 26.2, p &lt; .0001. I dont think you can calculate \\(\\omega^2\\) for a Welchs ANOVA object. 3.6.2.2 Games-Howell Post Hoc Test Use the PMCMRplus::gamesHowellTest() to run the Games-Howell post hoc test. As expected, the three steps differ from each other. newton_games_howell &lt;- rstatix::games_howell_test(newton, newtons ~ step) newton_games_howell %&gt;% flextable() %&gt;% autofit() %&gt;% set_caption(&quot;Games-Howell Post Hoc Test&quot;) .cl-5c3b714a{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-5c3b9864{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5c3b9865{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-5c3bc46a{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc46b{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc46c{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc46d{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc46e{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc46f{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc470{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc471{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc472{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc473{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3bc474{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb7a{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb7b{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb7c{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb7d{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb7e{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb7f{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb80{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb81{width:62px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb82{width:66px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb83{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3beb84{width:55px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3c12bc{width:64px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5c3c12bd{width:73px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.14: Games-Howell Post Hoc Test .y.group1group2estimateconf.lowconf.highp.adjp.adj.signifnewtonsAB97.6486739.73284155.56454.41e-04***newtonsAC219.74333144.72971294.75701.62e-08****newtonsBC122.0946745.08372199.10561.00e-03*** 3.6.2.3 Reporting a Welchs ANOVA A Welchs ANOVA was conducted to determine if force was different for different steps. Measurements were classified into three groups: A (n = 30), B (n = 30), and C (n = 30). There was a single outlier, as assessed by boxplot, and was retained because it did not change the conclusions; data was normally distributed for each group, as assessed by Q-Q plot. ; Homogeneity of variances was violated, as assessed by Levenes Test of Homogeneity of Variance (p = 0.022). Data is presented as mean \\(\\pm\\) standard deviation. Force was statistically significantly different between different steps, F(2, 56.1842568) = 26.19, p &lt; .0005. Force increased from A (429.1793333 \\(\\pm\\) 88.66137), to B (526.828 \\(\\pm\\) 97.6), to C (648.9226667 \\(\\pm\\) 144.9). Games-Howell post hoc analysis revealed statistically significant increases from A to B, (97.6, 95% CI (39.7 to 39.7), p = 4e-04), A to C (219.7, 95% CI (144.7 to 144.7), p = 2e-08), and B to C (122.1, 95% CI (45.1 to 45.1), p = 0.001). 3.6.3 MANOVA Multi-factor ANOVA (MANOVA) is a method to compare mean responses by treatment factor level of two or more treatments applied in combination. The null hypotheses are \\(H_0: \\mu_{1.} = \\mu_{2.} = \\dots = \\mu_{a.}\\) for the \\(a\\) levels of factor 1, \\(H_0: \\mu_{.1} = \\mu_{.2} = \\dots = \\mu_{.b}\\) for the \\(b\\) levels of factor 2, etc. for all the factors in the experiment, and $H_0: $ no interaction for all the factor interactions. There are two equivalent ways to state the MANOVA model: \\[Y_{ijk} = \\mu_{ij} + \\epsilon_{ijk}\\] In this notation \\(Y_{ijk}\\) refers to the \\(k^{th}\\) observation in the \\(j^{th}\\) level of factor two and the \\(i^{th}\\) level of factor 1. Potentially there could be additional factors. This model formulation decomposes the response into a cell mean and an error term. The second makes the factor effect more explicit and is thus more common: \\[Y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\epsilon_{ijk}\\] 3.6.4 Multiple Variance Comparison F Test 3.6.5 Example A study investigates the relationship between oxygen update and two explanatory variables: smoking, and type of stress test. A sample of \\(n = 27\\) persons, 9 non-smoking, 9 moderately-smoking, and 9 heavy-smoking are divided into three stress tests, bicycle, treadmill, and steps and their oxygen uptake was measured. Is oxygen uptake related to smoking status and type of stress test? Is there an interaction effect between smoking status and type of stress test? library(dplyr) library(ggplot2) library(nortest) # for Anderson-Darling test library(stats) # for anova smoker &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3) stress &lt;- c(1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3) oxytime &lt;- c(12.8, 13.5, 11.2, 16.2, 18.1, 17.8, 22.6, 19.3, 18.9, 10.9, 11.1, 9.8, 15.5, 13.8, 16.2, 20.1, 21.0, 15.9, 8.7, 9.2, 7.5, 14.7, 13.2, 8.1, 16.2, 16.1, 17.8) oxy &lt;- data.frame(oxytime, smoker, stress) oxy$smoker &lt;- ordered(oxy$smoker, levels = c(1, 2, 3), labels = c(&quot;non-smoker&quot;, &quot;moderate&quot;, &quot;heavy&quot;)) oxy$stress &lt;- factor(oxy$stress, labels = c(&quot;bicycle&quot;, &quot;treadmill&quot;, &quot;steps&quot;)) lm_oxy &lt;- lm(oxytime~smoker+stress+smoker*stress, data = oxy) anova(lm_oxy) ## Analysis of Variance Table ## ## Response: oxytime ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## smoker 2 84.899 42.449 12.8967 0.0003348 *** ## stress 2 298.072 149.036 45.2793 9.473e-08 *** ## smoker:stress 4 2.815 0.704 0.2138 0.9273412 ## Residuals 18 59.247 3.291 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 SFU BIO710 3.6.6 Repeated Measures 3.6.7 Two-Way 3.6.8 Randomized Blocks 3.6.9 ANCOVA 3.7 KruskalWallis Test 3.8 pairwise.prop.test library(tidyverse) M &lt;- 3573 F &lt;- 4177 dat &lt;- tribble( ~gender, ~src, ~Y, ~N, &quot;Male&quot;, &quot;Indeed&quot;, 1699, M-1699, &quot;Male&quot;, &quot;LinkedIn&quot;, 1755, M-1755, &quot;Male&quot;, &quot;Google&quot;, 1578, M-1578, &quot;Female&quot;, &quot;Indeed&quot;, 2554, F-2554, &quot;Female&quot;, &quot;LinkedIn&quot;, 1914, F-1914, &quot;Female&quot;, &quot;Google&quot;, 1694, F-1694 ) prop.test(x = dat$Y, n = dat$Y + dat$N) ## ## 6-sample test for equality of proportions without continuity ## correction ## ## data: dat$Y out of dat$Y + dat$N ## X-squared = 412.66, df = 5, p-value &lt; 2.2e-16 ## alternative hypothesis: two.sided ## sample estimates: ## prop 1 prop 2 prop 3 prop 4 prop 5 prop 6 ## 0.4755108 0.4911839 0.4416457 0.6114436 0.4582236 0.4055542 pairwise.prop.test(x = dat$Y, n = dat$Y + dat$N) ## ## Pairwise comparisons using Pairwise comparison of proportions ## ## data: dat$Y out of dat$Y + dat$N ## ## 1 2 3 4 5 ## 2 0.40250 - - - - ## 3 0.02026 0.00021 - - - ## 4 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - - ## 5 0.40250 0.02026 0.40250 &lt; 2e-16 - ## 6 6.3e-09 4.8e-13 0.00873 &lt; 2e-16 1.1e-05 ## ## P value adjustment method: holm "],["association.html", "Chapter 4 Association 4.1 Pearson 4.2 Chi-Square 4.3 Spearman 4.4 Pearsons Correlation for Numeric Vars 4.5 Spearmans Ranked Correlation for Numeric Vars 4.6 Pearsons Correlation for Categorical Vars 4.7 Spearmans Ranked Correlation for Categorical Vars", " Chapter 4 Association 4.1 Pearson 4.2 Chi-Square 4.3 Spearman 4.4 Pearsons Correlation for Numeric Vars 4.5 Spearmans Ranked Correlation for Numeric Vars 4.6 Pearsons Correlation for Categorical Vars 4.7 Spearmans Ranked Correlation for Categorical Vars "],["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],["generalized-linear-models-glm.html", "Chapter 6 Generalized Linear Models (GLM) 6.1 Logistic Regression 6.2 Multinomial Logistic Regression 6.3 Ordinal Logistic Regression 6.4 Poisson Regression", " Chapter 6 Generalized Linear Models (GLM) These notes are primarily from PSUs Analysis of Discrete Data which uses Alan Agrestis Categorical Data Analysis (Agresti 2013). I also reviewed PSUs Regression Methods, DataCamps Generalized Linear Models in R, DataCamps Multiple and Logistic Regression, and Interpretable machine learning (Molnar 2020). The linear regression model, \\(E(y|X) = X \\beta\\), structured as \\(y_i = X_i \\beta + \\epsilon_i\\) where \\(X_i \\beta = \\mu_i\\), assumes the response is a linear function of the predictors and the residuals are independent random variables normally distributed with zero mean and constant variance, \\(\\epsilon \\sim N \\left(0, \\sigma^2 \\right)\\). This implies that given a set of predictors, the response is normally distributed about its expected value, \\(y_i \\sim N \\left(\\mu_i, \\sigma^2 \\right)\\). However, there are many situations where this normality assumption does not hold. Generalized linear models (GLMs) are a generalization of the linear regression model that addresses non-normal response distributions. The response will not have a normal distribution if the underlying data-generating process is binomial or multinomial (proportions), Poisson (counts), or exponential (time-to-event). In these situations the linear regression model can predict proportions outside [0, 100] or negative counts and times. GLMs solve this problem by modeling a function of the expected value of \\(y\\), \\(f(E(y|X)) = X \\beta\\). There are three components to a GLM: the random component is the probability distribution of the response variable (normal, binomial, Poisson, etc.); the systematic component is the explanatory variables \\(X\\beta\\); and the link function \\(\\eta\\) specifies the link between random and systematic components, converting the response range to \\([-\\infty, +\\infty]\\). Linear regression is thus a special case of GLM where link function is the identity function, \\(f(E(y|X)) = E(y|X)\\). For logistic regression, where the data generating process is binomial, the link function is \\[f(E(y|X)) = \\ln \\left( \\frac{E(y|X)}{1 - E(y|X)} \\right) = \\ln \\left( \\frac{\\pi}{1 - \\pi} \\right) = logit(\\pi)\\] where \\(\\pi\\) is the event probability.3 For Poisson regression, the link function is \\[f(E(y|X)) = \\ln (E(y|X)) = \\ln(\\lambda)\\] where \\(\\lambda\\) is the expected event rate. For exponential regression, the link function is \\[f(E(y|X) = -E(y|X) = -\\lambda\\] where \\(\\lambda\\) is the expected time to event. GLM uses maximum likelihood estimation (MLE) rather than ordinary least squares (OLS) to estimate the parameters, and thus relies on large-sample approximations. In R, specify a GLM just like an linear model, but with the glm() function, specifying the distribution with the family parameter. family = \"gaussian\": linear regression family = \"binomial\": logistic regression family = binomial(link = \"probit\"): probit regression family = \"poisson\": Poisson regression 6.1 Logistic Regression Logistic regression estimates the probability of a particular level of a categorical response variable given a set of predictors. The response levels can be binary, nominal, or ordinal. The binary logistic regression model is \\[y = logit(\\pi) = \\ln \\left( \\frac{\\pi}{1 - \\pi} \\right) = X \\beta\\] where \\(\\pi\\) is the event probability. The model predicts the log odds of the response variable. The maximum likelihood estimator maximizes the likelihood function \\[L(\\beta; y, X) = \\prod_{i=1}^n \\pi_i^{y_i}(1 - \\pi_i)^{(1-y_i)} = \\prod_{i=1}^n\\frac{\\exp(y_i X_i \\beta)}{1 + \\exp(X_i \\beta)}.\\] There is no closed-form solution, so GLM estimates coefficients with interatively reweighted least squares. Here is a case study to illustrate the points. Dataset donner contains observations of 45 members of the Donner party with response variable (surv) an explanatory variables age and sex. glimpse(donner) ## Rows: 45 ## Columns: 3 ## $ age &lt;dbl&gt; 23, 40, 40, 30, 28, 40, 45, 62, 65, 45, 25, 28, 28, 23, 22, 23... ## $ sex &lt;fct&gt; M, F, M, M, M, M, F, M, M, F, F, M, M, M, F, F, M, F, F, M, F,... ## $ surv &lt;fct&gt; Died, Lived, Lived, Died, Died, Died, Died, Died, Died, Died, ... donner %&gt;% ggplot(aes(x = age, y = as.integer(surv)-1, color = sex)) + geom_jitter(height = 0, alpha = 0.6) + geom_smooth(aes(y = as.integer(surv) - 1), method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), formula = &quot;y ~ x&quot;) + scale_y_continuous(breaks = c(0,1), labels = c(&quot;Died&quot;, &quot;Lived&quot;)) + labs(title = &quot;Donner Party Survivorship&quot;, color = NULL, y = NULL) + theme_minimal() + theme(legend.position = &quot;top&quot;) Fit a logistic regression \\(surv = sex + age + sex:age\\). m &lt;- glm(surv ~ sex*age, data = donner, family = binomial(link = logit)) summary(m) ## ## Call: ## glm(formula = surv ~ sex * age, family = binomial(link = logit), ## data = donner) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.2279 -0.9388 -0.5550 0.7794 1.6998 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 7.24638 3.20517 2.261 0.0238 * ## sexM -6.92805 3.39887 -2.038 0.0415 * ## age -0.19407 0.08742 -2.220 0.0264 * ## sexM:age 0.16160 0.09426 1.714 0.0865 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 61.827 on 44 degrees of freedom ## Residual deviance: 47.346 on 41 degrees of freedom ## AIC: 55.346 ## ## Number of Fisher Scoring iterations: 5 The z value in the Coefficients table is the Wald z statistic, \\(z = \\hat{\\beta} / SE(\\hat{\\beta})\\), which if squared is the Wald chi-squared statistic, \\(z^2\\). The p.value is the area to the right of \\(z^2\\) in the \\(\\chi_1^2\\) density curve: m %&gt;% tidy() %&gt;% mutate( z = estimate / std.error, p_z2 = pchisq(z^2, df = 1, lower.tail = FALSE) ) ## # A tibble: 4 x 7 ## term estimate std.error statistic p.value z p_z2 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.25 3.21 2.26 0.0238 2.26 0.0238 ## 2 sexM -6.93 3.40 -2.04 0.0415 -2.04 0.0415 ## 3 age -0.194 0.0874 -2.22 0.0264 -2.22 0.0264 ## 4 sexM:age 0.162 0.0943 1.71 0.0865 1.71 0.0865 Below the Coefficients table, the dispersion parameter refers to overdispersion, a common issue with GLM. For a logistic regression, the response variable should be distributed \\(y_i \\sim Bin(n_i, \\pi_i)\\) with \\(\\mu_i = n_i \\pi_i\\) and \\(\\sigma^2 = \\pi (1 - \\pi)\\). Overdispersion means the data shows evidence of variance greater than \\(\\sigma^2\\). Fisher scoring is a method for ML estimation. Logistic regression uses an iterative procedure to fit the model, so this section indicates whether the algorithm converged. The null deviance is the likelihood ratio \\(G^2 = 61.827\\) of the intercept-only model. The residual deviance is the likelihood ratio \\(G^2 = 47.346\\) after including all model covariates. \\(G^2\\) is large, so reject the null hypothesis of no age and sex effects. The ANOVA table shows the change in deviance from adding each variable successively to the model. anova(m) ## Analysis of Deviance Table ## ## Model: binomial, link: logit ## ## Response: surv ## ## Terms added sequentially (first to last) ## ## ## Df Deviance Resid. Df Resid. Dev ## NULL 44 61.827 ## sex 1 4.5403 43 57.286 ## age 1 6.0300 42 51.256 ## sex:age 1 3.9099 41 47.346 glance(m) ## # A tibble: 1 x 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 61.8 44 -23.7 55.3 62.6 47.3 41 45 Plug in values to interpret the model. The log odds of a 24 year-old female surviving is \\(\\hat{y} = 2.59\\). The log odds of a 24 year-old male surviving is \\(\\hat{y} = -0.46\\). coef(m)[&quot;(Intercept)&quot;] + coef(m)[&quot;sexM&quot;]*0 + coef(m)[&quot;age&quot;]*24 + coef(m)[&quot;sexM:age&quot;]*0*24 coef(m)[&quot;(Intercept)&quot;] + coef(m)[&quot;sexM&quot;]*1 + coef(m)[&quot;age&quot;]*24 + coef(m)[&quot;sexM:age&quot;]*1*24 # Or use predict() (lo_f &lt;- predict(m, newdata = data.frame(sex = &quot;F&quot;, age = 24))) (lo_m &lt;- predict(m, newdata = data.frame(sex = &quot;M&quot;, age = 24))) Log odds are not easy to interpet. Exponentiate the log odds to get the odds. \\[odds(\\hat{y}) = \\exp (\\hat{y}) = \\frac{\\pi}{1 - \\pi}.\\] The odds of a 24 year-old female surviving is \\(\\exp(\\hat{y}) = 13.31\\). The odds of a 24 year-old male surviving is \\(\\exp(\\hat{y}) = 0.63\\). exp(lo_f) exp(lo_m) Solve for \\(\\pi\\) to get the probability. \\[\\pi = \\frac{\\exp (\\hat{y})}{1 + \\exp (\\hat{y})}\\] The probability of a 24 year-old female surviving is \\(\\pi = 0.93\\). The probability of a female of average age surviving is \\(\\pi = 0.39\\). The predict() function for a logistic model returns log-odds, but can also return \\(\\pi\\) by specifying parameter type = \"response\". exp(lo_f) / (1 + exp(lo_f)) exp(lo_m) / (1 + exp(lo_m)) # Or use predict(..., type = &quot;response&quot;) (p_f &lt;- predict(m, newdata = data.frame(sex = &quot;F&quot;, age =24), type = &quot;response&quot;)) (p_m &lt;- predict(m, newdata = data.frame(sex = &quot;M&quot;, age =24), type = &quot;response&quot;)) Interpret the coefficient estimates using the odds ratio, the ratio of the odds before and after an increment to the predictors. The odds ratio is how much the odds would be multiplied after a \\(\\delta = X_1 - X_0\\) unit increase in \\(X\\). \\[\\theta = \\frac{\\pi / (1 - \\pi) |_{X = X_1}}{\\pi / (1 - \\pi) |_{X = X_0}} = \\frac{\\exp (X_1 \\hat{\\beta})}{\\exp (X_0 \\hat{\\beta})} = \\exp ((X_1-X_0) \\hat{\\beta}) = \\exp (\\delta \\hat{\\beta})\\] The odds of a female surviving are multiplied by a factor of \\(\\exp(1 \\cdot (-0.19)) = 0.824\\) per additional year of age (or the odds fall by \\(1 - 0.824 = 17.6\\%\\)). The odds of a male surviving are multiplied by a factor of \\(\\exp(1 \\cdot (-0.161-0.19)) = 0.968\\) per additional year of age. exp(1 * (coef(m)[&quot;age&quot;] + 0*coef(m)[&quot;sexM:age&quot;])) # female exp(1 * (coef(m)[&quot;age&quot;] + 1*coef(m)[&quot;sexM:age&quot;])) # male oddsratio::or_glm() calculates the odds ratio from an increment in the predictor values. oddsratio::or_glm(donner, m, incr = list(age = 1)) ## predictor oddsratio ci_low (2.5) ci_high (97.5) increment ## 1 sexM 0.001 0.000 0.243 Indicator variable ## 2 age 0.824 0.652 0.945 1 ## 3 sexM:age 1.175 1.001 1.496 Indicator variable The predicted values can also be expressed as the probabilities \\(\\pi\\). This produces the familiar signmoidal shape of the binary relationship. augment(m, type.predict = &quot;response&quot;) %&gt;% ggplot(aes(x = age)) + geom_point(aes(y = surv)) + geom_line(aes(y = .fitted+1)) + labs(x = &quot;AGE&quot;, y = &quot;Probability of SURVIVE&quot;, title = &quot;Binary Fitted Line Plot&quot;) Evaluate a logistic regression using a Gain curve or ROC curve. In the gain curve, the x-axis is the fraction of items seen when sorted by the predicted value, and the y-axis is the cumulative summed true outcome. The wizard curve is the gain curve when the data is sorted by the true outcome. If the models gain curve is close to the wizard curve, then the model predicted the response variable well. The grey area is the gain over a random prediction. 20 of the 45 members of the Donner party survived. The gain curve encountered 10 survivors (50%) within the first 12 observations (27%). It encountered all 20 survivors on the 37th observation. The bottom of the grey area is the outcome of a random model. Only half the survivors would be observed within 50% of the observations. The top of the grey area is the outcome of the perfect model, the wizard curve. Half the survivors would be observed in 10/45=22% of the observations. options(yardstick.event_first = FALSE) # set the second level as success augment(m, type.predict = &quot;response&quot;) %&gt;% yardstick::gain_curve(surv, .fitted) %&gt;% autoplot() + labs(title = &quot;Gain Curve&quot;) ## Warning: The `yardstick.event_first` option has been deprecated as of yardstick 0.0.7 and will be completely ignored in a future version. ## Instead, set the following argument directly in the metric function: ## `options(yardstick.event_first = TRUE)` -&gt; `event_level = &#39;first&#39;` (the default) ## `options(yardstick.event_first = FALSE)` -&gt; `event_level = &#39;second&#39;` ## This warning is displayed once per session. The ROC (Receiver Operating Characteristics) curve plots sensitivity vs specificity at different cut-off values for the probability, ranging cut-off from 0 to 1. options(yardstick.event_first = FALSE) # set the second level as success augment(m, type.predict = &quot;response&quot;) %&gt;% yardstick::roc_curve(surv, .fitted) %&gt;% autoplot() + labs(title = &quot;ROC Curve&quot;) 6.2 Multinomial Logistic Regression The following notes rely on the [PSU STAT 504 course notes](https://online.stat.psu.edu/stat504/node/171/. Multinomial logistic regression models the odds the multinomial response variable \\(Y \\sim Mult(n, \\pi)\\) is in level \\(j\\) relative to baseline category \\(j^*\\) for all pairs of categories as a function of \\(k\\) explanatory variables, \\(X = (X_1, X_2, ... X_k)\\). \\[\\log \\left( \\frac{\\pi_{ij}}{\\pi_{ij^*}} \\right) = x_i^T \\beta_j, \\hspace{5mm} j \\ne j^2\\] Interpet the \\(k^{th}\\) element of \\(\\beta_j\\) as the increase in log-odds of falling a response in category \\(j\\) relative to category \\(j^*\\) resulting from a one-unit increase in the \\(k^{th}\\) predictor term, holding the other terms constant. Multinomial model is a type of GLM. Here is an example using multinomial logistic regression. A researcher classified the stomach contents of \\(n = 219\\) alligators according to \\(r = 5\\) categories (fish, Inv., Rept, Bird, Other) as a function of covariates Lake, Sex, and Size.. gator_dat &lt;- tribble( ~profile, ~Gender, ~Size, ~Lake, ~Fish, ~Invertebrate, ~Reptile, ~Bird, ~Other, &quot;1&quot;, &quot;f&quot;, &quot;&lt;2.3&quot;, &quot;george&quot;, 3, 9, 1, 0, 1, &quot;2&quot;, &quot;m&quot;, &quot;&lt;2.3&quot;, &quot;george&quot;, 13, 10, 0, 2, 2, &quot;3&quot;, &quot;f&quot;, &quot;&gt;2.3&quot;, &quot;george&quot;, 8, 1, 0, 0, 1, &quot;4&quot;, &quot;m&quot;, &quot;&gt;2.3&quot;, &quot;george&quot;, 9, 0, 0, 1, 2, &quot;5&quot;, &quot;f&quot;, &quot;&lt;2.3&quot;, &quot;hancock&quot;, 16, 3, 2, 2, 3, &quot;6&quot;, &quot;m&quot;, &quot;&lt;2.3&quot;, &quot;hancock&quot;, 7, 1, 0, 0, 5, &quot;7&quot;, &quot;f&quot;, &quot;&gt;2.3&quot;, &quot;hancock&quot;, 3, 0, 1, 2, 3, &quot;8&quot;, &quot;m&quot;, &quot;&gt;2.3&quot;, &quot;hancock&quot;, 4, 0, 0, 1, 2, &quot;9&quot;, &quot;f&quot;, &quot;&lt;2.3&quot;, &quot;oklawaha&quot;, 3, 9, 1, 0, 2, &quot;10&quot;, &quot;m&quot;, &quot;&lt;2.3&quot;, &quot;oklawaha&quot;, 2, 2, 0, 0, 1, &quot;11&quot;, &quot;f&quot;, &quot;&gt;2.3&quot;, &quot;oklawaha&quot;, 0, 1, 0, 1, 0, &quot;12&quot;, &quot;m&quot;, &quot;&gt;2.3&quot;, &quot;oklawaha&quot;, 13, 7, 6, 0, 0, &quot;13&quot;, &quot;f&quot;, &quot;&lt;2.3&quot;, &quot;trafford&quot;, 2, 4, 1, 1, 4, &quot;14&quot;, &quot;m&quot;, &quot;&lt;2.3&quot;, &quot;trafford&quot;, 3, 7, 1, 0, 1, &quot;15&quot;, &quot;f&quot;, &quot;&gt;2.3&quot;, &quot;trafford&quot;, 0, 1, 0, 0, 0, &quot;16&quot;, &quot;m&quot;, &quot;&gt;2.3&quot;, &quot;trafford&quot;, 8, 6, 6, 3, 5 ) gator_dat &lt;- gator_dat %&gt;% mutate( Gender = as_factor(Gender), Lake = fct_relevel(Lake, &quot;hancock&quot;), Size = as_factor(Size) ) There are 4 equations to estimate: \\[\\log \\left( \\frac{\\pi_j} {\\pi_{j^*}} \\right) = \\beta X\\] where \\(\\pi_{j^*}\\) is the probability of fish, the baseline category. Run a multivariate logistic regression model with VGAM::vglm(). library(VGAM) vglm() fits 4 logit models. gator_vglm &lt;- vglm( cbind(Bird,Invertebrate,Reptile,Other,Fish) ~ Lake + Size + Gender, data = gator_dat, family = multinomial ) summary(gator_vglm) ## ## Call: ## vglm(formula = cbind(Bird, Invertebrate, Reptile, Other, Fish) ~ ## Lake + Size + Gender, family = multinomial, data = gator_dat) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept):1 -1.8568 0.5813 -3.195 0.001400 ** ## (Intercept):2 -1.6115 0.5508 -2.926 0.003435 ** ## (Intercept):3 -2.2866 0.6566 -3.483 0.000497 *** ## (Intercept):4 -0.6642 0.3802 -1.747 0.080639 . ## Lakegeorge:1 -0.5753 0.7952 -0.723 0.469429 ## Lakegeorge:2 1.7805 0.6232 2.857 0.004277 ** ## Lakegeorge:3 -1.1295 1.1928 -0.947 0.343687 ## Lakegeorge:4 -0.7666 0.5686 -1.348 0.177563 ## Lakeoklawaha:1 -1.1256 1.1923 -0.944 0.345132 ## Lakeoklawaha:2 2.6937 0.6693 4.025 5.70e-05 *** ## Lakeoklawaha:3 1.4008 0.8105 1.728 0.083926 . ## Lakeoklawaha:4 -0.7405 0.7421 -0.998 0.318372 ## Laketrafford:1 0.6617 0.8461 0.782 0.434145 ## Laketrafford:2 2.9363 0.6874 4.272 1.94e-05 *** ## Laketrafford:3 1.9316 0.8253 2.340 0.019263 * ## Laketrafford:4 0.7912 0.5879 1.346 0.178400 ## Size&gt;2.3:1 0.7302 0.6523 1.120 0.262918 ## Size&gt;2.3:2 -1.3363 0.4112 -3.250 0.001155 ** ## Size&gt;2.3:3 0.5570 0.6466 0.861 0.388977 ## Size&gt;2.3:4 -0.2906 0.4599 -0.632 0.527515 ## Genderm:1 -0.6064 0.6888 -0.880 0.378666 ## Genderm:2 -0.4630 0.3955 -1.171 0.241796 ## Genderm:3 -0.6276 0.6853 -0.916 0.359785 ## Genderm:4 -0.2526 0.4663 -0.542 0.588100 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Names of linear predictors: log(mu[,1]/mu[,5]), log(mu[,2]/mu[,5]), ## log(mu[,3]/mu[,5]), log(mu[,4]/mu[,5]) ## ## Residual deviance: 50.2637 on 40 degrees of freedom ## ## Log-likelihood: -73.3221 on 40 degrees of freedom ## ## Number of Fisher scoring iterations: 5 ## ## No Hauck-Donner effect found in any of the estimates ## ## ## Reference group is level 5 of the response The residual deviance is 50.2637 on 40 degrees of freedom. Residual deviance tests the current model fit versus the saturated model. The saturated model, which fits a separate multinomial distribution to each of the 16 profiles (unique combinations of lake, sex and size), has 16  4 = 64 parameters. The current model has an intercept, three lake coefficients, one sex coefficient and one size coefficient for each of the four logit equations, for a total of 24 parameters. Therefore, the overall fit statistics have 64  24 = 40 degrees of freedom. # E &lt;- data.frame(fitted(gator_vglm) * rowSums(gator_dat[, 5:9])) # O &lt;- gator_dat %&gt;% select(Bird, Invertebrate, Reptile, Other, Fish) + .000001 # (g2 &lt;- 2 * sum(O * log(O / E))) indicates the model fits okay, but not great. The Residual Deviance of 50.26 with 40 df from the table above output is reasonable, with p-value of 0.1282 and the statistics/df is close to 1 that is 1.256. 6.3 Ordinal Logistic Regression Ordinal logistic regression, also call cumulative link model (CLM), is a generalized linear model (GZLM), an extension of the general linear model (GLM) to non-continuous outcome variables. There are many approaches to ordinal logistic regression, including cumulative, adjacent, and continuation categories, but the most popular is the cumulative odds ordinal logistic regression with proportional odds. These notes rely on UVA, PSU, Laerd, and the CLM package article vignette. The model for ordinal response random variable \\(Y_i\\) with \\(J\\) levels is \\[\\gamma_{ij} = F(\\eta_{ij}), \\hspace{5 mm} \\eta_{ij} = \\theta_j - x_i^\\mathrm{T}\\beta, \\hspace{5 mm} i = 1, \\ldots, n, \\hspace{5 mm} j = 1, \\ldots, J-1\\] where \\(\\gamma_{ij} = P(Y_i \\le j) = \\pi_{i1} + \\cdots + \\pi_{ij}\\). \\(\\eta_{ij}\\) is a linear predictor with \\(J-1\\) intercepts. \\(F\\) is the inverse link function. The regression models the logit link function of \\(\\gamma_{ij}\\). \\[\\mathrm{logit}(\\gamma_{ij}) = \\log \\left[\\frac{P(Y_i \\le j)}{P(Y_i \\gt j)} \\right] = \\theta_j - x_i^\\mathrm{T}\\beta\\] The cumulative logit is the log-odds of the cumulative probabilities that the response is in category \\(\\le j\\) versus \\(\\gt j\\). \\(\\theta_j\\) is the log-odds when \\(x_i^\\mathrm{T}=0\\) and \\(\\beta\\) is the increase in the log odds attributed to a one unit increase in \\(x_i^\\mathrm{T}=0\\). Notice \\(\\beta\\) is the same for all \\(j\\). Once you fit the model, you will either generate predicted values or evaluate the coefficient estimators. The predicted value is a log-odds by default (useless), so you will at least take exponential to get the odds. From there you can solve for the probability, \\[P(Y_i \\gt j) = \\frac{\\mathrm{exp}(\\hat{y}_i)}{1 + \\mathrm{exp}(\\hat{y}_i)}.\\] The exponential of \\(\\beta\\) is the odds ratio of \\(x_1^\\mathrm{T} - x_0^\\mathrm{T}\\). You can solve for the odds ratio \\[\\mathrm{OR} = \\frac{\\mathrm{exp}(\\theta_j - x_1^\\mathrm{T}\\beta)}{\\mathrm{exp}(\\theta_j - x_2^\\mathrm{T}\\beta)} = \\mathrm{exp}(\\beta(x_1^\\mathrm{T} - x_0^\\mathrm{T}))\\] If \\(x\\) is a binary factor factor, then \\(exp(\\beta)\\) is the odds ratio of \\(x=1\\) vs \\(x=0\\). Thus the odds-ratio is proportional to the difference between values of \\(x\\) and \\(\\beta\\) is the constant of proportionality. The model is estimated with a regularized Newton-Raphson algorithm with step-halving (line search) using analytic expressions for the gradient and Hessian of the negative log-likelihood function. What this means is beyond me right now, but the upshot is that the estimation is an iterative maximization exercise, not a formulaic matrix algebra process. It is possible for the model estimation to fail to converge on a maximum. You will sometimes encounter discussion about the latent variable. That is just the underlying quality you are trying to measure. If you rate something a 4 on a 5-level likert scale, 4 is the expression of your valuation, the latent variable. Your precise valuation is somewhere between 3 and 5 on a continuous scale. The link function defines the distribution of the latent variable. There are variations on the ordinal model. Structured thresholds impose restrictions on \\(\\theta_j\\), for example requiring equal distances between levels. Partial proportional odds allow \\(\\theta_j\\) to vary with nominal predictors. You can also use link functions other than logit. There are two conditions to ordinal logistic regression: (a) no multicollinearity, and (b) proportional odds. Case Study 192 participants in a study respond to the statement Taxes are too high on a 4-level likert scale (tax_too_high, Strongly Disagree, Disagree, Agree, Strongly Agree). Participant attributes include business owner (biz_owner, Y|N), age (age), and political affiliation (politics, Liberal, Conservative, Labor). tax$gt &lt;- tbl_summary( tax$dat %&gt;% select(-age), by = politics, statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;) ) tax$gt html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #lqcdyonvuz .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lqcdyonvuz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lqcdyonvuz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lqcdyonvuz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #lqcdyonvuz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lqcdyonvuz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lqcdyonvuz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lqcdyonvuz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lqcdyonvuz .gt_column_spanner_outer:first-child { padding-left: 0; } #lqcdyonvuz .gt_column_spanner_outer:last-child { padding-right: 0; } #lqcdyonvuz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #lqcdyonvuz .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #lqcdyonvuz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lqcdyonvuz .gt_from_md > :first-child { margin-top: 0; } #lqcdyonvuz .gt_from_md > :last-child { margin-bottom: 0; } #lqcdyonvuz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lqcdyonvuz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #lqcdyonvuz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lqcdyonvuz .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #lqcdyonvuz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lqcdyonvuz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lqcdyonvuz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lqcdyonvuz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lqcdyonvuz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lqcdyonvuz .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #lqcdyonvuz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lqcdyonvuz .gt_sourcenote { font-size: 90%; padding: 4px; } #lqcdyonvuz .gt_left { text-align: left; } #lqcdyonvuz .gt_center { text-align: center; } #lqcdyonvuz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lqcdyonvuz .gt_font_normal { font-weight: normal; } #lqcdyonvuz .gt_font_bold { font-weight: bold; } #lqcdyonvuz .gt_font_italic { font-style: italic; } #lqcdyonvuz .gt_super { font-size: 65%; } #lqcdyonvuz .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Lab, N = 621 Lib, N = 541 Con, N = 761 biz_owner 36 (58%) 26 (48%) 47 (62%) income 36 (8) 35 (6) 37 (7) tax_too_high Strongly Disagree 10 (16%) 10 (19%) 4 (5.3%) Disagree 13 (21%) 16 (30%) 9 (12%) Agree 28 (45%) 21 (39%) 42 (55%) Strongly Agree 11 (18%) 7 (13%) 21 (28%) 1 Statistics presented: n (%); Mean (SD) tax$dat %&gt;% mutate(income = case_when(income &lt; quantile(income, .25) ~ &quot;low income&quot;, income &lt; quantile(income, .75) ~ &quot;med income&quot;, TRUE ~ &quot;high income&quot;), income = factor(income, levels = c(&quot;low income&quot;, &quot;med income&quot;, &quot;high income&quot;))) %&gt;% count(tax_too_high, biz_owner, politics, income) %&gt;% ggplot(aes(x = tax_too_high, y = n, fill = biz_owner)) + geom_col(position = position_dodge2(preserve = &quot;single&quot;)) + facet_grid(rows = vars(income), cols = vars(politics), space = &quot;free&quot;) + scale_x_discrete(labels = function (x) str_wrap(x, width = 10)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) + labs(title = &quot;Taxes too high?&quot;, subtitle = &quot;Reponse count by business owner, income level, and party.&quot;) Fit a cumulative link model for the cumulative probability of the \\(i\\)th response falling in \\(j\\)th category or below where \\(i\\) indexes the (\\(n = 192\\)) responses, \\(j = 1, \\ldots, J\\) indexes the (\\(J = 4\\)) response categories, and \\(\\theta_j\\) is the threshold for the \\(j\\)th cumulative logit. \\[\\mathrm{logit}(P(Y_i \\le j)) = \\theta_j - \\beta_1(\\mathrm{politics}_i) - \\beta_2(\\mathrm{biz\\_owner}_i) - \\beta_3(\\mathrm{age}_i)\\] Fit the Model tax$fmla &lt;- formula(tax_too_high ~ biz_owner + age + politics) tax$clm &lt;- clm(tax$fmla, data = tax$dat) summary(tax$clm) ## formula: tax_too_high ~ biz_owner + age + politics ## data: tax$dat ## ## link threshold nobs logLik AIC niter max.grad cond.H ## logit flexible 192 -197.62 409.23 6(0) 3.14e-12 3.2e+05 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## biz_ownerYes 0.66462 0.28894 2.300 0.021435 * ## age 0.24189 0.03260 7.421 1.17e-13 *** ## politicsLib 0.03695 0.36366 0.102 0.919072 ## politicsCon 1.16142 0.34554 3.361 0.000776 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Threshold coefficients: ## Estimate Std. Error z value ## Strongly Disagree|Disagree 7.026 1.166 6.024 ## Disagree|Agree 8.766 1.231 7.119 ## Agree|Strongly Agree 11.653 1.357 8.590 The summary table shows two fit statistics at the top: the log-likelihood and the AIC. The log-likelihood is the sum of the likelihoods for each observation that the predicted value correctly predicts the observed value. Its value ranges from \\(-\\infty\\) to \\(+\\infty\\). Its value increases with observations, additional variables, and fit quality. I think you just use it to compare alternative model formulations. Akaike Information Criterion (AIC) is a measure of the relative quality of a statistical model. Again, I think the value is only useful as a comparison benchmark between alternative model fits. Youd want the model with the lowest AIC. The Coefficients table is the familiar parameter estimates. E.g., for biz_ownerYes, the coefficient estimate is 0.665 with standard error 0.289. The z-value is the ratio \\(z = \\hat{\\beta} / se =\\) 2.300 with p-value equal to \\(2 \\cdot P(Z&gt;z) =\\) 0.021. Some programs (e.g., SPSS) also show the Wald chi-squared statistic, the square of the z statistic, \\(z^2 =\\), 5.291. The square of a normal variable has a chi-square distribution, so the p value for the Wald chi-squared statistic is the pchisq(z^2, df = 1) \\(=\\) 0.021. The Threshold coefficients table are the intercepts, or cut-points. The first cut-point is log-odds of a response level Strongly Disagree (or less) vs greater than Strongly Disagree when all factor variables are at their reference level and the continuous vars are at 0. There may be interaction effects between biz_owner and politics. Fit a saturate model, then compare their log likelihoods with a likelihood ratio test. tax$fmla_sat &lt;- formula(tax_too_high ~ biz_owner*politics + age) tax$clm_sat &lt;- clm(tax$fmla_sat, data = tax$dat) tax$sat_anova &lt;- anova(tax$clm, tax$clm_sat) tax$sat_anova ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## tax$clm tax$fmla logit flexible ## tax$clm_sat tax$fmla_sat logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## tax$clm 7 409.23 -197.62 ## tax$clm_sat 9 411.75 -196.87 1.4805 2 0.477 The likelihood ratio test indicates the main-effects model fits about the same in comparison to the saturated model (\\(\\chi^2(\\) 2 $) = $ LR = 1.48, p = 0.477) Verify Assumptions Cumulative odds ordinal logistic regression with proportional odds models require a) no multicollinearity, and b) proportional odds. Multicollinearity Multicollinearity occurs when two or more independent variables are highly correlated so that they do not provide unique or independent information in the regression model. Multicollinearity inflates the variances of the estimated coefficients, resulting in larger confidence intervals. The usual interpretation of a slope coefficient as the change in the mean response per unit increase in the predictor when all the other predictors are held constant breaks down because changing one predictor necessarily changes other predictors. Test for multicollinearity with variance inflation factors (VIF). The VIF is the inflation percentage of the parameter variance due to multicollinearity. E.g., a VIF of 1.9 means the parameter variance is 90% larger than what it would be if it was not correlated with other predictors. Predictor \\(K\\)s variance, \\(Var(\\hat{\\beta_k})\\), is inflated by a factor of \\[VIF_k = \\frac{1}{1 - R_k^2}\\] due to collinearity with other predictors, where \\(R_k^2\\) is the \\(R^2\\) of a regression of the \\(k^{th}\\) predictor on the remaining predictors. If there is zero relationship between predictor \\(k\\) and the other variables, \\(R_k^2 = 0\\) and \\(VIF = 1\\) (no variance inflation). If 100% of the variance in predictor \\(k\\) is explained by the other predictors, then \\(R_k^2 = 1\\) and \\(VIF = \\infty\\). A good rule of thumb is that \\(VIF \\le 5\\) is acceptable. # Cannot use CLM model with vif(). Re-express as a linear model. tax$vif &lt;- lm(as.numeric(tax_too_high) ~ politics + biz_owner + age, dat = tax$dat) %&gt;% car::vif() tax$vif ## GVIF Df GVIF^(1/(2*Df)) ## politics 1.035831 2 1.008840 ## biz_owner 1.023642 1 1.011752 ## age 1.036491 1 1.018082 The VIFs in column GVIF are all below 5, so this model is not compromised by multicollinearity. Proportional Odds The assumption of proportional odds means the independent variable effects are constant across each cumulative split of the ordinal dependent variable. Test for proportional odds using a full likelihood ratio test comparing the proportional odds model with a multinomial logit model, also called an unconstrained baseline logit model. This is also called the test of parallel lines. The multinomial logit model fits a slope to each of the \\(J  1\\) levels. The proportional odds model is nested within the multinomial model, so you can use a likelihood ratio test to see if the models are statistically different. Fit the proportional odds model and a multinomial model using VGAM::vglm() and capture the log likelihoods and degrees of freedom. Perform a likelihood ratio test on the differences in log likelihoods, \\(D = -2 \\mathrm{loglik}(\\beta)\\). tax$vglm_ordinal &lt;- vglm(tax$fmla, propodds, data = tax$dat) tax$vglm_multinomial &lt;- vglm(tax$fmla, cumulative, data = tax$dat) tax$po_lrt &lt;- lrtest(tax$vglm_multinomial, tax$vglm_ordinal) tax$po_lrt ## Likelihood ratio test ## ## Model 1: tax_too_high ~ biz_owner + age + politics ## Model 2: tax_too_high ~ biz_owner + age + politics ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 561 -193.31 ## 2 569 -197.62 8 8.6197 0.3754 The assumption of proportional odds was met, as assessed by a full likelihood ratio test comparing the fit of the proportional odds model to a model with varying location parameters, \\(\\chi^2\\)(8) = 8.620, p = 0.375. Another option is the partial proportional odds test. This test locates specific variables causing the rejection of proportional odds. tax$po_lrt2 &lt;- clm(tax$fmla, data = tax$dat) %&gt;% nominal_test() tax$po_lrt2 ## Tests of nominal effects ## ## formula: tax_too_high ~ biz_owner + age + politics ## Df logLik AIC LRT Pr(&gt;Chi) ## &lt;none&gt; -197.62 409.23 ## biz_owner 2 -197.34 412.67 0.55974 0.7559 ## age ## politics 4 -196.20 414.40 2.83415 0.5860 The assumption of proportional odds was met, as assessed by a full likelihood ratio test comparing the fit of the proportional odds model to a model with varying location parameters for business owner, \\(\\chi^2\\)(2) = 0.560, p = 0.756 and politics, \\(\\chi^2\\)(4) = 2.834, p = 0.586. Assess the Model Fit There are three ways to assess overall model fit: The Deviance and Pearson goodness-of-fit tests of the overall model fit; the Cox and Snell, Nagelkerke, and McFadden pseudo R measures of explained variance; and the likelihood ratio test comparing the model fit to the intercept-only model. Deviance and Pearson However, these tests rely on large frequencies in each cell, that is, each possible combination of predictor values. Overall goodness-of-fit statistics should be treated with suspicion when a continuous independent variable is present and/or there are a large number of cells with zero frequency.The Pearson goodness-of-fit statistic is \\(X^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\) where \\(i\\) is the observation number and \\(j\\) is the response variable level. It is a summary of the Pearson residuals, the difference between the observed and expected cell counts, \\(O_{ij} - E_{ij}\\). The deviance goodness-of-fit statistic is the difference in fit between the model and a full model; a full model being a model that fits the data perfectly, \\(G^2 = 2 \\sum_{ij} O_{ij} \\log \\left( \\frac{O_{ij}}{E_{ij}} \\right)\\). Neither of these tests are reliable if there are many cells with zero frequencies and/or small expected frequencies and are generally not recommended. Generally, the chi-squared test requires a frequency count of at least 5 per cell. # Observed combinations of model vars tax$cell_patterns &lt;- tax$dat %&gt;% count(biz_owner, age, politics, tax_too_high) %&gt;% nrow() # Observed combinations of predictor vars * levels of response var tax$covariate_patterns &lt;- tax$dat %&gt;% count(biz_owner, age, politics) %&gt;% nrow() tax$possible_cells &lt;- tax$covariate_patterns * length(levels(tax$dat$tax_too_high)) # 1 - ratio of observed to possible tax$pct_freq_zero &lt;- 1 - tax$cell_patterns / tax$possible_cells There are 137 observed combinations of model variables (predictors), and 372 possible combinations (predictors * outcome levels), so 63.2% of cells have zero frequencies. Ideally, zero frequencies should be less than 20%, so if you were to use the deviance or Pearson tests, you would need to report this. The results below are contradictory and bogus. I think youd only use this test if you didnt have continuous predictor variables. observed &lt;- tax$dat %&gt;% count(biz_owner, age, politics, tax_too_high) %&gt;% pivot_wider(names_from = tax_too_high, values_from = n) %&gt;% replace_na(list(`Strongly Disagree` = 0, Disagree = 0, Agree = 0, `Strongly Agree` = 0)) %&gt;% pivot_longer(cols = `Strongly Disagree`:`Strongly Agree`, names_to = &quot;outcome&quot;, values_to = &quot;observed&quot;) expected &lt;- bind_cols( tax$dat, predict(tax$clm, subset(tax$dat, select = -tax_too_high))$fit %&gt;% data.frame() ) %&gt;% rename(c(&quot;Strongly Disagree&quot; = &quot;Strongly.Disagree&quot;, &quot;Strongly Agree&quot; = &quot;Strongly.Agree&quot;)) %&gt;% group_by(biz_owner, age, politics) %&gt;% summarize(.groups = &quot;drop&quot;, across(`Strongly Disagree`:`Strongly Agree`, sum)) %&gt;% pivot_longer(cols = `Strongly Disagree`:`Strongly Agree`, names_to = &quot;outcome&quot;, values_to = &quot;expected&quot;) obs_exp &lt;- observed %&gt;% inner_join(expected, by = c(&quot;politics&quot;, &quot;biz_owner&quot;, &quot;age&quot;, &quot;outcome&quot;)) %&gt;% mutate(epsilon_sq = (observed - expected)^2, chi_sq = epsilon_sq / expected, g_sq = 2 * observed * log((observed+.0001) / expected) ) tax$chisq &lt;- list() tax$chisq$X2 = sum(obs_exp$chi_sq) tax$chisq$G2 = sum(obs_exp$g_sq) tax$chisq$df = tax$covariate_patterns * (length(levels(tax$dat$tax_too_high)) - 1) - 7 tax$chisq$X2_p.value = pchisq(tax$chisq$X2, df = tax$chisq$df, lower.tail = FALSE) tax$chisq$G2_p.value = pchisq(tax$chisq$G2, df = tax$chisq$df, lower.tail = FALSE) The Pearson goodness-of-fit test indicated that the model was not a good fit to the observed data, \\(\\chi^2\\)(272) = 745.4, p &lt; .001$. The deviance goodness-of-fit test indicated that the model was a good fit to the observed data, \\(G^2\\)(272) = 232.6, p = 0.960. Pseudo-R2 Measures There are a number of measures in ordinal regression that attempt to provide a similar variance explained measure as that provided in ordinary least-squares linear regression. However, these measures do not have the direct interpretation that they do in ordinary linear regression and are often, therefore, referred to as pseudo R2 measures. The three most common measures (Cox and Snell, Nagelkerke, and McFadden) are not particularly good and not universally used. It is presented in the SPSS output, so you might encounter it in published work. tax$nagelkerke &lt;- rcompanion::nagelkerke(tax$clm) tax$nagelkerke$Pseudo.R.squared.for.model.vs.null ## Pseudo.R.squared ## McFadden 0.181957 ## Cox and Snell (ML) 0.367369 ## Nagelkerke (Cragg and Uhler) 0.399641 Likelihood Ratio Test The best way to assess model fit is the likelihood ratio test comparing the model to an intercept-only model. The difference in the -2 log likelihood between the models has a \\(\\chi^2\\) distribution with degrees of freedom equal to the difference in the number of parameters. intercept_only &lt;- clm(tax_too_high ~ 1, data = tax$dat) tax$lrt &lt;- anova(tax$clm, intercept_only) tax$lrt ## Likelihood ratio tests of cumulative link models: ## ## formula: link: threshold: ## intercept_only tax_too_high ~ 1 logit flexible ## tax$clm tax$fmla logit flexible ## ## no.par AIC logLik LR.stat df Pr(&gt;Chisq) ## intercept_only 3 489.14 -241.57 ## tax$clm 7 409.23 -197.62 87.911 4 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The table shows the log likelihoods of the two models. LR.stat is the difference between 2 * the logLik values. The final model statistically significantly predicted the dependent variable over and above the intercept-only model, \\(\\chi^2(4)\\) = 87.9, p = 0.000. Interpret Results Return to the model summary. tidy(tax$clm) ## # A tibble: 7 x 6 ## term estimate std.error statistic p.value coef.type ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Strongly Disagree|Disagree 7.03 1.17 6.02 1.70e- 9 intercept ## 2 Disagree|Agree 8.77 1.23 7.12 1.08e-12 intercept ## 3 Agree|Strongly Agree 11.7 1.36 8.59 8.72e-18 intercept ## 4 biz_ownerYes 0.665 0.289 2.30 2.14e- 2 location ## 5 age 0.242 0.0326 7.42 1.17e-13 location ## 6 politicsLib 0.0369 0.364 0.102 9.19e- 1 location ## 7 politicsCon 1.16 0.346 3.36 7.76e- 4 location The coefficients for biz_owner, age, and politics are positive. Positive parameters increase the likelihood of stronger agreement with the statement. In this case, discontent with taxes are higher for business owners, increase with age, and are higher for Liberal Democrats and Conservatives relative to the Labor Party. The expected cumulative log-odds of declaring \\(\\le j\\) level of agreement with the statement for the baseline group (biz_ownerNo, age = 0, politicsLib) is 7.026 for \\(j = 1\\) (Strongly Disagree), 8.766 for \\(j = 2\\) (Disagree), and 11.653 for \\(j = 3\\) (Agree). You could solve the logit equation for \\[\\pi_j = \\frac{\\mathrm{exp}(Y_i)} {1 + \\mathrm{exp}(Y_i)}\\] to get the cumulative probabilities for each level. Thats what predict(type = \"cum.prob\") does. But it might be more intuitive to work with individual probabilities, the lagged differences to get the individual probabilities for each \\(j\\). Thats what predict(type = \"prob\") does. I like to play with predicted values to get a sense of the outcome distributions. In this case, Ill take the median age, and each combination of biz_owner and politics. new_data &lt;- tax$dat %&gt;% mutate(age = median(tax$dat$age)) %&gt;% expand(age, politics, biz_owner) preds &lt;- predict(tax$clm, newdata = new_data, type = &quot;prob&quot;)[[&quot;fit&quot;]] %&gt;% as.data.frame() bind_cols(new_data, preds) %&gt;% pivot_longer(cols = `Strongly Disagree`:`Strongly Agree`) %&gt;% mutate(name = factor(name, levels = levels(tax$dat$tax_too_high))) %&gt;% ggplot(aes(y = politics, x = value, fill = fct_rev(name))) + geom_col() + geom_text(aes(label = scales::percent(value, accuracy = 1)), size = 3, position = position_stack(vjust=0.5)) + facet_grid(~paste(&quot;Bus Owner = &quot;, biz_owner)) + scale_fill_grey(start = 0.5, end = 0.8) + theme_bw() + theme(legend.position = &quot;top&quot;, axis.text.x = element_blank(), axis.ticks.x = element_blank()) + guides(fill = guide_legend(reverse = TRUE)) + labs(title = &quot;Taxes too High for Conservative Business Owners?&quot;, x = NULL, fill = NULL) You will want to establish whether politics is statistically significant overall before exploring any specific contrasts. The ANOVA procedure with type I test reports an overall test of significance for each variable entered into the model. (tax$anovaI &lt;- anova(tax$clm, type = &quot;I&quot;)) ## Type I Analysis of Deviance Table with Wald chi-square tests ## ## Df Chisq Pr(&gt;Chisq) ## biz_owner 1 13.201 0.0002798 *** ## age 1 57.413 3.533e-14 *** ## politics 2 14.636 0.0006635 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The political party last voted for has a statistically significant effect on the prediction of whether tax is thought to be too high, Wald \\(\\chi^2\\)(2) = 14.6, p = 0.001. The best way to work with the data is with the tidy(exponentiate = TRUE) version. tax$tidy &lt;- tax$clm %&gt;% tidy(conf.int = TRUE, exponentiate = TRUE) tax$tidy ## # A tibble: 7 x 8 ## term estimate std.error statistic p.value conf.low conf.high coef.type ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Strongly D~ 1.13e3 1.17 6.02 1.70e- 9 NA NA intercept ## 2 Disagree|A~ 6.41e3 1.23 7.12 1.08e-12 NA NA intercept ## 3 Agree|Stro~ 1.15e5 1.36 8.59 8.72e-18 NA NA intercept ## 4 biz_ownerY~ 1.94e0 0.289 2.30 2.14e- 2 1.11 3.44 location ## 5 age 1.27e0 0.0326 7.42 1.17e-13 1.20 1.36 location ## 6 politicsLib 1.04e0 0.364 0.102 9.19e- 1 0.508 2.12 location ## 7 politicsCon 3.19e0 0.346 3.36 7.76e- 4 1.63 6.35 location Then you can summarize the table in words. The odds of business owners considering tax to be too high was 1.944 (95% CI, 1.107 to 3.443) times that of non-business owners, a statistically significant effect, z = 2.300, p = 0.021. The odds of Conservative voters considering tax to be too high was 3.194 (95% CI, 1.635 to 6.351) times that of Labour voters, a statistically significant effect, z = 3.361, p = 0.001. The odds of Liberal Democrat voters considering tax to be too high was similar to that of Labour voters (odds ratio of 1.038 (95% CI, 0.508 to 2.121), p = 0.919. An increase in age (expressed in years) was associated with an increase in the odds of considering tax too high, with an odds ratio of 1.274 (95% CI, 1.197 to 1.360), z = 7.421, p = 0.000. Reporting Here is the complete write-up. A cumulative odds ordinal logistic regression with proportional odds was run to determine the effect of business ownership, political party voted for, and age, on the belief that taxes are too high. There were proportional odds, as assessed by a full likelihood ratio test comparing the fitted model to a model with varying location parameters, \\(\\chi^2\\)(8) = 8.620, p = 0.375. The final model statistically significantly predicted the dependent variable over and above the intercept-only model, \\(\\chi^2(4)\\) = 87.9, p = 0.000. The odds of business owners considering tax to be too high was 1.944 (95% CI, 1.107 to 3.443) times that of non-business owners, a statistically significant effect, z = 2.300, p = 0.021. The political party last voted for has a statistically significant effect on the prediction of whether tax is thought to be too high, Wald \\(\\chi^2\\)(2) = 14.6, p = 0.001. The odds of Conservative voters considering tax to be too high was 3.194 (95% CI, 1.635 to 6.351) times that of Labour voters, a statistically significant effect, z = 3.361, p = 0.001. The odds of Liberal Democrat voters considering tax to be too high was similar to that of Labour voters (odds ratio of 1.038 (95% CI, 0.508 to 2.121), p = 0.919. An increase in age (expressed in years) was associated with an increase in the odds of considering tax too high, with an odds ratio of 1.274 (95% CI, 1.197 to 1.360), z = 7.421, p = 0.000. Package gtsummary shows a nice summary table. tbl_regression(tax$clm) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #lanemodafe .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lanemodafe .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lanemodafe .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lanemodafe .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #lanemodafe .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lanemodafe .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lanemodafe .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lanemodafe .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lanemodafe .gt_column_spanner_outer:first-child { padding-left: 0; } #lanemodafe .gt_column_spanner_outer:last-child { padding-right: 0; } #lanemodafe .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #lanemodafe .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #lanemodafe .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lanemodafe .gt_from_md > :first-child { margin-top: 0; } #lanemodafe .gt_from_md > :last-child { margin-bottom: 0; } #lanemodafe .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lanemodafe .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #lanemodafe .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lanemodafe .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #lanemodafe .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lanemodafe .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lanemodafe .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lanemodafe .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lanemodafe .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lanemodafe .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #lanemodafe .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lanemodafe .gt_sourcenote { font-size: 90%; padding: 4px; } #lanemodafe .gt_left { text-align: left; } #lanemodafe .gt_center { text-align: center; } #lanemodafe .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lanemodafe .gt_font_normal { font-weight: normal; } #lanemodafe .gt_font_bold { font-weight: bold; } #lanemodafe .gt_font_italic { font-style: italic; } #lanemodafe .gt_super { font-size: 65%; } #lanemodafe .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Beta 95% CI1 p-value Strongly Disagree|Disagree 7.0 Disagree|Agree 8.8 Agree|Strongly Agree 12 biz_owner No &mdash; &mdash; Yes 0.66 0.10, 1.2 0.021 age 0.24 0.18, 0.31 politics Lab &mdash; &mdash; Lib 0.04 -0.68, 0.75 >0.9 Con 1.2 0.49, 1.8 1 CI = Confidence Interval 6.4 Poisson Regression Poisson models count data, like traffic tickets per day, or website hits per day. The response is an expected rate or intensity. For count data, specify the generalized model, this time with family = poisson or family = quasipoisson. Recall that the probability of achieving a count \\(y\\) when the expected rate is \\(\\lambda\\) is distributed \\[P(Y = y|\\lambda) = \\frac{e^{-\\lambda} \\lambda^y}{y!}.\\] The poisson regression model is \\[\\lambda = \\exp(X \\beta).\\] You can solve this for \\(y\\) to get \\[y = X\\beta = \\ln(\\lambda).\\] That is, the model predicts the log of the response rate. For a sample of size n, the likelihood function is \\[L(\\beta; y, X) = \\prod_{i=1}^n \\frac{e^{-\\exp({X_i\\beta})}\\exp({X_i\\beta})^{y_i}}{y_i!}.\\] The log-likelihood is \\[l(\\beta) = \\sum_{i=1}^n (y_i X_i \\beta - \\sum_{i=1}^n\\exp(X_i\\beta) - \\sum_{i=1}^n\\log(y_i!).\\] Maximizing the log-likelihood has no closed-form solution, so the coefficient estimates are found through interatively reweighted least squares. Poisson processes assume the variance of the response variable equals its mean. Equals means the mean and variance are of a similar order of magnitude. If that assumption does not hold, use the quasi-poisson. Use Poisson regression for large datasets. If the predicted counts are much greater than zero (&gt;30), the linear regression will work fine. Whereas RMSE is not useful for logistic models, it is a good metric in Poisson. Dataset fire contains response variable injuries counting the number of injuries during the month and one explanatory variable, the month mo. fire &lt;- read_csv(file = &quot;C:/Users/mpfol/OneDrive/Documents/Data Science/Data/CivilInjury_0.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## ID = col_double(), ## `Injury Date` = col_datetime(format = &quot;&quot;), ## `Total Injuries` = col_double() ## ) fire &lt;- fire %&gt;% mutate(mo = as.POSIXlt(`Injury Date`)$mon + 1) %&gt;% rename(dt = `Injury Date`, injuries = `Total Injuries`) str(fire) ## tibble [300 x 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ ID : num [1:300] 1 2 3 4 5 6 7 8 9 10 ... ## $ dt : POSIXct[1:300], format: &quot;2005-01-10&quot; &quot;2005-01-11&quot; ... ## $ injuries: num [1:300] 1 1 1 5 2 1 1 1 1 1 ... ## $ mo : num [1:300] 1 1 1 1 1 1 2 2 2 4 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. ID = col_double(), ## .. `Injury Date` = col_datetime(format = &quot;&quot;), ## .. `Total Injuries` = col_double() ## .. ) In a situation like this where there the relationship is bivariate, start with a visualization. ggplot(fire, aes(x = mo, y = injuries)) + geom_jitter() + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;poisson&quot;)) + labs(title = &quot;Injuries by Month&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Fit a poisson regression in R using glm(formula, data, family = poisson). But first, check whether the mean and variance of injuries are the same magnitude? If not, then use family = quasipoisson. mean(fire$injuries) ## [1] 1.36 var(fire$injuries) ## [1] 1.020468 They are of the same magnitude, so fit the regression with family = poisson. m2 &lt;- glm(injuries ~ mo, family = poisson, data = fire) summary(m2) ## ## Call: ## glm(formula = injuries ~ mo, family = poisson, data = fire) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.3987 -0.3473 -0.3034 -0.2502 4.3185 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.22805 0.10482 2.176 0.0296 * ## mo 0.01215 0.01397 0.870 0.3844 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 139.87 on 299 degrees of freedom ## Residual deviance: 139.11 on 298 degrees of freedom ## AIC: 792.08 ## ## Number of Fisher Scoring iterations: 5 The predicted value \\(\\hat{y}\\) is the estimated log of the response variable, \\[\\hat{y} = X \\hat{\\beta} = \\ln (\\lambda).\\] Suppose mo is January (mo = ), then the log ofinjuries` is \\(\\hat{y} = 0.323787\\). Or, more intuitively, the expected count of injuries is \\(\\exp(0.323787) = 1.38\\) predict(m2, newdata = data.frame(mo=1)) ## 1 ## 0.2401999 predict(m2, newdata = data.frame(mo=1), type = &quot;response&quot;) ## 1 ## 1.271503 Here is a plot of the predicted counts in red. augment(m2, type.predict = &quot;response&quot;) %&gt;% ggplot(aes(x = mo, y = injuries)) + geom_point() + geom_point(aes(y = .fitted), color = &quot;red&quot;) + scale_y_continuous(limits = c(0, NA)) + labs(x = &quot;Month&quot;, y = &quot;Injuries&quot;, title = &quot;Poisson Fitted Line Plot&quot;) Evaluate a logistic model fit with an analysis of deviance. (perf &lt;- glance(m2)) ## # A tibble: 1 x 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 140. 299 -394. 792. 799. 139. 298 300 (pseudoR2 &lt;- 1 - perf$deviance / perf$null.deviance) ## [1] 0.005413723 The deviance of the null model (no regressors) is 139.9. The deviance of the full model is 132.2. The psuedo-R2 is very low at .05. How about the RMSE? RMSE(pred = predict(m2, type = &quot;response&quot;), obs = fire$injuries) ## [1] 1.006791 The average prediction error is about 0.99. Thats almost as much as the variance of injuries - i.e., just predicting the mean of injuries would be almost as good! Use the GainCurvePlot() function to plot the gain curve. augment(m2, type.predict = &quot;response&quot;) %&gt;% ggplot(aes(x = injuries, y = .fitted)) + geom_point() + geom_smooth(method =&quot;lm&quot;) + labs(x = &quot;Actual&quot;, y = &quot;Predicted&quot;, title = &quot;Poisson Fitted vs Actual&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; augment(m2) %&gt;% data.frame() %&gt;% GainCurvePlot(xvar = &quot;.fitted&quot;, truthVar = &quot;injuries&quot;, title = &quot;Poisson Model&quot;) It seems that mo was a poor predictor of injuries. References "],["Probablity.html", "Chapter 7 Probability 7.1 Bayesian Inference 7.2 Stochastic Processes", " Chapter 7 Probability 7.1 Bayesian Inference The Bayesian model for inference adds to the statistical model \\(\\{f_\\theta : \\theta \\in \\Omega\\}\\) a prior probability measure \\(\\Pi\\) for \\(\\theta\\). For example, suppose \\(\\theta\\) is the probability a flipping a coin to heads, with \\(\\Omega = [0,1]\\). The statisticians conservative believe \\(\\pi\\) may be a wide bell curve centered on \\(\\theta=0.5\\), or maybe the statistician is quite confident, so \\(\\pi\\) is a daring narrow bell curve around \\(\\theta=0.5\\). By the law of total probability, the probability of event \\(s\\) is a joint distribution, \\(\\pi(\\theta)f_\\theta(s)\\). The marginal distribution of \\(s\\) is \\(m(s) = \\int_\\Omega \\pi(\\theta)f_\\theta(s)d\\theta.\\) After \\(s\\) is observed the posterior distribution of \\(\\theta\\) is the conditional distribution of \\(\\theta\\) given \\(s\\) is \\[\\pi(\\theta|s) = \\frac{\\pi(\\theta)f_\\theta(s)}{m(s)}\\] Suppose you observe a sample from a Bernoulli distribution with an unknown success probability, \\(\\theta \\in [0,1].\\) You take a uniform prior, \\(\\pi= Beta(\\alpha, \\beta) = Beta(1,1).\\). Your sample of \\(n = 40\\) includes \\(n\\bar{x} = 10\\) successes. Then the posterior of \\(\\theta\\) is \\(Beta(11,31):\\) The likelihood \\(\\theta^{n\\bar{x}}\\left(1-\\theta\\right)^{n(1-\\bar{x})}\\) times the prior \\(B^{-1}(\\alpha, \\beta)\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\\) 7.2 Stochastic Processes Stochastic processes are proceed randomly over time. The simplest version is the random walk. A random walk is a sequence \\(\\{X_n\\}\\) of random variables, with \\(X_0\\) = 1 and \\(P\\left(X_{n+1} = X_n + 1 \\right) = p\\) where \\(p\\) is the probability of success and its complement is \\(q= 1-p\\). It follows that, given an initial value \\(a\\), \\(P\\left(X_n = a + k\\right) = \\binom{n}{\\frac{n+k}{2}} p^{(n+k)/2}q^{(n-k)/2}\\) for \\(k = -n, -n+2, -n+4, \\dots,n\\), and \\(E\\left(X_n\\right) = a + n(2p-1)\\). 7.2.1 Markov Chains A Markov chain is the random motion of an object. Given a state space \\(S\\) of all places an object can go, and a set of transition probabilities \\(\\{p_{ij}: i,j \\in S\\}\\) to move from state \\(i\\) to \\(j\\), and a probability \\(u_i = P\\left(X_0 = i\\right)\\) that the object starts at state \\(i\\), then \\(P\\left(X_{n+1} = j|X_n =i\\right)=p_{ij}\\) ?? "],["references.html", "References", " References "]]
