<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 One-Sample Inference Tests | Statistics Handbook</title>
  <meta name="description" content="Notes cobbled together from books, online classes, etc. to be used as quick reference for common work projects." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 One-Sample Inference Tests | Statistics Handbook" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notes cobbled together from books, online classes, etc. to be used as quick reference for common work projects." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 One-Sample Inference Tests | Statistics Handbook" />
  
  <meta name="twitter:description" content="Notes cobbled together from books, online classes, etc. to be used as quick reference for common work projects." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2021-01-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="two-group-comparison-tests.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html"><i class="fa fa-check"></i><b>1</b> One-Sample Inference Tests</a><ul>
<li class="chapter" data-level="1.1" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#one-sample-mean-z-test"><i class="fa fa-check"></i><b>1.1</b> One-Sample Mean z Test</a></li>
<li class="chapter" data-level="1.2" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#one-sample-mean-t-test"><i class="fa fa-check"></i><b>1.2</b> One-Sample Mean t Test</a></li>
<li class="chapter" data-level="1.3" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#one-sample-median-wilcoxon-test"><i class="fa fa-check"></i><b>1.3</b> One-Sample Median Wilcoxon Test</a></li>
<li class="chapter" data-level="1.4" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#chi-squared-goodness-of-fit-test"><i class="fa fa-check"></i><b>1.4</b> Chi-Squared Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="1.5" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#g-test"><i class="fa fa-check"></i><b>1.5</b> G-Test</a></li>
<li class="chapter" data-level="1.6" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#pairwise.prop.test"><i class="fa fa-check"></i><b>1.6</b> pairwise.prop.test</a></li>
<li class="chapter" data-level="1.7" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#exact-tests"><i class="fa fa-check"></i><b>1.7</b> Exact Tests</a><ul>
<li class="chapter" data-level="1.7.1" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#one-sample-poisson-test"><i class="fa fa-check"></i><b>1.7.1</b> One-Sample Poisson Test</a></li>
<li class="chapter" data-level="" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#conditions-3"><i class="fa fa-check"></i>Conditions</a></li>
<li class="chapter" data-level="" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#results-3"><i class="fa fa-check"></i>Results</a></li>
<li class="chapter" data-level="1.7.2" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#one-sample-binomial-test"><i class="fa fa-check"></i><b>1.7.2</b> One-Sample Binomial Test</a></li>
<li class="chapter" data-level="1.7.3" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#fishers-exact-test"><i class="fa fa-check"></i><b>1.7.3</b> Fisher’s Exact Test</a></li>
<li class="chapter" data-level="1.7.4" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#sample-z-test-for-categorical-var"><i class="fa fa-check"></i><b>1.7.4</b> 1 Sample z Test for Categorical Var</a></li>
<li class="chapter" data-level="1.7.5" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#sample-t-test-for-categorical-var"><i class="fa fa-check"></i><b>1.7.5</b> 1 sample t Test for Categorical Var</a></li>
<li class="chapter" data-level="1.7.6" data-path="one-sample-inference-tests.html"><a href="one-sample-inference-tests.html#wilcoxon-1-sample-median-test-for-categorical-var"><i class="fa fa-check"></i><b>1.7.6</b> Wilcoxon 1-Sample Median Test for Categorical Var</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html"><i class="fa fa-check"></i><b>2</b> Two-Group Comparison Tests</a><ul>
<li class="chapter" data-level="2.1" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#two-group-comparison-tests-for-numeric-vars"><i class="fa fa-check"></i><b>2.1</b> Two-Group Comparison Tests for Numeric Vars</a><ul>
<li class="chapter" data-level="2.1.1" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#sample-independent-t-test-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.1</b> 2 Sample Independent t Test for Numeric Vars</a></li>
<li class="chapter" data-level="2.1.2" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#sample-welchs-t-test-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.2</b> 2 Sample Welch’s t Test for Numeric Vars</a></li>
<li class="chapter" data-level="2.1.3" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#paired-sample-t-test-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.3</b> Paired Sample t Test for Numeric Vars</a></li>
<li class="chapter" data-level="2.1.4" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#mann-whitney-u-test-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.4</b> Mann-Whitney U Test for Numeric Vars</a></li>
<li class="chapter" data-level="2.1.5" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#wilcoxon-paired-sample-test-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.5</b> Wilcoxon Paired-Sample Test for Numeric Vars</a></li>
<li class="chapter" data-level="2.1.6" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#pearsons-correlation-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.6</b> Pearson’s Correlation for Numeric Vars</a></li>
<li class="chapter" data-level="2.1.7" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#spearmans-ranked-correlation-for-numeric-vars"><i class="fa fa-check"></i><b>2.1.7</b> Spearman’s Ranked Correlation for Numeric Vars</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#two-group-comparison-tests-for-categorical-vars"><i class="fa fa-check"></i><b>2.2</b> Two-Group Comparison Tests for Categorical Vars</a><ul>
<li class="chapter" data-level="2.2.1" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#sample-independent-t-test-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.1</b> 2 Sample Independent t Test for Categorical Vars</a></li>
<li class="chapter" data-level="2.2.2" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#sample-welchs-t-test-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.2</b> 2 Sample Welch’s t Test for Categorical Vars</a></li>
<li class="chapter" data-level="2.2.3" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#paired-sample-t-test-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.3</b> Paired Sample t Test for Categorical Vars</a></li>
<li class="chapter" data-level="2.2.4" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#mann-whitney-u-test-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.4</b> Mann-Whitney U Test for Categorical Vars</a></li>
<li class="chapter" data-level="2.2.5" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#wilcoxon-paired-sample-test-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.5</b> Wilcoxon Paired-Sample Test for Categorical Vars</a></li>
<li class="chapter" data-level="2.2.6" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#pearsons-correlation-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.6</b> Pearson’s Correlation for Categorical Vars</a></li>
<li class="chapter" data-level="2.2.7" data-path="two-group-comparison-tests.html"><a href="two-group-comparison-tests.html#spearmans-ranked-correlation-for-categorical-vars"><i class="fa fa-check"></i><b>2.2.7</b> Spearman’s Ranked Correlation for Categorical Vars</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html"><i class="fa fa-check"></i><b>3</b> Multi-Group Comparison Tests</a><ul>
<li class="chapter" data-level="3.1" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#independent-t-test"><i class="fa fa-check"></i><b>3.1</b> Independent t-Test</a></li>
<li class="chapter" data-level="3.2" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#paired-t-test"><i class="fa fa-check"></i><b>3.2</b> Paired t-Test</a></li>
<li class="chapter" data-level="3.3" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#sign-est"><i class="fa fa-check"></i><b>3.3</b> Sign est</a></li>
<li class="chapter" data-level="3.4" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>3.4</b> Wilcoxon Rank-Sum Test</a></li>
<li class="chapter" data-level="3.5" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>3.5</b> Wilcoxon Signed-Rank Test</a></li>
<li class="chapter" data-level="3.6" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#anova"><i class="fa fa-check"></i><b>3.6</b> ANOVA</a><ul>
<li class="chapter" data-level="3.6.1" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#one-way-anova"><i class="fa fa-check"></i><b>3.6.1</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="3.6.2" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#welchs-anova-wgames-howell"><i class="fa fa-check"></i><b>3.6.2</b> Welch’s ANOVA w/Games-Howell</a></li>
<li class="chapter" data-level="3.6.3" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#manova"><i class="fa fa-check"></i><b>3.6.3</b> MANOVA</a></li>
<li class="chapter" data-level="3.6.4" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#multiple-variance-comparison-f-test"><i class="fa fa-check"></i><b>3.6.4</b> Multiple Variance Comparison F Test</a></li>
<li class="chapter" data-level="3.6.5" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#example-2"><i class="fa fa-check"></i><b>3.6.5</b> Example</a></li>
<li class="chapter" data-level="3.6.6" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#repeated-measures"><i class="fa fa-check"></i><b>3.6.6</b> Repeated Measures</a></li>
<li class="chapter" data-level="3.6.7" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#two-way"><i class="fa fa-check"></i><b>3.6.7</b> Two-Way</a></li>
<li class="chapter" data-level="3.6.8" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#randomized-blocks"><i class="fa fa-check"></i><b>3.6.8</b> Randomized Blocks</a></li>
<li class="chapter" data-level="3.6.9" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#ancova"><i class="fa fa-check"></i><b>3.6.9</b> ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="multi-group-comparison-tests.html"><a href="multi-group-comparison-tests.html#kruskalwallis-test"><i class="fa fa-check"></i><b>3.7</b> Kruskal–Wallis Test</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>4</b> Applications</a><ul>
<li class="chapter" data-level="4.1" data-path="applications.html"><a href="applications.html#example-one"><i class="fa fa-check"></i><b>4.1</b> Example one</a></li>
<li class="chapter" data-level="4.2" data-path="applications.html"><a href="applications.html#example-two"><i class="fa fa-check"></i><b>4.2</b> Example two</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>5</b> Final Words</a><ul>
<li class="chapter" data-level="5.1" data-path="final-words.html"><a href="final-words.html#pearson"><i class="fa fa-check"></i><b>5.1</b> Pearson</a></li>
<li class="chapter" data-level="5.2" data-path="final-words.html"><a href="final-words.html#chi-square"><i class="fa fa-check"></i><b>5.2</b> Chi-Square</a></li>
<li class="chapter" data-level="5.3" data-path="final-words.html"><a href="final-words.html#spearman"><i class="fa fa-check"></i><b>5.3</b> Spearman</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="final-words-1.html"><a href="final-words-1.html"><i class="fa fa-check"></i><b>6</b> Final Words</a><ul>
<li class="chapter" data-level="6.1" data-path="final-words-1.html"><a href="final-words-1.html#linear"><i class="fa fa-check"></i><b>6.1</b> Linear</a></li>
<li class="chapter" data-level="6.2" data-path="final-words-1.html"><a href="final-words-1.html#generalized-linear"><i class="fa fa-check"></i><b>6.2</b> Generalized Linear</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Probablity.html"><a href="Probablity.html"><i class="fa fa-check"></i><b>7</b> Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="Probablity.html"><a href="Probablity.html#bayesian-inference"><i class="fa fa-check"></i><b>7.1</b> Bayesian Inference</a></li>
<li class="chapter" data-level="7.2" data-path="Probablity.html"><a href="Probablity.html#stochastic-processes"><i class="fa fa-check"></i><b>7.2</b> Stochastic Processes</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Probablity.html"><a href="Probablity.html#markov-chains"><i class="fa fa-check"></i><b>7.2.1</b> Markov Chains</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Handbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="one-sample-inference-tests" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> One-Sample Inference Tests</h1>
<p><em>One-sample</em> tests are used to either describe a variable in terms of frequency or measures of central tendency and spread, or compare a variable to a known or hypothesized population or value.</p>
<p>If the data generating process produces continuous outcomes (either interval or ratio), and the outcomes are symmetrically distributed, then you can treat the sample mean, <span class="math inline">\(\bar{x}\)</span>, as a normally distributed random variable centered at the population mean, <span class="math inline">\(\mu\)</span>. You can then use the distribution to estimate an 95% confidence interval (CI) around <span class="math inline">\(\mu\)</span>, or test the likelihood that <span class="math inline">\(\bar{x}\)</span> is contained within an 95% CI of an hypothesized population mean, <span class="math inline">\(\mu_0\)</span>. If you (somehow) know the population variance, or the Central Limit Theorem (CLT) conditions hold, you can use the <em>z</em>-test, otherwise you have to use the <em>t</em>-test. The <em>t</em>-test returns nearly the same result as the <em>z</em>-test when the CLT holds, so in practice no one bothers with the <em>z</em>-test except as an aid to teach the <em>t</em>-test. If the outcome is continuous, but <em>not</em> symmetric, then you must use a non-parametric test like the Wilcoxon median test.</p>
<p>If the data generating process produces discrete outcomes (counts), then you can treat the sample count, <span class="math inline">\(x\)</span>, as a random variable from a Poisson, binomial, normal, or multinomial distribution.</p>
<ul>
<li><p>For counts over a fixed time or space, then treat the count as a random variable from a Poisson distribution with expected value <span class="math inline">\(\lambda\)</span> and variance <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>For counts within a fixed total that are then classified into two levels (usually yes/no), then treat the count as a random variable from a binomial distribution with expected value <span class="math inline">\(n\pi\)</span> and variance <span class="math inline">\(n\pi(1-\pi)\)</span> where <span class="math inline">\(\pi = x / n\)</span>.</p></li>
<li><p>For binomial cases where <span class="math inline">\(n\ge30\)</span> and the number of occurrences of each of the two levels is <span class="math inline">\(\ge\)</span> 5, then treat the count as a random variable from the normal distribution with expected valued <span class="math inline">\(\pi\)</span> and variance <span class="math inline">\(\frac{\pi(1-\pi)}{n}\)</span>.</p></li>
<li><p>For counts withing a fixed total that are then classified into three or more levels, then treat the count as a random variable from the multinomial distribution with expected value <span class="math inline">\(n\pi_j\)</span> and variance <span class="math inline">\(n\pi_j(1-\pi_j)\)</span>.</p></li>
</ul>
<p>The above cases can be generalized into a single class of tests, the <em>chi-squared goodness-of-fit</em> test. All of these discrete variable tests are discussed in <a href="https://online.stat.psu.edu/stat504">PSU STATS 504</a>.</p>
<div id="one-sample-mean-z-test" class="section level2">
<h2><span class="header-section-number">1.1</span> One-Sample Mean z Test</h2>
<p>The <em>z</em> test is also called the normal approximation <em>z</em> test. It only applies when the sampling distribution of the population mean is normally distributed with known variance, and there are no significant outliers. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large <span class="math inline">\((n &gt;= 30)\)</span>, as follows from the central limit theorem. The <em>t</em> test returns similar results, plus it is valid when the variance is unknown, and that is pretty much always. For that reason, you probably will never use this test.</p>
<p>Under the normal approximation method, the measured mean <span class="math inline">\(\bar{x}\)</span> approximates the population mean <span class="math inline">\(\mu\)</span>, and the sampling distribution has a normal distribution centered at <span class="math inline">\(\mu\)</span> with standard error <span class="math inline">\(se_\mu = \frac{\sigma}{\sqrt{n}}\)</span> where <span class="math inline">\(\sigma\)</span> is the standard deviation of the underlying population. Define a <span class="math inline">\((1 - \alpha)\%\)</span> confidence interval as <span class="math inline">\(\bar{x} \pm z_{(1 - \alpha) {/} 2} se_\mu\)</span>, or test <span class="math inline">\(H_0: \mu = \mu_0\)</span> with test statistic <span class="math inline">\(Z = \frac{\bar{x} - \mu_0}{se_\mu}\)</span>.</p>
<div id="example" class="section level4 unnumbered">
<h4>Example</h4>
<p>The <code>mtcars</code> data set is a sample of <em>n</em> = 32 cars. The mean fuel economy is <span class="math inline">\(\bar{x} \pm s\)</span> = 20.1 <span class="math inline">\(\pm\)</span> 6.0 mpg. The prior measured overall fuel economy for vehicles was <span class="math inline">\(\mu_0 \pm \sigma\)</span> = 18.0 <span class="math inline">\(\pm\)</span> 6.0 mpg. Has fuel economy improved?</p>
<p>The sample size is <span class="math inline">\(\ge\)</span> 30, so the sampling distribution of the population mean is normally distributed. The population variance is known, so use the <em>z</em> test.</p>
<p><span class="math inline">\(H_0: \mu = 16.0\)</span>, and <span class="math inline">\(H_a: \mu &gt; 16.0\)</span> - a right-tail test. The test statistic is <span class="math inline">\(Z = \frac{\bar{x} - \mu_0}{se_\mu}=\)</span> 1.97 where <span class="math inline">\(se_{\mu_0} = \frac{\mu_0}{\sqrt{n}} =\)</span> 1.06. <span class="math inline">\(P(z &gt; Z) =\)</span> 0.0244, so reject <span class="math inline">\(H_0\)</span> at the <span class="math inline">\(\alpha =\)</span> 0.05 level of significance.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-4-1.png" width="624" /></p>
<p>The 95% confidence interval for <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\bar{x} \pm z_{(1 - \alpha){/}2} se_\mu\)</span> where <span class="math inline">\(z_{(1 - \alpha){/}2} =\)</span> 1.96. <span class="math inline">\(\mu =\)</span> 20.09 <span class="math inline">\(\pm\)</span> 2.08 (95% CI 18.01 to 22.17).</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-6-1.png" width="624" /></p>
</div>
</div>
<div id="one-sample-mean-t-test" class="section level2">
<h2><span class="header-section-number">1.2</span> One-Sample Mean t Test</h2>
<p>The one-sample <em>t</em> test applies when the sampling distribution of the population mean is normally distributed and there are no significant outliers. Unlike the <em>z</em> test, the population variance can be unknown. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large <span class="math inline">\((n &gt;= 30)\)</span>, as follows from the central limit theorem.</p>
<p>Under the <em>t</em> test method, the measured mean, <span class="math inline">\(\bar{x}\)</span>, approximates the population mean, <span class="math inline">\(\mu\)</span>. The sample standard deviation, <span class="math inline">\(s\)</span>, estimates the unknown population standard deviation, <span class="math inline">\(\sigma\)</span>. The resulting sampling distribution has a <em>t</em> distribution centered at <span class="math inline">\(\mu\)</span> with standard error <span class="math inline">\(se_\bar{x} = \frac{s}{\sqrt{n}}\)</span>. Define a <span class="math inline">\((1 - \alpha)\%\)</span> confidence interval as <span class="math inline">\(\bar{x} \pm t_{(1 - \alpha){/}2} se_\bar{x}\)</span> and/or test <span class="math inline">\(H_0: \mu = \mu_0\)</span> with test statistic <span class="math inline">\(T = \frac{\bar{x} - \mu_0}{se_\bar{x}}\)</span>.</p>
<div id="example-1" class="section level4 unnumbered">
<h4>Example</h4>
<p>A researcher recruits a random sample of <em>n</em> = 40 people to participate in a study about depression intervention. The researcher measures the participants’ depression level prior to the study. The mean depression score (3.72 <span class="math inline">\(\pm\)</span> 0.74) was lower than the population ‘normal’ depression score of 4.0. The null hypothesis is that the sample is representative of the overall population. Should you reject <span class="math inline">\(H_0\)</span>?</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="one-sample-inference-tests.html#cb1-1"></a>dep <span class="op">%&gt;%</span><span class="st"> </span>gtsummary<span class="op">::</span><span class="kw">tbl_summary</span>(<span class="dt">statistic =</span> <span class="kw">list</span>(<span class="kw">all_continuous</span>() <span class="op">~</span><span class="st"> &quot;{mean} ({sd})&quot;</span>))</span></code></pre></div>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#jqlvhxjael .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#jqlvhxjael .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#jqlvhxjael .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#jqlvhxjael .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#jqlvhxjael .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#jqlvhxjael .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#jqlvhxjael .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#jqlvhxjael .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#jqlvhxjael .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#jqlvhxjael .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#jqlvhxjael .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#jqlvhxjael .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#jqlvhxjael .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#jqlvhxjael .gt_from_md > :first-child {
  margin-top: 0;
}

#jqlvhxjael .gt_from_md > :last-child {
  margin-bottom: 0;
}

#jqlvhxjael .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#jqlvhxjael .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#jqlvhxjael .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#jqlvhxjael .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#jqlvhxjael .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#jqlvhxjael .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#jqlvhxjael .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#jqlvhxjael .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#jqlvhxjael .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#jqlvhxjael .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#jqlvhxjael .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#jqlvhxjael .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#jqlvhxjael .gt_left {
  text-align: left;
}

#jqlvhxjael .gt_center {
  text-align: center;
}

#jqlvhxjael .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#jqlvhxjael .gt_font_normal {
  font-weight: normal;
}

#jqlvhxjael .gt_font_bold {
  font-weight: bold;
}

#jqlvhxjael .gt_font_italic {
  font-style: italic;
}

#jqlvhxjael .gt_super {
  font-size: 65%;
}

#jqlvhxjael .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="jqlvhxjael" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>N = 40</strong><sup class="gt_footnote_marks">1</sup></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr>
      <td class="gt_row gt_left">dep_score</td>
      <td class="gt_row gt_center">3.72 (0.74)</td>
    </tr>
  </tbody>
  
  <tfoot>
    <tr class="gt_footnotes">
      <td colspan="2">
        <p class="gt_footnote">
          <sup class="gt_footnote_marks">
            <em>1</em>
          </sup>
           
          Statistics presented: Mean (SD)
          <br />
        </p>
      </td>
    </tr>
  </tfoot>
</table></div>
</div>
<div id="conditions" class="section level4 unnumbered">
<h4>Conditions</h4>
<p>The one-sample <em>t</em> test applies when the variable is continuous and the observations are independent. Additionally, there are two conditions related to the data distribution. If either condition fails, try the suggested work-arounds or use the non-parametric [Wilcoxon 1-Sample Median Test for Numeric Var] instead.</p>
<ol style="list-style-type: decimal">
<li><strong>Outliers</strong>. There should be no significant outliers. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data.</li>
<li><strong>Normality</strong>. Values should be <em>nearly</em> normally distributed (“nearly” because the <em>t</em>-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data.</li>
</ol>
<div id="outliers" class="section level5 unnumbered">
<h5>Outliers</h5>
<p>Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. The boxplot shows no outliers.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>If the outliers might are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you have a couple options before reverting to Wilcoxon.</p>
<ul>
<li>Transform the variable. Don’t do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult.</li>
<li>Leave it in if it doesn’t affect the conclusion (compared to taking it out).</li>
</ul>
</div>
<div id="normality" class="section level5 unnumbered">
<h5>Normality</h5>
<p>Assume the population is normally distributed if <em>n</em> <span class="math inline">\(\ge\)</span> 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still don’t feel confident about normality, run a [Shapiro-Wilk Test].</p>
<p>The data set has <em>n</em> = 40 observations, so you can assume normality. Here is a QQ plot anyway. The QQ plot indicates normality.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="one-sample-inference-tests.html#cb2-1"></a>dep <span class="op">%&gt;%</span></span>
<span id="cb2-2"><a href="one-sample-inference-tests.html#cb2-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> dep_score)) <span class="op">+</span></span>
<span id="cb2-3"><a href="one-sample-inference-tests.html#cb2-3"></a><span class="st">  </span><span class="kw">stat_qq</span>() <span class="op">+</span></span>
<span id="cb2-4"><a href="one-sample-inference-tests.html#cb2-4"></a><span class="st">  </span><span class="kw">stat_qq_line</span>(<span class="dt">col =</span> <span class="st">&quot;goldenrod&quot;</span>) <span class="op">+</span></span>
<span id="cb2-5"><a href="one-sample-inference-tests.html#cb2-5"></a><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></span>
<span id="cb2-6"><a href="one-sample-inference-tests.html#cb2-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Normal Q-Q Plot&quot;</span>)</span></code></pre></div>
<p><img src="statistics_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Here is the Shapiro-Wilk normality test. It fails to reject the null hypothesis of a normally distributed population.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="one-sample-inference-tests.html#cb3-1"></a><span class="kw">shapiro.test</span>(dep<span class="op">$</span>dep_score)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  dep$dep_score
## W = 0.98446, p-value = 0.8474</code></pre>
<p>If the data is not normally distributed, you still have a couple options before reverting to Wilcoxon.</p>
<ul>
<li>Transform the dependent variable.</li>
<li>Carry on regardless - the one-sample <em>t</em>-test is fairly robust to deviations from normality.</li>
</ul>
</div>
</div>
<div id="results" class="section level4 unnumbered">
<h4>Results</h4>
<p>Conduct the <em>t</em>-test. To get a 95% CI around the <em>difference</em> (instead of around the estimate), run the test using the difference, <span class="math inline">\(\mu_0 - \bar{x}\)</span>, and leave <code>mu</code> at its default of 0.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="one-sample-inference-tests.html#cb5-1"></a>(dep_95ci &lt;-<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> mu_<span class="dv">0</span> <span class="op">-</span><span class="st"> </span>dep<span class="op">$</span>dep_score, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>, <span class="dt">conf.level =</span> <span class="fl">.95</span>))</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  mu_0 - dep$dep_score
## t = 2.3811, df = 39, p-value = 0.02224
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  0.04176615 0.51323385
## sample estimates:
## mean of x 
##    0.2775</code></pre>
<p>The difference is statistically different from 0 at the <em>p</em> = .05 level. The effect size, called Cohen’s <em>d</em>, is defined as <span class="math inline">\(d = |M_D| / s\)</span>, where <span class="math inline">\(|M_D| = \bar{x} - \mu_0\)</span>, and <span class="math inline">\(s\)</span> is the sample standard deviation. <span class="math inline">\(d &lt;.2\)</span> is considered trivial, <span class="math inline">\(.2 \le d &lt; .5\)</span> small, and <span class="math inline">\(.5 \le d &lt; .8\)</span> large.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="one-sample-inference-tests.html#cb7-1"></a>(d &lt;-<span class="st"> </span>rstatix<span class="op">::</span><span class="kw">cohens_d</span>(dep, dep_score <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">mu =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(effsize) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">abs</span>())</span></code></pre></div>
<pre><code>## Cohen&#39;s d 
## 0.3764788</code></pre>
<p>Cohen’s <em>d</em> is 0.38, a small effect.</p>
<p>Make a habit of constructing a plot, just to make sure your head is on straight.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-14-1.png" width="624" /></p>
<p>Now you are ready to report the results.</p>
<blockquote>
<p>A one-sample <em>t</em>-test was run to determine whether depression score in recruited subjects was different from normal, as defined as a depression score of 4.0. Depression scores were normally distributed, as assessed by Shapiro-Wilk’s test (<em>p</em> &gt; .05) and there were no outliers in the data, as assessed by inspection of a boxplot. Data are mean <span class="math inline">\(\pm\)</span> standard deviation, unless otherwise stated. Mean depression score (3.72 <span class="math inline">\(\pm\)</span> 0.74) was lower than the population “normal” depression score of 4.00, a statistically significant difference of 0.28 (95% CI, 0.04 to 0.51), t(39) = 2.38, <em>p</em> = 0.022, <em>d</em> = 0.38.</p>
</blockquote>
</div>
<div id="appendix-deciding-sample-size" class="section level4 unnumbered">
<h4>Appendix: Deciding Sample Size</h4>
<p>Determine the sample size required for a maximum error <span class="math inline">\(\epsilon\)</span> in the estimate by solving the confidence interval equation, <span class="math inline">\(\bar{x} \pm t_{(1 - \alpha){/}2} \frac{s}{\sqrt{n}}\)</span> for <span class="math inline">\(n=\frac{{t_{\alpha/2,n-1}^2se^2}}{{\epsilon^2}}\)</span> . Unfortunately, <span class="math inline">\(t_{\alpha/2,n-1}^2\)</span> is dependent on <span class="math inline">\(n\)</span>, so replace it with <span class="math inline">\(z_{\alpha/2}^2\)</span>. What about <span class="math inline">\(s^2\)</span>? Estimate it from the literature, a pilot study, or using the empirical rule that 95% of the range falls within two standard deviations, <span class="math inline">\(s=range / 4\)</span>.</p>
<p>For example, if the maximum tolerable error is* <span class="math inline">\(\epsilon\)</span> = 3, and <span class="math inline">\(s\)</span> is approximately 10, what sample size produces an <span class="math inline">\(\alpha\)</span> =0.05 confidence level?</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="one-sample-inference-tests.html#cb9-1"></a><span class="kw">ceiling</span>(<span class="kw">qnorm</span>(.<span class="dv">975</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span><span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 43</code></pre>
</div>
</div>
<div id="one-sample-median-wilcoxon-test" class="section level2">
<h2><span class="header-section-number">1.3</span> One-Sample Median Wilcoxon Test</h2>
<p>The Wilcoxon one-sample median test (aka Wilcoxon signed rank test) is a non-parametric alternative to the <em>t</em>-test for cases when the the sampling distribution of the population mean is <em>not</em> normally distributed, but is at least symmetric.</p>
<p>Under the Wilcoxon test, the measured median, <span class="math inline">\(\eta_x\)</span>, approximates the population median, <span class="math inline">\(\eta\)</span>. The method calculates the difference between each value and the hypothesized median, <span class="math inline">\(\eta_0\)</span>, ranks the difference magnitudes, then sums the ranks for the negative and the positive differences, <span class="math inline">\(W+\)</span> and <span class="math inline">\(W-\)</span>. The test compares the smaller of the two sums to a table of critical values.</p>
<p>Here is a case study. A store claims their checkout wait times are <span class="math inline">\(\le\)</span> 4 minutes. You challenge the claim by sampling 6 checkout experiences. The mean wait time was 4.6, but the data may violate normality.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="one-sample-inference-tests.html#cb11-1"></a><span class="kw">data.frame</span>(<span class="dt">wait =</span> wait) <span class="op">%&gt;%</span></span>
<span id="cb11-2"><a href="one-sample-inference-tests.html#cb11-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> wait)) <span class="op">+</span></span>
<span id="cb11-3"><a href="one-sample-inference-tests.html#cb11-3"></a><span class="st">  </span><span class="kw">stat_qq</span>() <span class="op">+</span></span>
<span id="cb11-4"><a href="one-sample-inference-tests.html#cb11-4"></a><span class="st">  </span><span class="kw">stat_qq_line</span>(<span class="dt">col =</span> <span class="st">&quot;goldenrod&quot;</span>) <span class="op">+</span></span>
<span id="cb11-5"><a href="one-sample-inference-tests.html#cb11-5"></a><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></span>
<span id="cb11-6"><a href="one-sample-inference-tests.html#cb11-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Normal Q-Q Plot&quot;</span>)</span></code></pre></div>
<p><img src="statistics_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Shapiro-Wilk rejects the null hypothesis of a normally distributed population.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="one-sample-inference-tests.html#cb12-1"></a><span class="kw">shapiro.test</span>(wait)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  wait
## W = 0.75105, p-value = 0.0204</code></pre>
<p>Use the Wilcoxon test instead.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="one-sample-inference-tests.html#cb14-1"></a>(wt &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(wait, <span class="dt">mu =</span> <span class="dv">4</span>, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>))</span></code></pre></div>
<pre><code>## Warning in wilcox.test.default(wait, mu = 4, alternative = &quot;greater&quot;): cannot
## compute exact p-value with ties</code></pre>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  wait
## V = 14.5, p-value = 0.2309
## alternative hypothesis: true location is greater than 4</code></pre>
<blockquote>
<p>A Wilcoxon Signed-Ranks Test indicated that wait times were <em>not</em> statistically significantly higher than the 4-minute claim, <em>z</em> = 14.5, <em>p</em> = 0.231.</p>
</blockquote>
</div>
<div id="chi-squared-goodness-of-fit-test" class="section level2">
<h2><span class="header-section-number">1.4</span> Chi-Squared Goodness-of-Fit Test</h2>
<p>Use the chi-squared goodness-of-fit test to test whether the observed frequency counts, <span class="math inline">\(O_j\)</span>, of the <span class="math inline">\(J\)</span> levels of a categorical variable differ from the expected frequency counts, <span class="math inline">\(E_j\)</span>. <span class="math inline">\(H_0\)</span> is <span class="math inline">\(O_j = E_j\)</span>. The test applies when the variable is dichotomous, nominal, or ordinal; and the observations are independent. There must also be an expected frequency of at least 5 in each group.</p>
<p>The Pearson goodness-of-fit test statistic is</p>
<p><span class="math display">\[X^2 = \sum \frac{(O_j - E_j)^2}{E_j}\]</span></p>
<p>where <span class="math inline">\(O_j = p_j n\)</span> and <span class="math inline">\(E_j = \pi_j n\)</span>. The sampling distribution of <span class="math inline">\(X^2\)</span> approaches the <span class="math inline">\(\chi_{J-1}^2\)</span> as the sample size <span class="math inline">\(n \rightarrow \infty\)</span>. The assumption that <span class="math inline">\(X^2\)</span> is distributed <span class="math inline">\(\sim \chi^2\)</span> is not quite correct, so you will see researchers subtract .5 from the differences to increase the p-value, the so-called <a href="https://en.wikipedia.org/wiki/Yates%27s_correction_for_continuity">Yates Continuity Correction</a>.</p>
<p><span class="math display">\[X^2 = \sum \frac{(O_j - E_j - 0.5)^2}{E_j}\]</span></p>
<p><span class="math inline">\(X^2 \rightarrow 0\)</span> as the saturated model (the observed data represent the fit of the saturated model, the most complex model possible with the data) proportions approach the expected proportions, <span class="math inline">\(p_j \rightarrow \pi_j\)</span>. The chi-squared test calculates the probability of the occurrence of <span class="math inline">\(X^2\)</span> at least as extreme given that it is a chi-squared random variable with degrees of freedom equal to the number of levels of the variable minus one, <span class="math inline">\(J-1\)</span>. The test is valid when the data are independent (a random sample, or a randomized experiment), and the expected counts in each cell are <span class="math inline">\(\ge\)</span> 5.</p>
<div id="example-with-theoretical-values" class="section level4 unnumbered">
<h4>Example with Theoretical Values</h4>
<p>A researcher crosses tall cut-leaf tomatoes with dwarf potato-leaf tomatoes, then classifies the <em>n</em> = 1,611 offspring’s phenotype. The four phenotypes should occur with relative frequencies 9:3:3:1. The observed frequencies constitute a one-way table.</p>
<p>If you only care about one level (or if the variable is binary) of if, conduct a one-proportion <em>Z</em>-test or an exact binomial test. Otherwise, conduct an exact multinomial test (recommended when <em>n</em> &lt;= 1,000), Pearson’s chi-squared goodness-of-fit test, or a <em>G</em>-test.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-20-1.png" width="624" /></p>
</div>
<div id="conditions-1" class="section level4 unnumbered">
<h4>Conditions</h4>
<p>This is a randomized experiment. The minimum expected frequency was 100, so the chi-squared test of independence is valid.</p>
<p>Had the data violated the <span class="math inline">\(\ge\)</span> 5 condition, you could run an exact test (like the binomial, or in this case, the multinomial), or lump some factor levels together.</p>
</div>
<div id="results-1" class="section level4 unnumbered">
<h4>Results</h4>
<p>You can calculate <span class="math inline">\(X^2\)</span> by hand, and find the probability of a test statistic at least as extreme using the <span class="math inline">\(\chi^2\)</span> distribution with 4-1 = 3 degrees of freedom.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="one-sample-inference-tests.html#cb17-1"></a>(pheno_x2 &lt;-<span class="st"> </span><span class="kw">sum</span>((pheno_obs <span class="op">-</span><span class="st"> </span>pheno_exp)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>pheno_exp))</span>
<span id="cb17-2"><a href="one-sample-inference-tests.html#cb17-2"></a><span class="co">## [1] 9.54652</span></span>
<span id="cb17-3"><a href="one-sample-inference-tests.html#cb17-3"></a>(pheno_p &lt;-<span class="st"> </span><span class="kw">pchisq</span>(<span class="dt">q =</span> pheno_x2, <span class="dt">df =</span> <span class="kw">length</span>(pheno_type) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>))</span>
<span id="cb17-4"><a href="one-sample-inference-tests.html#cb17-4"></a><span class="co">## [1] 0.02284158</span></span></code></pre></div>
<p>That is what <code>chisq.test()</code> does. The function applies the Yates continuity correction by default, so I had to specify <code>correct = FALSE</code> to exclude it. In this case, setting it to <code>TRUE</code> has almost no effect because the sample size is large.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="one-sample-inference-tests.html#cb18-1"></a>(pheno_chisq_test &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(pheno_obs, <span class="dt">p =</span> pheno_pi, <span class="dt">correct =</span> <span class="ot">FALSE</span>))</span></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  pheno_obs
## X-squared = 9.5465, df = 3, p-value = 0.02284</code></pre>
<p>As always, plot the distribution.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-23-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>At this point you can report,</p>
<blockquote>
<p>Of the 1,611 offspring produced from the cross-fertiliation, 956 were <em>tall cut-leaf</em>, 258 were <em>tall potato-leaf</em>, 293 where <em>dwarf cut-leaf</em>, and 104 were <em>dwarf potato-leaf</em>. A chi-square goodness-of-fit test was conducted to determine whether the offspring had the same proportion of phenotypes as the theoretical distribution. The minimum expected frequency was 101. The chi-square goodness-of-fit test indicated that the number of tall cut-leaf, tall potato-leaf, dwarf cut-leaf, and dwarf potato-leaf offspring was statistically significantly different from the proportions expected in the theoretical distribution (<span class="math inline">\(X^2\)</span>(3) = 9.547, <em>p</em> = 0.023).</p>
</blockquote>
<p>If you reject <span class="math inline">\(H_0\)</span>, inspect the residuals to learn which differences contribute most to the rejection. Notice how <span class="math inline">\(X^2\)</span> is a sum of squared standardized cell differences, or “Pearson residuals”,</p>
<p><span class="math display">\[r_i = \frac{o_j - e_j}{\sqrt{e_j}}\]</span></p>
<p>Cells with the largest <span class="math inline">\(|r|\)</span> contribute the most to the total <span class="math inline">\(X^2\)</span>.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="one-sample-inference-tests.html#cb20-1"></a>pheno_chisq_test<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>pheno_chisq_test<span class="op">$</span>statistic</span></code></pre></div>
<pre><code>##     tall cut-leaf  tall potato-leaf    dwarf cut-leaf dwarf potato-leaf 
##        0.28682269        0.67328098        0.02848093        0.01141540</code></pre>
<p>The two “tall” cells contributed over 95% of the <span class="math inline">\(X^2\)</span> test statistic, with the tall potato-leaf accounting for 67%. This aligns with what you’d expect from the bar plot.</p>
</div>
<div id="example-with-distribution" class="section level4 unnumbered">
<h4>Example with Distribution</h4>
<p>You need to reduce the degrees of freedom (df) in the chi-squared goodness-of-fit test by 1 if you test whether the data conform to a particular distribution instead of a set of theoretical values.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="one-sample-inference-tests.html#cb22-1"></a>j &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>)</span>
<span id="cb22-2"><a href="one-sample-inference-tests.html#cb22-2"></a>o &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">19</span>, <span class="dv">26</span>, <span class="dv">29</span>, <span class="dv">13</span>, <span class="dv">10</span>, <span class="dv">3</span>)</span>
<span id="cb22-3"><a href="one-sample-inference-tests.html#cb22-3"></a>childr_n &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>)</span></code></pre></div>
<p>Suppose you sample <em>n</em> = 100 families and count the number of children. The count of children is a Poisson random variable, <span class="math inline">\(J\)</span>, with maximum likelihood estimate <span class="math inline">\(\hat{\lambda} = \sum{j_i O_i} / \sum{O_i}\)</span>. Test whether the observed values can be described as samples from a Poisson random variable. The probabilities for each possible count are</p>
<p><span class="math display">\[f(j; \lambda) = \frac{e^{-\hat{\lambda}} \hat{\lambda}^j}{j!}.\]</span></p>
<p><img src="statistics_files/figure-html/unnamed-chunk-26-1.png" width="624" /></p>
</div>
<div id="conditions-2" class="section level4 unnumbered">
<h4>Conditions</h4>
<p>This is random sampling. The minimum expected frequency was 2, so the data violates the <span class="math inline">\(\ge\)</span> 5 rule. Lump the last two categories into “4-5”.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-27-1.png" width="624" /></p>
<p>The minimum expected frequency was 6, so now the chi-squared test of independence is valid.</p>
</div>
<div id="results-2" class="section level4 unnumbered">
<h4>Results</h4>
<p>Compare the expected values to the observed values with the chi-squared goodness of fit test, but in this case <span class="math inline">\(df = 5 - 1 - 1\)</span> because the estimated parameter <span class="math inline">\(\lambda\)</span> reduces df by 1. You cannot set df in <code>chisq.test()</code>, so perform the test manually.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="one-sample-inference-tests.html#cb23-1"></a>(X2 &lt;-<span class="st"> </span><span class="kw">sum</span>((o <span class="op">-</span><span class="st"> </span>e)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>e))</span>
<span id="cb23-2"><a href="one-sample-inference-tests.html#cb23-2"></a><span class="co">## [1] 7.092968</span></span>
<span id="cb23-3"><a href="one-sample-inference-tests.html#cb23-3"></a>(p.value &lt;-<span class="st"> </span><span class="kw">pchisq</span>(<span class="dt">q =</span> X2, <span class="dt">df =</span> <span class="kw">length</span>(j) <span class="op">-</span><span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>))</span>
<span id="cb23-4"><a href="one-sample-inference-tests.html#cb23-4"></a><span class="co">## [1] 0.06899286</span></span></code></pre></div>
<p><img src="statistics_files/figure-html/unnamed-chunk-29-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>At this point you can report,</p>
<blockquote>
<p>Of the 100 families sampled, 19 had no children, 26 had one child, 29 had two children, 13 had three children, and 13 had 4 or 5 children. A chi-square goodness-of-fit test was conducted to determine whether the observed family sizes follow a Poisson distribution. The minimum expected frequency was 13. The chi-square goodness-of-fit test indicated that the number of children was not statistically significantly different from the proportions expected in the Poisson distribution (<span class="math inline">\(X^2\)</span>(3) = 7.093, <em>p</em> = 0.069).</p>
</blockquote>
</div>
</div>
<div id="g-test" class="section level2">
<h2><span class="header-section-number">1.5</span> G-Test</h2>
<p>The G-test is a likelihood-ratio statistical significance test increasingly used instead of chi-squared tests. The test statistic is defined</p>
<p><span class="math display">\[G^2 = 2 \sum O_j \log \left[ \frac{O_j}{E_j} \right]\]</span></p>
<p>where the 2 multiplier asymptotically aligns with the chi-squared test formula. <em>G</em> is distributed <span class="math inline">\(\sim \chi^2\)</span>, with the same number of degrees of freedom as in the corresponding chi-squared test. In fact, the chi-squared test statistic is a second order Taylor expansion of the natural logarithm around 1.</p>
<p>Returning to the phenotype case study in the chi-squared goodness-of-fit test section, you can calculate the <span class="math inline">\(G^2\)</span> test statistic and probability by hand.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="one-sample-inference-tests.html#cb24-1"></a>(pheno_g2 &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(pheno_obs <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(pheno_obs <span class="op">/</span><span class="st"> </span>pheno_exp)))</span>
<span id="cb24-2"><a href="one-sample-inference-tests.html#cb24-2"></a><span class="co">## [1] 9.836806</span></span>
<span id="cb24-3"><a href="one-sample-inference-tests.html#cb24-3"></a>(<span class="kw">pchisq</span>(<span class="dt">q =</span> pheno_g2, <span class="dt">df =</span> <span class="kw">length</span>(pheno_type) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>))</span>
<span id="cb24-4"><a href="one-sample-inference-tests.html#cb24-4"></a><span class="co">## [1] 0.02000552</span></span></code></pre></div>
<p>This is pretty close to the <span class="math inline">\(X^2\)</span> = 9.547, <em>p</em> = 0.023 using the chi-squared goodness-of-fit test. The <code>DescTools::GTest()</code> function to conducts a G-test.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="one-sample-inference-tests.html#cb25-1"></a>DescTools<span class="op">::</span><span class="kw">GTest</span>(pheno_obs, <span class="dt">p =</span> pheno_pi)</span></code></pre></div>
<pre><code>## 
##  Log likelihood ratio (G-test) goodness of fit test
## 
## data:  pheno_obs
## G = 9.8368, X-squared df = 3, p-value = 0.02001</code></pre>
<p>According to the function documentation, the G-test is not usually used for 2x2 tables.</p>
</div>
<div id="pairwise.prop.test" class="section level2">
<h2><span class="header-section-number">1.6</span> pairwise.prop.test</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="one-sample-inference-tests.html#cb27-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb27-2"><a href="one-sample-inference-tests.html#cb27-2"></a>M &lt;-<span class="st"> </span><span class="dv">3573</span></span>
<span id="cb27-3"><a href="one-sample-inference-tests.html#cb27-3"></a>F &lt;-<span class="st"> </span><span class="dv">4177</span></span>
<span id="cb27-4"><a href="one-sample-inference-tests.html#cb27-4"></a>dat &lt;-<span class="st"> </span><span class="kw">tribble</span>(</span>
<span id="cb27-5"><a href="one-sample-inference-tests.html#cb27-5"></a>  <span class="op">~</span>gender, <span class="op">~</span>src, <span class="op">~</span>Y, <span class="op">~</span>N,</span>
<span id="cb27-6"><a href="one-sample-inference-tests.html#cb27-6"></a>  <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Indeed&quot;</span>, <span class="dv">1699</span>, M<span class="dv">-1699</span>,</span>
<span id="cb27-7"><a href="one-sample-inference-tests.html#cb27-7"></a>  <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;LinkedIn&quot;</span>, <span class="dv">1755</span>, M<span class="dv">-1755</span>,</span>
<span id="cb27-8"><a href="one-sample-inference-tests.html#cb27-8"></a>  <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Google&quot;</span>, <span class="dv">1578</span>, M<span class="dv">-1578</span>,</span>
<span id="cb27-9"><a href="one-sample-inference-tests.html#cb27-9"></a>  <span class="st">&quot;Female&quot;</span>, <span class="st">&quot;Indeed&quot;</span>, <span class="dv">2554</span>, F<span class="dv">-2554</span>,</span>
<span id="cb27-10"><a href="one-sample-inference-tests.html#cb27-10"></a>  <span class="st">&quot;Female&quot;</span>, <span class="st">&quot;LinkedIn&quot;</span>, <span class="dv">1914</span>, F<span class="dv">-1914</span>,</span>
<span id="cb27-11"><a href="one-sample-inference-tests.html#cb27-11"></a>  <span class="st">&quot;Female&quot;</span>, <span class="st">&quot;Google&quot;</span>, <span class="dv">1694</span>, F<span class="dv">-1694</span></span>
<span id="cb27-12"><a href="one-sample-inference-tests.html#cb27-12"></a>)</span>
<span id="cb27-13"><a href="one-sample-inference-tests.html#cb27-13"></a><span class="kw">prop.test</span>(<span class="dt">x =</span> dat<span class="op">$</span>Y, <span class="dt">n =</span> dat<span class="op">$</span>Y <span class="op">+</span><span class="st"> </span>dat<span class="op">$</span>N)</span></code></pre></div>
<pre><code>## 
##  6-sample test for equality of proportions without continuity
##  correction
## 
## data:  dat$Y out of dat$Y + dat$N
## X-squared = 412.66, df = 5, p-value &lt; 2.2e-16
## alternative hypothesis: two.sided
## sample estimates:
##    prop 1    prop 2    prop 3    prop 4    prop 5    prop 6 
## 0.4755108 0.4911839 0.4416457 0.6114436 0.4582236 0.4055542</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="one-sample-inference-tests.html#cb29-1"></a><span class="kw">pairwise.prop.test</span>(<span class="dt">x =</span> dat<span class="op">$</span>Y, <span class="dt">n =</span> dat<span class="op">$</span>Y <span class="op">+</span><span class="st"> </span>dat<span class="op">$</span>N)</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Pairwise comparison of proportions 
## 
## data:  dat$Y out of dat$Y + dat$N 
## 
##   1       2       3       4       5      
## 2 0.40250 -       -       -       -      
## 3 0.02026 0.00021 -       -       -      
## 4 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 -       -      
## 5 0.40250 0.02026 0.40250 &lt; 2e-16 -      
## 6 6.3e-09 4.8e-13 0.00873 &lt; 2e-16 1.1e-05
## 
## P value adjustment method: holm</code></pre>
</div>
<div id="exact-tests" class="section level2">
<h2><span class="header-section-number">1.7</span> Exact Tests</h2>
<p>If you are confident that your variable can be described by a particular distribution, then you can run a so-called “exact” test comparing your measured value to a hypothesized value, or defining a 95% CI around the measured value.</p>
<div id="one-sample-poisson-test" class="section level3">
<h3><span class="header-section-number">1.7.1</span> One-Sample Poisson Test</h3>
<p>If <span class="math inline">\(X\)</span> is the number of successes in <span class="math inline">\(n\)</span> (many) trials when the probability of success <span class="math inline">\(\lambda / n\)</span> is small, then <span class="math inline">\(X\)</span> is a random variable with a Poisson distribution,</p>
<p><span class="math display">\[f(x;\lambda) = \frac{e^{-\lambda} \lambda^x}{x!} \hspace{1cm} x \in (0, 1, ...), \hspace{2mm} \lambda &gt; 0\]</span></p>
<p>with <span class="math inline">\(E(X)=\lambda\)</span> and <span class="math inline">\(Var(X) = \lambda\)</span>.</p>
<p>The Poisson likelihood function is</p>
<p><span class="math display">\[L(\lambda; x) = \prod_{i=1}^N f(x_i; \lambda) = \prod_{i=1}^N \frac{e^{-\lambda} \lambda^x_i}{x_i !} = \frac{e^{-n \lambda} \lambda^{\sum x_i}}{\prod x_i}.\]</span></p>
<p>Its log-likelihood function is</p>
<p><span class="math display">\[l(\lambda; x) = \sum_{i=1}^N x_i \log \lambda - n \lambda.\]</span></p>
<p>The log-likelihood function is maximized at</p>
<p><span class="math display">\[\hat{\lambda} = \sum_{i=1}^N x_i / n.\]</span></p>
<p>Thus, for a Poisson random variable, the maximum likelihood estimator (MLE) for <span class="math inline">\(\lambda\)</span> is just the sample mean.</p>
<p>Poisson sampling is used to model counts of events that occur randomly over a <em>fixed period of time</em>.</p>
<p>Here is a simple analysis of data from a Poisson process. Data set <code>dat</code> contains frequencies of goal counts during the first round matches of the 2002 World Cup.</p>
<p>Here is a case study. A researcher is analyzing World Cup play using a sample consisting of the 95 matches in the first round of the 2002 World Cup. The average match produced 1.38 <span class="math inline">\(\pm\)</span> 1.28 goals, lower than the 1.5 historical average during World Cup play. The null hypothesis is that the sample is representative of the overall population. Should you reject <span class="math inline">\(H_0\)</span>?</p>
</div>
<div id="conditions-3" class="section level3 unnumbered">
<h3>Conditions</h3>
<ul>
<li>The events must be independent of each other. E.g., if you are counting goals scored during the first round of the World Cup, you must assume the goals scored in one game do not affect the number of goals scored in another game.</li>
<li>The expected value of each data-generator must be the same (homogeneity). E.g., you must assume their is no relationship between points scored and which teams are playing. In practice, this assumption is often not met. E.g., some teams are better than others, the weather can affect scoring, etc. When the homogeneity condition fails, the distribution variance tends to be larger than the mean, a conditional called <em>overdispersion</em>.</li>
</ul>
</div>
<div id="results-3" class="section level3 unnumbered">
<h3>Results</h3>
<p>Conduct the exact Poisson test. To get a 95% CI around the <em>difference</em> (instead of around the estimate), run the test using the difference, <span class="math inline">\(\lambda_0 - \lambda\)</span>, and leave r at its default of 1.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="one-sample-inference-tests.html#cb31-1"></a>(pois_val &lt;-<span class="st"> </span><span class="kw">poisson.test</span>(<span class="dt">x =</span> <span class="kw">sum</span>(dat_pois<span class="op">$</span>goals <span class="op">*</span><span class="st"> </span>dat_pois<span class="op">$</span>freq), </span>
<span id="cb31-2"><a href="one-sample-inference-tests.html#cb31-2"></a>                          <span class="dt">T =</span> <span class="kw">sum</span>(dat_pois<span class="op">$</span>freq), <span class="dt">r =</span> <span class="fl">1.5</span>))</span></code></pre></div>
<pre><code>## 
##  Exact Poisson test
## 
## data:  sum(dat_pois$goals * dat_pois$freq) time base: sum(dat_pois$freq)
## number of events = 131, time base = 95, p-value = 0.3567
## alternative hypothesis: true event rate is not equal to 1.5
## 95 percent confidence interval:
##  1.152935 1.636315
## sample estimates:
## event rate 
##   1.378947</code></pre>
<p>The difference is <em>not</em> statistically different from 0 at the <em>p</em> = .05 level.</p>
<p>Construct a plot showing the 95% CI around the hypothesized value. <em>I’m not sure if you should build it around the hypothesized value to show that the estimate is not within its confidence interval, or around the measured value to show that the confidence interval does not contain the hypothesized value.</em> For a Poisson distribution, I built the distribution around the expected value, <span class="math inline">\(n\lambda\)</span>, not the rate, <span class="math inline">\(\lambda\)</span>.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-35-1.png" width="624" /></p>
<p>I think you could report these results like this.</p>
<blockquote>
<p>A one-sample exact Poisson test was run to determine whether the number of goals scored in the first round of the 2002 World Cup was different from past World Cups, 1.5. Depression scores were normally distributed, as assessed by Shapiro-Wilk’s test (<em>p</em> &gt; .05) and there were no outliers in the data, as assessed by inspection of a boxplot. Data are mean <span class="math inline">\(\pm\)</span> standard deviation, unless otherwise stated. Mean depression score (3.72 <span class="math inline">\(\pm\)</span> 0.74) was lower than the population “normal” depression score of 4.00, a statistically significant difference of 0.28 (95% CI, 0.04 to 0.51), t(39) = 2.38, <em>p</em> = 0.022, <em>d</em> = 0.38.</p>
</blockquote>
<p>The 0.95 CI is <span class="math inline">\(\lambda \pm z_{.05/2} \sqrt{\lambda / n}\)</span></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="one-sample-inference-tests.html#cb33-1"></a><span class="co"># n &lt;- sum(dat$freq)</span></span>
<span id="cb33-2"><a href="one-sample-inference-tests.html#cb33-2"></a><span class="co"># z &lt;- qnorm(0.975)</span></span>
<span id="cb33-3"><a href="one-sample-inference-tests.html#cb33-3"></a><span class="co"># se &lt;- sqrt(lambda / n)</span></span>
<span id="cb33-4"><a href="one-sample-inference-tests.html#cb33-4"></a><span class="co"># paste0(&quot;[&quot;, round(lambda - z*se, 2), &quot;, &quot;, round(lambda + z*se, 2),&quot;]&quot;)</span></span></code></pre></div>
<p>The expected probability of scoring 2 goals in a match is <span class="math inline">\(\frac{e^{-1.38} 1.38^2}{2!} = 0.239\)</span>.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="one-sample-inference-tests.html#cb34-1"></a><span class="kw">dpois</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">lambda =</span> lambda)</span></code></pre></div>
<pre><code>## [1] 0.2660914</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="one-sample-inference-tests.html#cb36-1"></a>events &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb36-2"><a href="one-sample-inference-tests.html#cb36-2"></a>density &lt;-<span class="st"> </span><span class="kw">dpois</span>(<span class="dt">x =</span> events, <span class="dt">lambda =</span> <span class="dv">3</span>)</span>
<span id="cb36-3"><a href="one-sample-inference-tests.html#cb36-3"></a>prob &lt;-<span class="st"> </span><span class="kw">ppois</span>(<span class="dt">q =</span> events, <span class="dt">lambda =</span> <span class="dv">3</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb36-4"><a href="one-sample-inference-tests.html#cb36-4"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(events, density, prob)</span>
<span id="cb36-5"><a href="one-sample-inference-tests.html#cb36-5"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(events), <span class="dt">y =</span> density)) <span class="op">+</span></span>
<span id="cb36-6"><a href="one-sample-inference-tests.html#cb36-6"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb36-7"><a href="one-sample-inference-tests.html#cb36-7"></a><span class="st">  </span><span class="kw">geom_text</span>(</span>
<span id="cb36-8"><a href="one-sample-inference-tests.html#cb36-8"></a>    <span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(density, <span class="dv">3</span>), <span class="dt">y =</span> density <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>),</span>
<span id="cb36-9"><a href="one-sample-inference-tests.html#cb36-9"></a>    <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb36-10"><a href="one-sample-inference-tests.html#cb36-10"></a>    <span class="dt">size =</span> <span class="dv">3</span>,</span>
<span id="cb36-11"><a href="one-sample-inference-tests.html#cb36-11"></a>    <span class="dt">vjust =</span> <span class="dv">0</span></span>
<span id="cb36-12"><a href="one-sample-inference-tests.html#cb36-12"></a>  ) <span class="op">+</span></span>
<span id="cb36-13"><a href="one-sample-inference-tests.html#cb36-13"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb36-14"><a href="one-sample-inference-tests.html#cb36-14"></a>    <span class="dt">data =</span> df, </span>
<span id="cb36-15"><a href="one-sample-inference-tests.html#cb36-15"></a>    <span class="kw">aes</span>(<span class="dt">x =</span> events, <span class="dt">y =</span> prob<span class="op">/</span><span class="dv">4</span>), </span>
<span id="cb36-16"><a href="one-sample-inference-tests.html#cb36-16"></a>    <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb36-17"><a href="one-sample-inference-tests.html#cb36-17"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span>.<span class="op">*</span><span class="dv">4</span>, <span class="dt">name =</span> <span class="st">&quot;Cum Prob&quot;</span>)) <span class="op">+</span></span>
<span id="cb36-18"><a href="one-sample-inference-tests.html#cb36-18"></a><span class="co">#  theme_mf() +</span></span>
<span id="cb36-19"><a href="one-sample-inference-tests.html#cb36-19"></a><span class="co">#  scale_fill_mf() +</span></span>
<span id="cb36-20"><a href="one-sample-inference-tests.html#cb36-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;PMF and CDF of Poisson Distribution&quot;</span>,</span>
<span id="cb36-21"><a href="one-sample-inference-tests.html#cb36-21"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Poisson(3).&quot;</span>,</span>
<span id="cb36-22"><a href="one-sample-inference-tests.html#cb36-22"></a>       <span class="dt">x =</span> <span class="st">&quot;Events (x)&quot;</span>,</span>
<span id="cb36-23"><a href="one-sample-inference-tests.html#cb36-23"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="statistics_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>The expected probability of scoring 2 to 4 goals in a match is</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="one-sample-inference-tests.html#cb37-1"></a><span class="kw">sum</span>(<span class="kw">dpois</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>), <span class="dt">lambda =</span> lambda))</span></code></pre></div>
<pre><code>## [1] 0.48922</code></pre>
<p>Or, using the cumulative probability distribution,</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="one-sample-inference-tests.html#cb39-1"></a><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">lambda =</span> lambda) <span class="op">-</span><span class="st"> </span><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">1</span>, <span class="dt">lambda =</span> lambda)</span></code></pre></div>
<pre><code>## [1] 0.48922</code></pre>
<p>How well does the Poisson distribution fit the 2002 World Cup data?</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="one-sample-inference-tests.html#cb41-1"></a><span class="co"># dat_pois %&gt;%</span></span>
<span id="cb41-2"><a href="one-sample-inference-tests.html#cb41-2"></a><span class="co">#   mutate(pred = n * dpois(x = goals, lambda = lambda)) %&gt;%</span></span>
<span id="cb41-3"><a href="one-sample-inference-tests.html#cb41-3"></a><span class="co">#   rename(obs = freq) %&gt;%</span></span>
<span id="cb41-4"><a href="one-sample-inference-tests.html#cb41-4"></a><span class="co">#   pivot_longer(cols = -goals) %&gt;%</span></span>
<span id="cb41-5"><a href="one-sample-inference-tests.html#cb41-5"></a><span class="co">#   ggplot(aes(x = goals, y = value, color = name)) +</span></span>
<span id="cb41-6"><a href="one-sample-inference-tests.html#cb41-6"></a><span class="co">#   geom_point() +</span></span>
<span id="cb41-7"><a href="one-sample-inference-tests.html#cb41-7"></a><span class="co"># #  theme_mf() +</span></span>
<span id="cb41-8"><a href="one-sample-inference-tests.html#cb41-8"></a><span class="co"># #  scale_color_mf() +</span></span>
<span id="cb41-9"><a href="one-sample-inference-tests.html#cb41-9"></a><span class="co">#   geom_smooth(se = FALSE) +</span></span>
<span id="cb41-10"><a href="one-sample-inference-tests.html#cb41-10"></a><span class="co">#   labs(</span></span>
<span id="cb41-11"><a href="one-sample-inference-tests.html#cb41-11"></a><span class="co">#     title = &quot;Poisson Dist: Observed vs Expected&quot;,</span></span>
<span id="cb41-12"><a href="one-sample-inference-tests.html#cb41-12"></a><span class="co">#     color = &quot;&quot;,</span></span>
<span id="cb41-13"><a href="one-sample-inference-tests.html#cb41-13"></a><span class="co">#     y = &quot;frequencey&quot;</span></span>
<span id="cb41-14"><a href="one-sample-inference-tests.html#cb41-14"></a><span class="co">#   )</span></span></code></pre></div>
<p>It fits the data pretty good!</p>
</div>
<div id="one-sample-binomial-test" class="section level3">
<h3><span class="header-section-number">1.7.2</span> One-Sample Binomial Test</h3>
<p>For a frequency variable you usually use the sample proportion of successes of group <span class="math inline">\(i\)</span>, <span class="math inline">\(p_i\)</span>, as an estimate of the population proportion, <span class="math inline">\(\pi_i\)</span>.</p>
<p>Use the one-sample <em>z</em>-test to evaluate the sample proportion of successes of group <span class="math inline">\(i\)</span> of a binary or multinomial variable. This test is also called the normal approximation method, and the Wald method.</p>
<p>The <em>z</em>-test uses the sample proportion of group <span class="math inline">\(j\)</span>, <span class="math inline">\(p_j\)</span>, as an estimate of the population proportion <span class="math inline">\(\pi_j\)</span> to evaluate an hypothesized population proportion <span class="math inline">\(\pi_{0j}\)</span> and/or construct a <span class="math inline">\((1−\alpha)\%\)</span> confidence interval around <span class="math inline">\(p_j\)</span> to estimate <span class="math inline">\(\pi_j\)</span> within a margin of error <span class="math inline">\(\epsilon\)</span>.</p>
<p>The <em>z</em>-test is intuitive to learn, but it only applies when the central limit theorem conditions hold:</p>
<ul>
<li>the sample is independently drawn, meaning random assignment (experiments) or random sampling without replacement from <span class="math inline">\(n &lt; 10\%\)</span> of the population (observational studies),</li>
<li>there are at least <span class="math inline">\(n\pi \ge 5\)</span> successes and <span class="math inline">\(n(1 − \pi) \ge 5\)</span> failures,</li>
<li>the sample size is <span class="math inline">\(n \ge 30\)</span>, and</li>
<li>the probability of success is not extreme, <span class="math inline">\(0.2 &lt; \pi &lt; 0.8\)</span>.</li>
</ul>
<p>If these conditions hold, the sampling distribution of <span class="math inline">\(\pi\)</span> is normally distributed around <span class="math inline">\(p\)</span> with standard error <span class="math inline">\(se_p = \frac{s_p}{\sqrt{n}} = \frac{\sqrt{p(1−p)}}{\sqrt{n}}\)</span>. The measured values <span class="math inline">\(p\)</span> and <span class="math inline">\(s_p\)</span> approximate the population values <span class="math inline">\(\pi\)</span> and <span class="math inline">\(\sigma_\pi\)</span>. You can define a <span class="math inline">\((1 − \alpha)\%\)</span> confidence interval as <span class="math inline">\(p \pm z_{\alpha / 2}se_p\)</span>. Test the hypothesis of <span class="math inline">\(\pi = \pi_0\)</span> with test statistic <span class="math inline">\(z = \frac{p − \pi_0}{se_{\pi_0}}\)</span> where <span class="math inline">\(se_{\pi_0} = \frac{s_{\pi_0}}{\sqrt{n}} = \frac{\sqrt{{\pi_0}(1−{\pi_0})}}{\sqrt{n}}\)</span>.</p>
<p>In the phenotype example above, you might test whether tall cut-leaf tomatoes occurred in the expected proportion, <span class="math inline">\(\pi_0 = 9 / (9 + 3 + 3 + 1) = 0.5625\)</span>. The sample is a random assignment experiment with <span class="math inline">\(956 \ge 5\)</span> successes and <span class="math inline">\(1611 - 956 = 655 \ge 5\)</span> failures, sample size <span class="math inline">\(n = 1611 \ge 30\)</span>, and probability of success <span class="math inline">\(0.2 &lt; 0.5625 &lt; 0.8\)</span>, so the <em>Z</em>-test is valid.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="one-sample-inference-tests.html#cb42-1"></a><span class="kw">prop.test</span>(<span class="dv">956</span>, <span class="dv">1611</span>, <span class="fl">0.5625</span>, <span class="st">&quot;two.sided&quot;</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  956 out of 1611, null probability 0.5625
## X-squared = 6.2586, df = 1, p-value = 0.01236
## alternative hypothesis: true p is not equal to 0.5625
## 95 percent confidence interval:
##  0.5692397 0.6171563
## sample estimates:
##         p 
## 0.5934202</code></pre>
<p>The first thing you’ll notice is that <code>prop.test()</code> performs a chi-squared goodness-of-fit test, not a one-proportion <em>Z</em>-test!</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="one-sample-inference-tests.html#cb44-1"></a><span class="kw">chisq.test</span>(<span class="kw">c</span>(<span class="dv">956</span>, <span class="dv">1611-956</span>), <span class="dt">p =</span> <span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span>(<span class="dv">9</span><span class="op">+</span><span class="dv">3</span><span class="op">+</span><span class="dv">3</span><span class="op">+</span><span class="dv">1</span>), <span class="dv">7</span><span class="op">/</span>(<span class="dv">9</span><span class="op">+</span><span class="dv">3</span><span class="op">+</span><span class="dv">3</span><span class="op">+</span><span class="dv">1</span>)), <span class="dt">correct =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  c(956, 1611 - 956)
## X-squared = 6.2586, df = 1, p-value = 0.01236</code></pre>
<p>It turns out <span class="math inline">\(P(\chi^2 &gt; X^2)\)</span> equals <span class="math inline">\(2 \cdot P(Z &gt; z).\)</span> Here is the manual calculation of the chi-squared test statistic <span class="math inline">\(X^2\)</span> and resulting <em>p</em>-value on 1 dof.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="one-sample-inference-tests.html#cb46-1"></a>pi_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="dv">9</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">9</span><span class="op">+</span><span class="dv">3</span><span class="op">+</span><span class="dv">3</span><span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb46-2"><a href="one-sample-inference-tests.html#cb46-2"></a>p &lt;-<span class="st"> </span><span class="dv">956</span> <span class="op">/</span><span class="st"> </span><span class="dv">1611</span></span>
<span id="cb46-3"><a href="one-sample-inference-tests.html#cb46-3"></a></span>
<span id="cb46-4"><a href="one-sample-inference-tests.html#cb46-4"></a>observed &lt;-<span class="st"> </span><span class="kw">c</span>(p, <span class="dv">1</span><span class="op">-</span>p) <span class="op">*</span><span class="st"> </span><span class="dv">1611</span></span>
<span id="cb46-5"><a href="one-sample-inference-tests.html#cb46-5"></a>expected &lt;-<span class="st"> </span><span class="kw">c</span>(pi_<span class="dv">0</span>, <span class="dv">1</span><span class="op">-</span>pi_<span class="dv">0</span>) <span class="op">*</span><span class="st"> </span><span class="dv">1611</span></span>
<span id="cb46-6"><a href="one-sample-inference-tests.html#cb46-6"></a></span>
<span id="cb46-7"><a href="one-sample-inference-tests.html#cb46-7"></a>X2 &lt;-<span class="st"> </span><span class="kw">sum</span>((observed <span class="op">-</span><span class="st"> </span>expected)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>expected)</span>
<span id="cb46-8"><a href="one-sample-inference-tests.html#cb46-8"></a><span class="kw">pchisq</span>(X2, <span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.01235885</code></pre>
<p>And here is the manual calculation of the <em>Z</em>-test statistic <span class="math inline">\(z\)</span> and resulting <em>p</em>-value.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="one-sample-inference-tests.html#cb48-1"></a>se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(pi_<span class="dv">0</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>pi_<span class="dv">0</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">1611</span>)</span>
<span id="cb48-2"><a href="one-sample-inference-tests.html#cb48-2"></a>z &lt;-<span class="st"> </span>(p <span class="op">-</span><span class="st"> </span>pi_<span class="dv">0</span>) <span class="op">/</span><span class="st"> </span>se</span>
<span id="cb48-3"><a href="one-sample-inference-tests.html#cb48-3"></a><span class="kw">pnorm</span>(z, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.01235885</code></pre>
<p>The 95% CI presented by <code>prop.test()</code> is also not the <span class="math inline">\(p \pm z_{\alpha / 2}se_p\)</span> Wald interval; it is the <em>Wilson</em> interval!</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="one-sample-inference-tests.html#cb50-1"></a>DescTools<span class="op">::</span><span class="kw">BinomCI</span>(<span class="dv">956</span>, <span class="dv">1611</span>, <span class="dt">method =</span> <span class="st">&quot;wilson&quot;</span>)</span></code></pre></div>
<pre><code>##            est    lwr.ci    upr.ci
## [1,] 0.5934202 0.5692397 0.6171563</code></pre>
<p>There are a lot of methods (<em>see</em> <code>?DescTools::BinomCI</code>), and <em>Wilson</em> is the one Agresti-Coull recommends. If you want <em>Wald</em>, use <code>DescTools::BinomCI()</code> with <code>method = "wald"</code>.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="one-sample-inference-tests.html#cb52-1"></a>DescTools<span class="op">::</span><span class="kw">BinomCI</span>(<span class="dv">956</span>, <span class="dv">1611</span>, <span class="dt">method =</span> <span class="st">&quot;wald&quot;</span>)</span></code></pre></div>
<pre><code>##            est    lwr.ci   upr.ci
## [1,] 0.5934202 0.5694344 0.617406</code></pre>
<p>This matches the manual calculation below.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="one-sample-inference-tests.html#cb54-1"></a>z_crit =<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">.05</span><span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb54-2"><a href="one-sample-inference-tests.html#cb54-2"></a>se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">1611</span>)</span>
<span id="cb54-3"><a href="one-sample-inference-tests.html#cb54-3"></a></span>
<span id="cb54-4"><a href="one-sample-inference-tests.html#cb54-4"></a>(CI &lt;-<span class="st"> </span><span class="kw">c</span>(p <span class="op">-</span><span class="st"> </span>z_crit<span class="op">*</span>se, p <span class="op">+</span><span class="st"> </span>z_crit<span class="op">*</span>se))</span></code></pre></div>
<pre><code>## [1] 0.5694344 0.6174060</code></pre>
<p><code>prop.test()</code> (and <code>chissq.test()</code>) reported a <em>p</em>-value of 0.01236, so you can reject the null hypothesis that <span class="math inline">\(\pi = 0.5625\)</span>. It’s good practice to plot this out to make sure your head is on straight.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-49-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Incidentally, if you have a margin of error requirement, you can back into the required sample size to achieve it. Just solve the margin of error equation <span class="math inline">\(\epsilon = z_{\alpha/2}^2 = \sqrt{\frac{\pi_0(1-\pi_0)}{n}}\)</span> for <span class="math inline">\(n = \frac{z_{\alpha/2}^2 \pi_0(1-\pi_0)}{\epsilon^2}.\)</span></p>
</div>
<div id="fishers-exact-test" class="section level3">
<h3><span class="header-section-number">1.7.3</span> Fisher’s Exact Test</h3>
<p>The one-sample <em>t</em> test applies when the sampling distribution of the population mean is normally distributed and there are no significant outliers. Unlike the <em>z</em> test, the population variance can be unknown. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large <span class="math inline">\((n &gt;= 30)\)</span>, as follows from the central limit theorem.</p>
<p>Under the <em>t</em> test method, the measured mean, <span class="math inline">\(\bar{x}\)</span>, approximates the population mean, <span class="math inline">\(\mu\)</span>. The sample standard deviation, <span class="math inline">\(s\)</span>, estimates the unknown population standard deviation, <span class="math inline">\(\sigma\)</span>. The resulting sampling distribution has a <em>t</em> distribution centered at <span class="math inline">\(\mu\)</span> with standard error <span class="math inline">\(se_\bar{x} = \frac{s}{\sqrt{n}}\)</span>. Define a <span class="math inline">\((1 - \alpha)\%\)</span> confidence interval as <span class="math inline">\(\bar{x} \pm t_{(1 - \alpha){/}2} se_\bar{x}\)</span> and/or test <span class="math inline">\(H_0: \mu = \mu_0\)</span> with test statistic <span class="math inline">\(T = \frac{\bar{x} - \mu_0}{se_\bar{x}}\)</span>.</p>
<p>Here is a case study. A researcher recruits a random sample of <em>n</em> = 40 people to participate in a study about depression intervention. The researcher measures the participants’ depression level prior to the study. The mean depression score (3.72 <span class="math inline">\(\pm\)</span> 0.74) was lower than the population ‘normal’ depression score of 4.0. The null hypothesis is that the sample is representative of the overall population. Should you reject <span class="math inline">\(H_0\)</span>?</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="one-sample-inference-tests.html#cb56-1"></a>dep <span class="op">%&gt;%</span><span class="st"> </span>gtsummary<span class="op">::</span><span class="kw">tbl_summary</span>(<span class="dt">statistic =</span> <span class="kw">list</span>(<span class="kw">all_continuous</span>() <span class="op">~</span><span class="st"> &quot;{mean} ({sd})&quot;</span>))</span></code></pre></div>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#bmocruhkoi .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#bmocruhkoi .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#bmocruhkoi .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#bmocruhkoi .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#bmocruhkoi .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bmocruhkoi .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#bmocruhkoi .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#bmocruhkoi .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#bmocruhkoi .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#bmocruhkoi .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#bmocruhkoi .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#bmocruhkoi .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#bmocruhkoi .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#bmocruhkoi .gt_from_md > :first-child {
  margin-top: 0;
}

#bmocruhkoi .gt_from_md > :last-child {
  margin-bottom: 0;
}

#bmocruhkoi .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#bmocruhkoi .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#bmocruhkoi .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#bmocruhkoi .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#bmocruhkoi .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#bmocruhkoi .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#bmocruhkoi .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#bmocruhkoi .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bmocruhkoi .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#bmocruhkoi .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#bmocruhkoi .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#bmocruhkoi .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#bmocruhkoi .gt_left {
  text-align: left;
}

#bmocruhkoi .gt_center {
  text-align: center;
}

#bmocruhkoi .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#bmocruhkoi .gt_font_normal {
  font-weight: normal;
}

#bmocruhkoi .gt_font_bold {
  font-weight: bold;
}

#bmocruhkoi .gt_font_italic {
  font-style: italic;
}

#bmocruhkoi .gt_super {
  font-size: 65%;
}

#bmocruhkoi .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="bmocruhkoi" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>N = 40</strong><sup class="gt_footnote_marks">1</sup></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr>
      <td class="gt_row gt_left">dep_score</td>
      <td class="gt_row gt_center">3.72 (0.74)</td>
    </tr>
  </tbody>
  
  <tfoot>
    <tr class="gt_footnotes">
      <td colspan="2">
        <p class="gt_footnote">
          <sup class="gt_footnote_marks">
            <em>1</em>
          </sup>
           
          Statistics presented: Mean (SD)
          <br />
        </p>
      </td>
    </tr>
  </tfoot>
</table></div>
<div id="conditions-4" class="section level4 unnumbered">
<h4>Conditions</h4>
<p>The one-sample <em>t</em> test applies when the variable is continuous and the observations are independent. Additionally, there are two conditions related to the data distribution. If either condition fails, try the suggested work-arounds or use the non-parametric [Wilcoxon 1-Sample Median Test for Numeric Var] instead.</p>
<ol style="list-style-type: decimal">
<li><strong>Outliers</strong>. There should be no significant outliers. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data.</li>
<li><strong>Normality</strong>. Values should be <em>nearly</em> normally distributed (“nearly” because the <em>t</em>-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data.</li>
</ol>
<div id="outliers-1" class="section level5 unnumbered">
<h5>Outliers</h5>
<p>Assess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. The boxplot shows no outliers.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>If the outliers might are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you have a couple options before reverting to Wilcoxon.</p>
<ul>
<li>Transform the variable. Don’t do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult.</li>
<li>Leave it in if it doesn’t affect the conclusion (compared to taking it out).</li>
</ul>
</div>
<div id="normality-1" class="section level5 unnumbered">
<h5>Normality</h5>
<p>Assume the population is normally distributed if <em>n</em> <span class="math inline">\(\ge\)</span> 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still don’t feel confident about normality, run a [Shapiro-Wilk Test].</p>
<p>The data set has <em>n</em> = 40 observations, so you can assume normality. Here is a QQ plot anyway. The QQ plot indicates normality.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="one-sample-inference-tests.html#cb57-1"></a>dep <span class="op">%&gt;%</span></span>
<span id="cb57-2"><a href="one-sample-inference-tests.html#cb57-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> dep_score)) <span class="op">+</span></span>
<span id="cb57-3"><a href="one-sample-inference-tests.html#cb57-3"></a><span class="st">  </span><span class="kw">stat_qq</span>() <span class="op">+</span></span>
<span id="cb57-4"><a href="one-sample-inference-tests.html#cb57-4"></a><span class="st">  </span><span class="kw">stat_qq_line</span>(<span class="dt">col =</span> <span class="st">&quot;goldenrod&quot;</span>) <span class="op">+</span></span>
<span id="cb57-5"><a href="one-sample-inference-tests.html#cb57-5"></a><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></span>
<span id="cb57-6"><a href="one-sample-inference-tests.html#cb57-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Normal Q-Q Plot&quot;</span>)</span></code></pre></div>
<p><img src="statistics_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>Here is the Shapiro-Wilk normality test. It fails to reject the null hypothesis of a normally distributed population.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="one-sample-inference-tests.html#cb58-1"></a><span class="kw">shapiro.test</span>(dep<span class="op">$</span>dep_score)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  dep$dep_score
## W = 0.98446, p-value = 0.8474</code></pre>
<p>If the data is not normally distributed, you still have a couple options before reverting to Wilcoxon.</p>
<ul>
<li>Transform the dependent variable.</li>
<li>Carry on regardless - the one-sample <em>t</em>-test is fairly robust to deviations from normality.</li>
</ul>
</div>
</div>
<div id="results-4" class="section level4 unnumbered">
<h4>Results</h4>
<p>Conduct the <em>t</em>-test. To get a 95% CI around the <em>difference</em> (instead of around the estimate), run the test using the difference, <span class="math inline">\(\mu_0 - \bar{x}\)</span>, and leave <code>mu</code> at its default of 0.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="one-sample-inference-tests.html#cb60-1"></a>(dep_95ci &lt;-<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> mu_<span class="dv">0</span> <span class="op">-</span><span class="st"> </span>dep<span class="op">$</span>dep_score, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>, <span class="dt">conf.level =</span> <span class="fl">.95</span>))</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  mu_0 - dep$dep_score
## t = 2.3811, df = 39, p-value = 0.02224
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  0.04176615 0.51323385
## sample estimates:
## mean of x 
##    0.2775</code></pre>
<p>The difference is statistically different from 0 at the <em>p</em> = .05 level. The effect size, called Cohen’s <em>d</em>, is defined as <span class="math inline">\(d = |M_D| / s\)</span>, where <span class="math inline">\(|M_D| = \bar{x} - \mu_0\)</span>, and <span class="math inline">\(s\)</span> is the sample standard deviation. <span class="math inline">\(d &lt;.2\)</span> is considered trivial, <span class="math inline">\(.2 \le d &lt; .5\)</span> small, and <span class="math inline">\(.5 \le d &lt; .8\)</span> large.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="one-sample-inference-tests.html#cb62-1"></a>(d &lt;-<span class="st"> </span>rstatix<span class="op">::</span><span class="kw">cohens_d</span>(dep, dep_score <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">mu =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(effsize) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">abs</span>())</span></code></pre></div>
<pre><code>## Cohen&#39;s d 
## 0.3764788</code></pre>
<p>Cohen’s <em>d</em> is 0.38, a small effect.</p>
<p>Make a habit of constructing a plot, just to make sure your head is on straight.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-57-1.png" width="624" /></p>
<p>Now you are ready to report the results.</p>
<blockquote>
<p>A one-sample <em>t</em>-test was run to determine whether depression score in recruited subjects was different from normal, as defined as a depression score of 4.0. Depression scores were normally distributed, as assessed by Shapiro-Wilk’s test (<em>p</em> &gt; .05) and there were no outliers in the data, as assessed by inspection of a boxplot. Data are mean <span class="math inline">\(\pm\)</span> standard deviation, unless otherwise stated. Mean depression score (3.72 <span class="math inline">\(\pm\)</span> 0.74) was lower than the population “normal” depression score of 4.00, a statistically significant difference of 0.28 (95% CI, 0.04 to 0.51), t(39) = 2.38, <em>p</em> = 0.022, <em>d</em> = 0.38.</p>
</blockquote>
</div>
<div id="appendix-deciding-sample-size-1" class="section level4 unnumbered">
<h4>Appendix: Deciding Sample Size</h4>
<p>Determine the sample size required for a maximum error <span class="math inline">\(\epsilon\)</span> in the estimate by solving the confidence interval equation, <span class="math inline">\(\bar{x} \pm t_{(1 - \alpha){/}2} \frac{s}{\sqrt{n}}\)</span> for <span class="math inline">\(n=\frac{{t_{\alpha/2,n-1}^2se^2}}{{\epsilon^2}}\)</span> . Unfortunately, <span class="math inline">\(t_{\alpha/2,n-1}^2\)</span> is dependent on <span class="math inline">\(n\)</span>, so replace it with <span class="math inline">\(z_{\alpha/2}^2\)</span>. What about <span class="math inline">\(s^2\)</span>? Estimate it from the literature, a pilot study, or using the empirical rule that 95% of the range falls within two standard deviations, <span class="math inline">\(s=range / 4\)</span>.</p>
<p>For example, if the maximum tolerable error is* <span class="math inline">\(\epsilon\)</span> = 3, and <span class="math inline">\(s\)</span> is approximately 10, what sample size produces an <span class="math inline">\(\alpha\)</span> =0.05 confidence level?</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="one-sample-inference-tests.html#cb64-1"></a><span class="kw">ceiling</span>(<span class="kw">qnorm</span>(.<span class="dv">975</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span><span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 43</code></pre>
</div>
</div>
<div id="sample-z-test-for-categorical-var" class="section level3">
<h3><span class="header-section-number">1.7.4</span> 1 Sample z Test for Categorical Var</h3>
<p>This test applies when you know the population variance.</p>
</div>
<div id="sample-t-test-for-categorical-var" class="section level3">
<h3><span class="header-section-number">1.7.5</span> 1 sample t Test for Categorical Var</h3>
<p>This test applies when you do not know the population variance.</p>
</div>
<div id="wilcoxon-1-sample-median-test-for-categorical-var" class="section level3">
<h3><span class="header-section-number">1.7.6</span> Wilcoxon 1-Sample Median Test for Categorical Var</h3>
<p>This test applies when the variable is not normally distributed.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="two-group-comparison-tests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["statistics.pdf", "statistics.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
