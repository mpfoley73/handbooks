# Probability {#Probablity}

## Bayesian Inference

The Bayesian model for inference adds to the statistical model $\{f_\theta : \theta \in \Omega\}$ a prior probability measure $\Pi$ for $\theta$. For example, suppose $\theta$ is the probability a flipping a coin to heads, with $\Omega = [0,1]$. The statistician's conservative believe $\pi$ may be a wide bell curve centered on $\theta=0.5$, or maybe the statistician is quite confident, so $\pi$ is a daring narrow bell curve around $\theta=0.5$. By the law of total probability, the probability of event $s$ is a joint distribution, $\pi(\theta)f_\theta(s)$. The marginal distribution of $s$ is $m(s) = \int_\Omega \pi(\theta)f_\theta(s)d\theta.$

After $s$ is observed the posterior distribution of $\theta$ is the conditional distribution of $\theta$ given $s$ is

$$\pi(\theta|s) = \frac{\pi(\theta)f_\theta(s)}{m(s)}$$

Suppose you observe a sample from a Bernoulli distribution with an unknown success probability, $\theta \in [0,1].$ You take a uniform prior, $\pi= Beta(\alpha, \beta) = Beta(1,1).$. Your sample of $n = 40$ includes $n\bar{x} = 10$ successes. Then the posterior of $\theta$ is $Beta(11,31):$

The likelihood $\theta^{n\bar{x}}\left(1-\theta\right)^{n(1-\bar{x})}$ times the prior $B^{-1}(\alpha, \beta)\theta^{\alpha-1}(1-\theta)^{\beta-1}.$

## Stochastic Processes

Stochastic processes are proceed randomly over time. 

The simplest version is the **random walk**. A random walk is a sequence $\{X_n\}$ of random variables, with $X_0$ = 1 and $P\left(X_{n+1} = X_n + 1 \right) = p$ where $p$ is the probability of "success" and its complement is $q= 1-p$. It follows that, given an initial value $a$, $P\left(X_n = a + k\right) = \binom{n}{\frac{n+k}{2}} p^{(n+k)/2}q^{(n-k)/2}$ for $k = -n, -n+2, -n+4, \dots,n$, and $E\left(X_n\right) = a + n(2p-1)$.

### Markov Chains

A Markov chain is the random motion of an object. Given a *state space* $S$ of all places an object can go, and a set of transition probabilities $\{p_{ij}: i,j \in S\}$ to move from state $i$ to $j$, and a probability $u_i = P\left(X_0 = i\right)$ that the object starts at state $i$, then $P\left(X_{n+1} = j|X_n =i\right)=p_{ij}$

\@ref(ANOVA)