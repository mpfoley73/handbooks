# Survival Analysis

These notes rely on the [Survival Analysis in R](https://campus.datacamp.com/courses/survival-analysis-in-r) DataCamp course, [STHDA](http://www.sthda.com/english/wiki/survival-analysis), [BJC](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262/), Applied Survival Analysis Using R [@Moore2016], [Emily Zabor](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html), and Clark et al ([1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262)).

Survival analyses model time to event. They differ from linear regression in two respects. Event times are typically skewed right with many early events and few late ones, violating linear regression's normality assumption. Survival analyses must also manage censoring, an unknown starting event (left censoring) and/or ending event (right censoring). Censuring occurs if the event does not take place by the end of the study window, or the subject is in some way lost to follow-up. In the figure below, subjects 3, 5, 9, and 15 either did not have the event or dropped out of the study. Censored observations do not reveal their total time to event, but they do reveal at least their minimum.

```{r echo=FALSE}
library(tidyverse)

survival::lung[81:100,] %>%
  mutate(subject = factor(row_number()),
         status = factor(status, levels = c(1, 2), labels = c("Censor", "Event"))) %>%
  ggplot(aes(y = subject)) +
  geom_segment(aes(yend = subject, x = 0, xend = time), size = 2, color = "darkgray") +
  geom_point(aes(x = time, color = status), size = 3) +
  theme_light() +
  theme(legend.position = "top") +
  labs(title = "Survival Data - How to handle censoring?", x = "days",
       y = "Subject", color = NULL)
```

A typical survival analysis uses Kaplan-Meier (KM) plots to visualize survival curves, log-rank tests to compare survival curves among groups, and Cox proportional hazards regression to describe the effect of explanatory variables on survival. In R, use the **survival** package for modeling, **survminer** for visualization, and **gtsummary** for summarization.

```{r message=FALSE, warning=FALSE}
library(scales)
library(survival)
library(survminer)
library(gtsummary)
```

## Basics

Let $T^*$ be a random variable representing the time until the event, and $U$ be a random variable representing the time until (right) censoring. The observed value is whichever comes first, $T = \mathrm{min}(T^*, U)$. The `lung` data set is typical, with `time` representing $T$ and `status` representing $\delta = I[T^* < U]$ (1 = censored, 2 = event).

```{r}
survival::lung %>% head()
```


Censoring sometimes occurs when subjects are monitored for a fixed period of time (Type I), the study is halted after a pre-specified level of events are reached (Type II), or the subject drops out for a reason other than the event of interest (random censoring).

You can specify the survival distribution function either as a *survival function*, $S(t)$, or as a *hazard function*, $h(t)$. Let $F(t) = P(T \le t)$ be the cumulative risk function, the probability of the event occurring on or before time $t$. $S(t)$ is its complement, $S(t) = 1 - F(t)$. 

$$S(t) = P(T > t).$$

The hazard function is the instantaneous event rate at $t$ given survival up to $t$,

$$h(t) = \lim_{\delta \rightarrow 0}{\frac{P(t < T < t + \delta|T > t)}{\delta}}.$$

The functions are related by the multiplication rule, $P(AB) = P(A|B)P(B)$. The event probability at $t$, $f(t) = F'(t)$, is the probability of the event at $t$ given survival up to $t$ multiplied by the probability of survival up to $t$.

$$f(t) = h(t) S(t).$$

$h(t)dt = \frac{f(t)}{S(t)}dt$ is useful for describing the prognosis for a subject who has survived through a period of time. $S(t)$ is also the negative exponent of the cumulative hazard function,

$$S(t) = e^{-H(t)}.$$

Use the survival function to estimate the mean survival time, $E(T) = \int S(t)dt$, and median survival time, $S(t) = 0.5$.

Take the exponential distribution as a quick example. It has a constant hazard, $h(t) = \lambda$. The cumulative hazard is $H(t) = \int_0^t \lambda du = \lambda t$. The survival function is $S(t) = e^{-\lambda t}$. The probability of failure at time $t$ is $f(t) = \lambda e^{-\lambda t}$. The expected time to failure is $E(t) = \int_0^\infty e^{-\lambda t} dt = 1 / \lambda$, and the median time to failure is $S(t) = e^{-\lambda t} = .5$, or $t_{med} = \log(2) / \lambda$.

There are parametric and non-parametric methods to estimate a survival curve.  The usual non-parametric method is the *Kaplan-Meier* estimator.  The usual parametric method is the *Weibull* distribution. In between is the most common way to estimate a survivor curve, the *Cox proportional hazards* model.

## Kaplan-Meier

The Kaplan-Meier (KM) estimator for the survival function is the product over failure times of the conditional probabilities of surviving to the next failure time.

$$\hat{S}(t) = \prod_{i: t_i < t}{\frac{n_i - d_i}{n_i}}$$

where $n_i$ is the number of subjects at risk at time $i$ and $d_i$ is the number incurring the event. I.e., $\hat{S}(t)$ is the sum-product of the survival proportions at each time interval. The KM curve falls only when an event occurs, not when a subject is censored. Confidence limits are calculated using the "delta" method to obtain the variance of $\log \hat{S}(t)$.

Calculate $\hat{S}(t)$ with `survival::survfit()`. Data set `lung` records the `status` (1 = censored, 2 = dead) of 228 lung cancer patients. `survfit()` operates on a `Surv` object, created by `Surv()`. Explanatory variables can be defined as factors, but the event indicator must be numeric and coded as 0|1 or 1|2.^[See neat discussion in Note section of `Surv()` help file.]

```{r}
lung_1 <- survival::lung %>%
  mutate(sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female")))
```

`survfit()` creates survival curves from a formula or from a previously fitted Cox model. If the confidence interval crosses zero, you can cap it, or specify the log-log transformation parameter `conf.type = "log-log"`. This one doesn't need it.

```{r}
# km_fit <- survfit(Surv(time, status) ~ sex, data = lung, conf.type = "log-log")
km_fit <- survfit(Surv(time, status) ~ sex, data = lung_1)
km_fit
```

112 of the 138 males and 53 of the 90 females died. The median survival times were `r km_fit %>% summary %>% pluck("table") %>% .["sex=Male", "median"]` days for males and `r km_fit %>% summary %>% pluck("table") %>% .["sex=Female", "median"]` days for females. The 95% CI is defined around the median time to event. Retrieve these values from the `summary()$table` object. E.g., `summary(km_fit)$table[1, "0.95LCL"]` = `r summary(km_fit)$table[1, "0.95LCL"]`. You can also use `summary()` with the `time` parameter to estimate survival up until a point in time.

```{r}
summary(km_fit, time = 300)
```

`broom::tidy()` summarizes the data by each event time in the data. At time *t* = 11, 3 of the 138 males at risk died, so $S(11) = 1 - \frac{3}{138} = .978$. At *t* = 12, 1 of the 135 that remained died, so $S(12) = S(11) \cdot \frac{1}{135} = .971$, and so on.

```{r}
km_fit %>% broom::tidy()
```

Don't construct your own ggplot - **survminer** does a good job plotting KM models. Vertical drops indicate events and vertical ticks indicate censoring.

```{r warning=FALSE}
ggsurvplot(
  km_fit,
  fun = "pct",
  linetype = "strata", # Change line type by groups
  pval = FALSE, 
  pval.method = TRUE,
  conf.int = TRUE,
  risk.table = TRUE,
  fontsize = 3, # used in risk table
  surv.median.line = "hv", # median horizontal and vertical ref lines
  ggtheme = theme_light(),
  palette = c("#E7B800", "#2E9FDF"),
  title = "Kaplan-Meier Survival Function Estimate"
)
```

`ggsurvplot()` can also plot the cumulative risk function, $F(t) = 1 - S(t)$, with parameter `fun = "event"`, and the cumulative hazard function, $H(t) = -\log S(t)$, with parameter `fun = "cumhaz"`.

<!-- The colons (::::, :::) create a style html within document -->
:::: {style="display: grid; grid-template-columns: 1fr 1fr; grid-column-gap: 10px;"}

::: {}
```{r echo=FALSE}
ggsurvplot(
  km_fit,
  fun = "event",
  linetype = "strata", # Change line type by groups
  pval = TRUE,
  conf.int = TRUE,
  ggtheme = theme_bw(),
  palette = c("#E7B800", "#2E9FDF"),
  title = "Cumulative Risk"
)
```
:::

::: {}
```{r echo=FALSE}
ggsurvplot(
  km_fit,
  fun = "cumhaz",
  linetype = "strata", # Change line type by groups
  pval = TRUE,
  conf.int = TRUE,
  ggtheme = theme_bw(),
  palette = c("#E7B800", "#2E9FDF"),
  title = "Cumulative Hazard"
)
```
:::

::::

A KM analysis is valid under the following conditions:

* The event status consists of two states: event or censor,
* Left-censoring (unknown starting point) is minimal,
* Censoring causes are independent of the event,
* There are no secular trends (e.g., staggered starting times, or introduction of new therapies), and
* The amount and pattern of censorship is similar per group.

The first three assumptions relate to study design and cannot be tested, but secular trends can be tested by running KM tests for multiple time intervals, and censorship patterns can be tested by inspection.

## Log-Rank Test

It is not obvious how to compare two survival distributions because they can cross, diverge, etc. When observations do not follow a parametric distribution function, compare them with the non-parametric log-rank test. The alternative hypothesis, termed the Lehmann alternative, is that one survival distribution is uniformly higher than the other, $H_A : S_1(t) = [S_0(t)]^\psi$, or equivalently, the hazard functions are proportional, $h_1(t) = \psi h_0(t)$, with $H_A: \psi \ne 1$.

At each $t$, you could construct a 2x2 contingency table between event/no-event and curves A and B. 

|              |Curve A           |Curve B           |Total         |
|--------------|------------------|------------------|--------------|
|Event         |$d_{Ai}$          |$d_{Bi}$          |$d_i$         |
|No Event      |$n_{Ai} - d_{0i}$ |$n_{Bi} - d_{1i}$ |$n_i - d_i$   |
|Total         |$n_{Ai}$          |$n_{Bi}$          |$n_i$         |


Holding the margins as fixed, the probability of observing $d_{Ai}$ events in curve A at time $i$ follows a [hypergeometric](https://bookdown.org/mpfoley1973/probability/hypergeometric.html) distribution.

$$f(d_{Ai} | n_{Ai}, n_{Bi}, d_i) = \frac{{{n_{Ai}}\choose{d_{Ai}}}{{n_{Bi}}\choose{d_{Bi}}}}{{n_i}\choose{d_i}}$$

The expected value is $e_{Ai} = E(d_{Ai}) = \frac{d_i}{n_i} \cdot n_{0i}$ with variance $v_{Ai} = Var(d_{Ai}) = d_{i} \cdot \frac{n_{Ai}}{n_i}  \cdot \frac{n_{1i}}{n_i} \cdot \frac{n_i - d_i}{n_i - 1}$. 

The log-rank test statistic is the sum of the differences between the observed and expected events, $U_0 = \sum (d_{Ai} - e_{Ai})$, normalized by dividing by the square-root of its variance, $V_0 = Var({U_0}) = \sum v_{Ai}$.

$$U = \frac{U_0}{\sqrt{V_0}} \sim N(0, 1)$$

$U^2$ is a chi-square random variable with one degree of freedom.

$$U^2 = \frac{U_0^2}{V_0} \sim \chi_1^2$$

```{r}
(km_diff <- survdiff(Surv(time, status) ~ sex, data = lung_1))
```

The *p*-value for $\chi_1^2$ = `r comma(km_diff$chisq, .1)` is `1 - pchisq(km_diff$chisq, length(km_diff$n) - 1)` = `r comma(1 - pchisq(km_diff$chisq, length(km_diff$n) - 1), .001)`, so reject $H_0$ that males and females have identical survival patterns.

## Common Distributions

KM curves and logrank tests are univariate analyses. They describe survival as a function of a single categorical factor variable. Weibull and other parametric models describe the effect of *multiple* covariates. Fully-parametric models are less common than KM and the semi-parametric Cox model because they are less flexible, but if the process follows the parametric distribution these models are preferable because the estimated parameters provide clinically meaningful estimates of the effect^[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5233524/?msclkid=2bbc1508ac1f11ecad286fc872ce9a29].

### Exponential

The exponential distribution (notes)[https://bookdown.org/mpfoley1973/probability/exponential.html], $T \sim \mathrm{Exp}(\lambda)$, is the easiest to use because its hazard function is time-independent.

$$\begin{eqnarray}
\log h(t) &=& \alpha + \beta X \\
h(t) &=& e^{\left(\alpha + \beta X \right)} \\
&=& \lambda
\end{eqnarray}$$

Interpret $\alpha$ as the baseline log-hazard because when $X$ is zero $h(t) = e^\alpha$. The cumulative hazard is $H(t) = \int_0^t \lambda dt = \lambda t$ and the corresponding survival function is 

$$S(t) = e^{-H(t)} = e^{-\lambda t}.$$

The expected survival time is $E(T) = \int_0^\infty S(t)dt = \int_0^\infty e^{-\lambda t} dt = 1 / \lambda.$. The median survival time is $S(t) = e^{-\lambda t} = 0.5$, or $t_{med} = \log(2) / \lambda$.

The survival curve is fit using *maximimum likelihood estimation* (MLE). My notes [here](https://bookdown.org/mpfoley1973/statistics/maximum-likelihood-estimation.html) explain MLE for the exponential distribution. Survival curve MLE is a little more complicated because of censoring. The likelihood $L$ that $\lambda$ produces the observed outcomes is the product of the probability densities for each observation because they are a sequence of independent variables. Let $\delta_i = [1, 0]$ for unsensored and censored observations. 

$$
L(\lambda; t_1, t_2, \dots, t_n) = \Pi_{i=1}^n f(t_i; \lambda)^{\delta_i} S(t_i; \lambda)^{1-\delta_i}
$$

Substituting $f(t) = h(t) S(t)$, and then substituting $h(t) = \lambda$ and $S(t) = e^{-\lambda t}$ and simplifying,

$$\begin{eqnarray}
L(\lambda; t_1, t_2, \dots, t_n) &=& \Pi_{i=1}^n h(t_i; \lambda)^{\delta_i} S(t_i; \lambda) \\
&=& \Pi_{i=1}^n \lambda^{\delta_1} e^{-\lambda t_i} \\
&=& \lambda^{\sum \delta_i} \exp \left(-\lambda \sum_{i=1}^n t_i \right)
\end{eqnarray}$$

Simplify the notation by letting $d = \sum \delta_i$, the total number of events (or deaths or whatever), and $V = \sum t_i$, the number of person-years (or days or whatever).

$$L(\lambda; t_1, t_2, \dots, t_n) = \lambda^d e^{-\lambda V}$$

This form is difficult to optimize, but the log of it is simple.

$$l(\lambda; t_1, t_2, \dots, t_n) = d \log(\lambda) - \lambda V$$

Maximize the log-likelihood equation by setting its derivative to zero and solving for $\lambda$.

$$\begin{eqnarray}
\frac{d}{d \lambda} l(\lambda; t_1, t_2, \dots, t_n) &=& \frac{d}{d \lambda} \left(d \log(\lambda) - \lambda V \right) \\
0 &=& \frac{d}{\lambda} - V \\
\lambda &=& \frac{d}{V}
\end{eqnarray}$$

$\lambda$ is the reciprocal of the sample mean, person-years divided by failures.

The second derivative, $-\frac{d}{\lambda^2}$, is approximately the negative of the variance of $\lambda$.

$$V(\lambda) = d / V^2$$

### Weibull

Although the exponential function is convenient, the [Weibull distribution](https://bookdown.org/mpfoley1973/probability/weibull.html) is more appropriate for modeling lifetimes. 

Its hazard function is 

$$\begin{eqnarray}
h(t) &=& \alpha \lambda (\lambda t)^{\alpha - 1} \\
&=& \alpha \lambda^\alpha t^{\alpha-1}
\end{eqnarray}$$  

The cumulative hazard function is $H(t) = (\lambda t)^\alpha$ and the corresponding survival function is

$$S(t) = e^{-(\lambda t)^\alpha}.$$

The exponential distribution is a special case of the Weibull where $\alpha = 1$. The expected survival time is $E(t) = \frac{\Gamma (1 + 1 / \alpha)}{\lambda}$. The median survival time is $t_{med} = \frac{[\log(2)]^{1 / \alpha}}{\lambda}$.

To measure the effects of covariates, it is preferable to substitute $\sigma = 1 / \alpha$ and $\mu = -\log \lambda$ so

$$
h(t) = \frac{1}{\sigma} e^{-\frac{\mu}{\sigma}} t^{\frac{1}{\sigma} - 1}
$$

and

$$
S(t) = e^{-e^{-\mu/\sigma}t^{1/\sigma}}
$$

The log of the negative log of $S$, $\log[-\log(S_i)] = \alpha \log(\lambda) + \alpha \log(t_i) = \frac{\mu}{\sigma} + \frac{1}{\sigma} \log(t_i)$ is a linear function, so you can use it to determine whether the Weibull function is appropriate for your analysis. Return to the `lung` data set introduced in Kaplan-Meier section. Use the Kaplan-Meier estimate of the survival distribution to extract the survival estimates and each time, transform them to conform to the above equation, and fit a linear model.

```{r}
km_fit_1 <- survfit(Surv(time, status) ~ 1, data = lung)
log_log_s <- log(-log(km_fit_1$surv))
log_t <- log(km_fit_1$time)

km_fit_1_lm <- lm(log_log_s ~ log_t)
km_fit_1_lm %>%
  broom::augment() %>%
  ggplot(aes(x = log_t)) +
  geom_point(aes(y = log_log_s)) +
  geom_line(aes(y = .fitted), linetype = 2, color = "goldenrod") +
  theme_light()
```

This is a decent fit. The coefficient estimates are 

```{r}
coef(km_fit_1_lm)
```

so $\mu = -\frac{`r comma(coef(km_fit_1_lm)[1], .001)`}{`r comma(coef(km_fit_1_lm)[2], .001)`} = `r comma(coef(km_fit_1_lm)[1] / coef(km_fit_1_lm)[2], .001)`$ and $\sigma = \frac{1}{`r comma(coef(km_fit_1_lm)[2], .001)`} = {`r comma(1 / coef(km_fit_1_lm)[2], .001)`}$.

Compare two Weibull distributions using the accelerated failure time (AFT) model. This model assumes the survival time for the treatment group is a multiple, $e^\gamma$, of the control group survival time. The survival distributions in the AFT model are related as $S_1(t) = S_0(e^{-\gamma}t)$ and the hazards are related by $h_1(t) = e^{-\gamma}h_0(e^{-\gamma}t)$. In the case of the Weibull distribution, the relationship is $h_1(t) = e^{-\frac{\gamma}{\sigma}}h_0(t)$. Fit a Weibull model with `survreg()` (recall KM is fit with `survfit()`). Return to the original model using the `lung` data set to compare survival between males and females.

```{r}
dat <- lung %>% mutate(sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female")))
wb_fit <- survreg(Surv(time, status) ~ sex, data = dat, dist = "weibull")
summary(wb_fit) 
```

$\hat{\gamma} = `r comma(coef(wb_fit)[2], .0001)`$, meaning females have longer times until death by a factor of $e^{\hat{\gamma}} = e^{`r comma(coef(wb_fit)[2], .0001)`} = `r comma(exp(coef(wb_fit)[2]), .01)`$. The scale parameter estimate is $\hat\sigma = `r summary(wb_fit) %>% pluck("scale") %>% comma(.001)`$, so the log proportional hazards is $\hat\beta = -\frac{\hat\gamma}{\hat\sigma} = \frac{`r comma(coef(wb_fit)[2], .0001)`}{`r summary(wb_fit) %>% pluck("scale") %>% comma(.001)`} = `r (coef(wb_fit)[2] / (summary(wb_fit) %>% pluck("scale"))) %>% comma(.001)`$. 

The survival curve estimate is $\hat{S}(t) = e^{-e^{-\hat\mu/\hat\sigma}t^{1/\hat\sigma}}$, but $\hat\alpha = 1 / \hat\sigma$.

```{r}
new_dat <- expand.grid(
  sex = levels(dat$sex), 
  survival = seq(.01, .99, by = .01)
  ) %>%
  mutate(
    pred = map2(sex, survival, 
                ~predict(wb_fit, type = "quantile", p = 1 - .y, se = TRUE, 
                         newdata = data.frame(sex = .x))),
    t = map_dbl(pred, ~pluck(.x, "fit")),
    se = map_dbl(pred, ~pluck(.x, "se.fit")),
    ucl = t + 1.96 * se,
    lcl = t - 1.96 * se
  )

palette_sex <- c("#E7B800", "#2E9FDF")
names(palette_sex) <- c("Male", "Female")

new_dat %>%
  ggplot(aes(y = survival)) +
  geom_line(aes(x = t, color = sex)) +
  geom_ribbon(aes(xmin = lcl, xmax = ucl, fill = sex), alpha = 0.2) +
  scale_color_manual(values = palette_sex) +
  scale_fill_manual(values = palette_sex) +
  theme_light()
```

Use `predict()` to get survival expectations. 


```{r collapse=TRUE}
# 90% of subjects fail by time 
wb_fit %>% predict(type = "quantile", p = .9, newdata = data.frame(sex = levels(dat$sex)))
```

```{r}
# Median survival times
predict(wb_fit, type = "quantile", p = 1 - 0.5, newdata = data.frame(sex = levels(dat$sex)))
```

You can fit other models with the `dist = c("lognormal", "exponential")` parameter.

## Cox

The Cox proportional hazards model expresses the expected hazard, $h(t)$, as an unspecified baseline hazard, $h_0(t)$, multiplied by the exponential of a linear combination of parameters, $\psi = e^{X\beta}$.

$$h(t) = h_0(t) \cdot e^{X \beta} = \psi h_0(t).$$

$h(t)$ is unspecified because it cancels out of the model. To see this, consider a hypothetical data set where 6 participants are assumed to fall into one of two hazards: participants 1, 2, and 3 have $h_0$ and 4, 5, and 6 have $\psi h_0$. Working through the event occurrences, the survival function is the product of each of the failure probabilities. Suppose participant 1 fails first. $p_1 = \frac{h_0(t_1)}{3 \cdot h_0(t_1) + 3 \psi \cdot h_0(t_1)}$. Suppose participant 2 censors, then participant 4 fails. $p_2 = \frac{\psi h_0(t_2)}{1 \cdot h_0(t_2) + 3 \psi \cdot h_0(t_2)}$. Now participant 3 fails. $p_3 = \frac{h_0(t_3)}{1 \cdot h_0(t_3) + 2 \psi \cdot h_0(t_3)}$. Notice how $h_0(t)$ cancels in each ratio. The partial likelihood is the product of the failure probabilities, $L(\psi) = \frac{\psi}{(3 + 3 \psi)(1 + 3 \psi)(1 + 2 \psi)}$. 

Find the value of $\psi$ that maximizes $L(\psi)$. $L(\psi)$ is difficult to optimize, but its log is easier. $l(\beta) = X \beta - \log (3 + 3 e^{X\beta}) - \log (1 + 3 e^{X\beta}) - \log (1 + 2 e^{X\beta})$. A function searches for the $\beta$ producing the global max. 

The proportionality of the model comes from the lack of time dependence in the $X$ variables. The ratio of the hazard functions of two individuals is 

$$\frac{h_i(t)}{h_{i'}(t)} = \frac{h_0(t) \cdot e^{X_i \beta}}{h_0(t) \cdot e^{X_{i'} \beta}}$$

There are three ways to test $H_0 : \beta = 0$: the Wald test, the score test, and the likelihood ratio test. 

* The Wald test statistic is $Z = \hat{\beta} / se({\hat{\beta}})$. Calculate $se({\hat{\beta}})$ from the second derivative of $l(\beta)$. As with other Wald tests, the square of this standard normal random variable is distributed chi-square, so you can equivalently test whether $Z^2 > \chi_{\alpha, 1}^2$.

* The score test compares the slope of $l(\beta)$ at $\beta = 0$ to 0. The test statistic is normally distributed, and again, its square is distributed chi-square.

* The likelihood ratio test statistic equals $2 [l(\beta = \hat{\beta}) - l(\beta = 0)]$. It has a chi-square distribution with one degree of freedom.

The Cox proportional hazards model is analogous to the [logistic regression](https://bookdown.org/mpfoley1973/supervised-ml/generalized-linear-models-glm.html#logistic-regression) model. Rearranging $h(t) = h_0(t) \cdot e^{X \beta}$,

$$\ln \left[ \frac{h(t)}{h_0(t)} \right] = X \beta.$$

Whereas logistic regression predicts the *log odds* of the response, Cox regression predicts the *log relative hazard* (relative to the unspecified baseline) of the response. $\beta$ is the change in the log of the relative hazard associated with a one unit change in $X$. Its antilog is the hazard ratio (HR). A positive $e^{\beta_j}$ means the hazard increases with the covariate. 

$$
\begin{eqnarray}
(x_b - x_a) \beta &=& \ln \left[ \frac{h_b(t)}{h_0(t)} \right] - \ln \left[ \frac{h_a(t)}{h_0(t)} \right] \\
\beta &=& \ln \left[ \frac{h_b(t)}{h_a(t)} \right] \\
e^\beta &=& \frac{h_b(t)}{h_a(t)} \\
 &=& \mathrm{HR}
\end{eqnarray}
$$

Fit a Cox proportional hazards model with `coxph()`.

```{r}
dat <- lung %>% 
  mutate(
    sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female")),
    ph.ecog = factor(ph.ecog, levels = c(0, 1, 2, 3), 
                     labels = c("asymptomatic", "ambulatory", "bedlow", "bedhigh"))
  )

cox_fit <- coxph(Surv(time, status) ~ sex, data = dat)
summary(cox_fit)
```

A negative coefficient estimator means the hazard decreases with increasing values of the variable. Females have a log hazard of death equal to `coef(cox_fit)[1]` = `r comma(coef(cox_fit)[1], .0001)` of that of males. The exponential is the hazard ratio, the effect-size of the covariate. Being female reduces the hazard by a factor of `exp(coef(cox_fit)[1])` = `r comma(exp(coef(cox_fit)[1]), .001)` (`r percent(1 - exp(coef(cox_fit)[1]), .1)`). I.e., at any given time, `r comma(exp(coef(cox_fit)[1]), .001)` times as many females die as males.

The last section of the summary object is the three tests for the overall significance of the model. These three methods are asymptotically equivalent. The Likelihood ratio test has better behavior for small sample sizes, so it is generally preferred.

Use **gtsummary** to present the results.

```{r}
cox_fit %>%
  tbl_regression(exponentiate = TRUE)
```

A multivariate analysis works the same way.  Here is the Cox model with two additional covariates: `age` and `ph.ecog`.

```{r}
cox_fit_2 <- coxph(Surv(time, status) ~ age + sex + ph.ecog, data = dat)
summary(cox_fit_2)
```

The p-values for all three overall tests (likelihood, Wald, and score) are significant, indicating that the model is significant (not all $\beta$ values are 0). 

A **landmark** analysis measures survival *after a milestone period*. E.g., I data set may have survival times after a disease onset, but a treatment typically starts after 90 days. In that case, you want to subset the persons surving at least 90 days and then subtract 90 from all the times. In a KM analysis manually adjust the data. In `coxph()` use the `subset` argument.

```{r eval=FALSE}
coxph(
  Surv(time, status) ~ age + sex + ph.ecog, 
  subset = time > 90, 
  data = dat
)
```

Visualize the fitted Cox model for each risk group. Function `survfit()` estimates survival at the mean values of covariates by default. That's usually not useful, so instead pass a dataframe with test cases into the `newdata` argument.

```{r}
# Predictions will be for all levels of sex and ph.ecog, but only at the median
# age.
new_data <- expand.grid(
    sex = unique(dat$sex),
    age = median(dat$age),
    ph.ecog = levels(dat$ph.ecog)
) %>% mutate(
  # strata is our key to join back to the fitted values.
  strata = as.factor(row_number())
)

# Create fitted survival curves at the covariate presets.
lung_pred_0 <- survfit(cox_fit_2, newdata = new_data, data = dat)

# `surv_summary()` is like `summary()` except that it includes risk table info,
# confidence interval attributes, and pivots the strata longer.
lung_pred_1 <- surv_summary(lung_pred_0)

# The cases are labeled "strata", but `survsummary()` doesn't label what the 
# strata are! Get it from new_data.
lung_pred_2 <- lung_pred_1 %>% inner_join(new_data, by = "strata")

# Now use ggplot() just like normal.
lung_pred_2 %>%
  ggplot(aes(x = time, y = surv, color = sex, fill = sex)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.4) +
  facet_wrap(facets = vars(ph.ecog)) +
  theme_light() +
  labs(title = "Cox fitted model",
       subtitle = "Age held at median.")
```

If a covariate changes over time, you need to modify the underlying data set. `tmerge()` lengthens the data set for the relevant time spans for the time-dependent covariate. Helper functions `event()` and `tdc()` modify the outcome and time-dependent covariates.

The BMT data set from the **SemiCompRisks** package is a good example. `T1` and `delta1` are the time and event indicator variables. `TA` and `deltaA` are time and event indicators for a secondary disease.

```{r}
data(BMT, package = "SemiCompRisks")

dat <- BMT %>%
  rowid_to_column("subject_id") %>%
  select(subject_id, T1, delta1, TA, deltaA)

dat %>% filter(subject_id %in% c(1, 2, 15, 18))
```

`tmerge()` merges two data sets, usually the same ones, and expands the time/event vars.

```{r}
dat_2 <- tmerge(
  data1 = dat,
  data2 = dat,
  id = subject_id,
  death = event(T1, delta1),
  agvhd = tdc(TA)
)

dat_2 %>% filter(subject_id %in% c(1, 2, 15, 18))
```

Define the Cox model Surv object with the start and end times.

```{r}
dat_2 %>% 
  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, data = .) %>% 
  gtsummary::tbl_regression(exp = TRUE)
```

From [Emily Zabor's tutorial](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html), use a landmark analysis to visualize a covariate and Cox for modeling.

The Cox model is valid under certain conditions.

* Censoring event causes should be independent of the event.
* There is a multiplicative relationship between the predictors and the hazard.
* The hazard ratio is constant over time.

## Case Study: KM + Cox

```{r include=FALSE}
cs_dat <- cancer %>%
  filter(!is.na(ph.ecog)) %>%
  mutate(
    ph.ecog = factor(
      ph.ecog,
      levels = c(0, 1, 2, 3, 4),
      labels = c("Asymptomatic", "Ambulatory", "In bed <50%", "In bed >50%", "Bedridden")),
    ph.ecog = fct_drop(ph.ecog),
    ph.ecog = fct_lump_n(ph.ecog, n = 2, other_level = "Bedridden")
  )
```

The guidelines for reporting the Kaplan-Meier test are from Laerd's Kaplan-Meier using SPSS Statistics [@Laerd2015]. The data is from `survival::cancer`. A researcher investigates differences in all-cause mortality between men and women diagnosed with advanced lung cancer. `r nrow(cs_dat) %>% comma(1)` participants aged `r min(cs_dat$age)` to `r max(cs_dat$age)` are monitored up to three years until time of death. The participants are segmented into three groups according to their ECOG performance score: *asymptomatic*, *symptomatic but completely ambulatory*, and *bedridden at least part of the day*. The study results are controlled for participant age.

```{r}
(t1 <- cs_dat %>%
  mutate(status = factor(status, levels = c(1, 2), labels = c("censored", "died"))) %>%
  tbl_summary(by = "ph.ecog", include = vars(time, status, ph.ecog, age)) %>%
  add_overall())
```

### KM

KM survival analyses require 1) binary outcomes (event or censoring), 2) defined times to events, 3) minimal left-censoring, 4) censoring independence, 5) no secular trends, and 6) similar censorship patterns per group. The first five requirements can be verified outside the data. The sixth can be verified in the data by checking for a similar amount and pattern of censorship per group.

The participant censoring plot shows censored cases are equally spread over time and not too dissimilar for the *asymptomatic* and *ambulatory* groups, but the *bedridden* group had a low number of censoring events. Use **gtsummary** to summarize (e.g., `gtsummary::inline_text(t1, variable = status, level = "censored", column = "Asymptomatic")` to get `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Asymptomatic")`).

> Censored cases were negatively associated with symptom severity, *asymptomatic*, `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Asymptomatic")`, *symptomatic but completely ambulatory*, `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Ambulatory")`, and *bedridden*, `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Bedridden")` study groups. 

```{r fig.height=4, fig.width=6.5}
cs_dat %>%
  filter(status == 1 | ph.ecog == "In bed >50%") %>%
  ggplot(aes(x = time, y = ph.ecog)) +
  geom_point() +
  theme_light() +
  labs(title = "Participant Censoring")
```

Construct a KM plot to get a feel for the data. The cumulative survival is negatively associated with the ECOG performance score. There is no substantial crossing of the survival curves (that would affect the power of the statistical tests). The curves are similarly shaped. The log-rank test is ideal for similarly shaped distributions and distributions that do not cross. The Breslow, and Tarone-Ware tests are more sensitive alternatives.

```{r fig.height=7, fig.width=6.5}
km_fit <- survfit(Surv(time, status) ~ ph.ecog, data = cs_dat)

km_fit %>%
  ggsurvplot(
    # data = cs_dat,
    fun = "pct",
    # linetype = "strata", # Change line type by groups
    # pval = TRUE,
    # conf.int = TRUE,
    risk.table = TRUE,
    fontsize = 3, # used in risk table
    surv.median.line = "hv", # median horizontal and vertical ref lines
    ggtheme = theme_light(),
    palette = c("goldenrod", "sienna", "tomato"),
    title = "Kaplan-Meier Survival Function Estimate",
    legend.title = "",
    legend.labs = levels(cs_dat$ph.ecog)
  )
```

The fitted KM model summary table shows the median survival times.

```{r}
(km_smry <- summary(km_fit) %>% pluck("table"))
```

```{r}
gtsummary::tbl_survfit(
  list(
    survfit(Surv(time, status) ~ 1, data = cs_dat),
    survfit(Surv(time, status) ~ ph.ecog, data = cs_dat)
    # survfit(Surv(time, status) ~ age, data = cs_dat)
  ),
  probs = 0.5,
  label_header = "**Median Survival**"
) %>%
  gtsummary::add_n() %>%
  gtsummary::add_nevent()
```

> Participants that were asymptomatic had a median survival time of `r km_smry["ph.ecog=Asymptomatic", "median"]` days (95% CI, `r km_smry["ph.ecog=Asymptomatic", "0.95LCL"]` to `r km_smry["ph.ecog=Asymptomatic", "0.95UCL"]` days). This was longer than the ambulatory group, `r km_smry["ph.ecog=Ambulatory", "median"]` days (95% CI, `r km_smry["ph.ecog=Ambulatory", "0.95LCL"]` to `r km_smry["ph.ecog=Ambulatory", "0.95UCL"]` days) and bedridden group, `r km_smry["ph.ecog=Bedridden", "median"]` days (95% CI, `r km_smry["ph.ecog=Bedridden", "0.95LCL"]` to `r km_smry["ph.ecog=Bedridden", "0.95UCL"]` days).

Determine whether there are significant differences in the fitted survival distributions using a log-rank test (and/or Breslow and Tarone-Ware). If there are differences, run a pairwise comparison post-hoc test to determine which curves differ.

The log-rank test weights the difference at each time point equally. Compared to the other two tests, it places greater emphasis on differences at later rather than earlier time points. The Breslow test (aka generalized Wilcoxon or Gehan) weights the differences by the number at risk at each time point. The effect is to place greater weight on the differences at earlier time points. The Tarone-Ware test weights differences the same way as Breslow, but takes the square root of the number at risk. 

```{r}
(km_diff <- survdiff(Surv(time, status) ~ ph.ecog, data = cs_dat))
```

> A log rank test was run to determine if there were differences in the survival distribution for the different types of intervention. The survival distributions for the three interventions were statistically significantly different, $\chi^2$(2) = `r km_diff$chisq %>% number(.1)`, *p* < .001.

Breslow and Tarone-Ware are in the **coin** package.

```{r}
coin::logrank_test(Surv(time, status) ~ ph.ecog, data = cs_dat, type = "Tarone-Ware")
coin::logrank_test(Surv(time, status) ~ ph.ecog, data = cs_dat, type = "Gehan-Breslow")
```

The log rank test is an ombnibus test. Create a pairwise comparisons table to see which groups differed.

```{r}
(km_pairwise <- survminer::pairwise_survdiff(Surv(time, status) ~ ph.ecog, data = cs_dat))
```

Adjust the statistical significance to compensate for making multiple comparisons with a Bonferroni correction. There are three comparisons so divide .05 by 3, so the significance is p < .0167.

> Pairwise log rank comparisons were conducted to determine which intervention groups had different survival distributions. A Bonferroni correction was made with statistical significance accepted at the *p* < .017 level. There was a statistically significant difference in survival distributions for the aymptomatic vs bedridden, *p* < .001, and ambulatory vs bedridden, *p* = `r km_pairwise$p.value["Bedridden", "Ambulatory"] %>% number(.001)`, groups. However, the survival distributions for the asymptomatic vs ambulatory group were not statistically significant, *p* = `r km_pairwise$p.value["Ambulatory", "Asymptomatic"] %>% number(.001)`.

Report the results like this.

> `r nrow(cs_dat) %>% comma(1)` Men and women diagnosed with advanced lung cancer aged `r min(cs_dat$age)` to `r max(cs_dat$age)` were monitored up to three years until time of death. Participants were classified into three groups according to their ECOG performance score: *asymptomatic* (n = `r cs_dat %>% count(ph.ecog) %>% filter(ph.ecog == "Asymptomatic") %>% pull(n)`), *symptomatic but completely ambulatory* (n = `r cs_dat %>% count(ph.ecog) %>% filter(ph.ecog == "Ambulatory") %>% pull(n)`), and *bedridden at least part of the day* (n = `r cs_dat %>% count(ph.ecog) %>% filter(ph.ecog == "Bedridden") %>% pull(n)`). A Kaplan-Meier survival analysis (Kaplan & Meier, 1958) was conducted to compare survival times among the three ECOG performance scores. Censored cases were negatively associated with symptom severity, *asymptomatic*, `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Asymptomatic")`, *symptomatic but completely ambulatory*, `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Ambulatory")`, and *bedridden*, `r gtsummary::inline_text(t1, variable = status, level = "censored", column = "Bedridden")` study groups. Participants that were asymptomatic had a median survival time of `r km_smry["ph.ecog=Asymptomatic", "median"]` days (95% CI, `r km_smry["ph.ecog=Asymptomatic", "0.95LCL"]` to `r km_smry["ph.ecog=Asymptomatic", "0.95UCL"]` days). This was longer than the ambulatory group, `r km_smry["ph.ecog=Ambulatory", "median"]` days (95% CI, `r km_smry["ph.ecog=Ambulatory", "0.95LCL"]` to `r km_smry["ph.ecog=Ambulatory", "0.95UCL"]` days) and bedridden group, `r km_smry["ph.ecog=Bedridden", "median"]` days (95% CI, `r km_smry["ph.ecog=Bedridden", "0.95LCL"]` to `r km_smry["ph.ecog=Bedridden", "0.95UCL"]` days). A log rank test was run to determine if there were differences in the survival distribution for the different types of intervention. The survival distributions for the three interventions were statistically significantly different, $\chi^2$(2) = `r km_diff$chisq %>% number(.1)`, *p* < .001. Pairwise log rank comparisons were conducted to determine which intervention groups had different survival distributions. A Bonferroni correction was made with statistical significance accepted at the *p* < .017 level. There was a statistically significant difference in survival distributions for the aymptomatic vs bedridden, *p* < .001, and ambulatory vs bedridden, *p* = `r km_pairwise$p.value["Bedridden", "Ambulatory"] %>% number(.001)`, groups. However, the survival distributions for the asymptomatic vs ambulatory group were not statistically significant, *p* = `r km_pairwise$p.value["Ambulatory", "Asymptomatic"] %>% number(.001)`

### Cox

The Cox proportional hazards model describes the effect of explanatory variables on survival and can include controlling variables. Add `age` as a controlling variable.

```{r}
cox_fit <- coxph(Surv(time, status) ~ ph.ecog + age, data = cs_dat)
(cox_tbl <- cox_fit %>% gtsummary::tbl_regression(exponentiate = TRUE))
```

```{r}
gtsummary::inline_text(cox_tbl, variable = ph.ecog, level = "Ambulatory")
```

Using a Cox proportional hazards regression analysis, we find the association between ECOG and survival time statistically significant with a Bedridden estimate of `r gtsummary::inline_text(cox_tbl, variable = ph.ecog, level = "Bedridden")` relative to Asymptomatic. The hazard ratio for Ambulatory was not statistically significant, `r gtsummary::inline_text(cox_tbl, variable = ph.ecog, level = "Ambulatory")`.
 
```{r}
survfit(cox_fit, newdata = list(ph.ecog = levels(cs_dat$ph.ecog),
                                             age = rep(median(cs_dat$age), 3)), data = cs_dat) %>%
  surv_summary() %>%
  ggsurvplot_df(
    fun = "pct",
    # linetype = "strata", # Change line type by groups
    # conf.int = TRUE,
    surv.median.line = "hv", # median horizontal and vertical ref lines
    ggtheme = theme_light(),
    palette = c("goldenrod", "sienna", "tomato"),
    title = "Fitted Cox model at Median Participant Age.",
    legend.title = "",
    legend.labs = levels(cs_dat$ph.ecog)
  )
```



### Reporting

> Participants were randomly assigned to three different interventions in order to quit smoking: a hypnotherapy programme (n = 50), wearing nicotine patches (n = 50) and using e-cigarettes (n = 50). Kaplan-Meier survival analysis (Kaplan & Meier, 1958) was conducted to compare the three different interventions for their effectiveness in preventing smoking resumption. A similar percentage of censored cases was present in the hypnotherapy (12.0%), nicotine patch (14.0%) and e-cigarette (14.0%) intervention groups and the pattern of censoring was similar. Participants that underwent the hypnotherapy programme had a median time to smoking resumption of 69.0 (95% CI, 45.2 to 92.8) days. This was longer than the groups receiving nicotine patches or e-cigarettes, which had identical median times to smoking resumption of 9.0 (95% CI, 6.6 to 11.4) days and 9.0 (95% CI, 7.1 to 10.9) days, respectively. A log rank test was conducted to determine if there were differences in the survival distributions for the different types of intervention. The survival distributions for the three interventions were statistically significantly different, χ2(2) = 25.818, p < .0005. Pairwise log rank comparisons were conducted to determine which intervention groups had different survival distributions. A Bonferroni correction was made with statistical significance accepted at the p < .0167 level. There was a statistically significant difference in survival distributions for the hypnotherapy vs nicotine patch intervention, χ2(1) = 11.035, p = .001, and hypnotherapy vs e-cigarette intervention, χ2(1) = 29.003, p < .0005. However, the survival distributions for the e-cigarette and nicotine patch interventions were not statistically significantly different, χ2(1) = 1.541, p = .214.

