[["sentimentanalysis.html", "Chapter 2 Sentiment Analysis 2.1 Subjectivity Lexicons 2.2 Polarity Scoring 2.3 Emotion Classification 2.4 Comparison Cloud 2.5 Statistical Test", " Chapter 2 Sentiment Analysis Sentiment analysis is the extraction of the emotional intent of text. You can classify the polarity (positive | negative) or sentiment (angry | sad | happy | ) at the document, sentence, or feature level. To practice with real-world data, I will use the Customer reviews of London-based hotels data set hosted on data.world. hotel_raw contains reviews of the top 10 most- and least-expensive hotels in London. hotel_raw_1 &lt;- read_csv(&quot;https://query.data.world/s/2zsbemxf66vevuuc47jqe24n4zwl54&quot;) %&gt;% mutate(`Date Of Review` = lubridate::mdy(`Date Of Review`), `Property Name` = trimws(str_remove(`Property Name`, &quot;Hotel&quot;)), `Property Name` = trimws(str_remove(`Property Name`, &quot;The&quot;)), `Property Name` = case_when( str_detect(`Property Name`, &quot;^45 Park Lane&quot;) ~ &quot;45 Park Lane&quot;, str_detect(`Property Name`, &quot;^Apex&quot;) ~ &quot;Apex&quot;, str_detect(`Property Name`, &quot;^Bulgari&quot;) ~ &quot;Bulgari&quot;, str_detect(`Property Name`, &quot;^Corinthia&quot;) ~ &quot;Corinthia&quot;, str_detect(`Property Name`, &quot;^London Guest House&quot;) ~ &quot;Guest House&quot;, str_detect(`Property Name`, &quot;^Xenia&quot;) ~ &quot;Xenia&quot;, str_detect(`Property Name`, &quot;^Mandarin&quot;) ~ &quot;Mandarin&quot;, str_detect(`Property Name`, &quot;^Mondrian&quot;) ~ &quot;Mondrian&quot;, str_detect(`Property Name`, &quot;^Wellesley&quot;) ~ &quot;Wellesley&quot;, TRUE ~ `Property Name`), `Property Name` = factor(`Property Name`), review_id = row_number() ) %&gt;% janitor::clean_names(case = &quot;snake&quot;) %&gt;% select(review_id, everything()) skimr::skim(hotel_raw_1) Table 2.1: Data summary Name hotel_raw_1 Number of rows 27330 Number of columns 7 _______________________ Column type frequency: character 3 Date 1 factor 1 numeric 2 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace review_title 0 1.00 1 508 0 22323 0 review_text 0 1.00 16 32759 0 27329 0 location_of_the_reviewer 3953 0.86 1 178 0 6624 0 Variable type: Date skim_variable n_missing complete_rate min max median n_unique date_of_review 1 1 2002-04-01 2018-10-18 2015-07-22 3870 Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts property_name 0 1 FALSE 20 Sav: 5417, Mon: 4330, Rem: 3028, Cor: 2820 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist review_id 0 1 13665.50 7889.64 1 6833.25 13665.5 20497.75 27330  review_rating 0 1 4.49 0.89 1 4.00 5.0 5.00 5  There are 27,330 reviews of 20 hotels posted between 2002-04-01 and 2018-10-18. This raw text needs cleaned. One issue is tags like &lt;e9&gt; and unicode characters like &lt;U+0440&gt;. One way to get rid of unicode characters is to convert them to ascii tags with iconv() and then remove the tags with str_remove(). For example, iconv() will change &lt;U+0093&gt; to ascii string &lt;93&gt; that you can remove with regex \"\\\\&lt;[:alnum]+\\\\&gt;]\" (more help with regex on RStudios cheat sheets). hotel_raw_2 &lt;- hotel_raw_1 %&gt;% mutate( review_text = iconv(review_text, from = &quot;&quot;, to = &quot;ASCII&quot;, sub = &quot;byte&quot;), review_text = str_remove_all(review_text, &quot;\\\\&lt;[[:alnum:]]+\\\\&gt;&quot;) ) I also want to remove reviews written in a foreign language. One blunt force way to handle this is to look for words common in other languages that do not also occur in English. hotel &lt;- hotel_raw_2 %&gt;% filter(!str_detect(review_text, &quot;( das )|( der )|( und )|( en )&quot;)) %&gt;% # German filter(!str_detect(review_text, &quot;( et )|( de )|( le )|( les )&quot;)) %&gt;% # French filter(!str_detect(review_text, &quot;( di )|( e )|( la )&quot;)) %&gt;% # Italian filter(!str_detect(review_text, &quot;( un )|( y )&quot;)) %&gt;% # Spanish select(review_id, everything()) That got rid of 3,557 rows. My cleansed data set hotel has 23,773 rows. 2.1 Subjectivity Lexicons There are three common sentiment lexicons. You commonly use Bing for polarity scoring, and AFINN for identifying emotions. Bing classifies words as positive or negative. sentiment_bing &lt;- get_sentiments(&quot;bing&quot;) sentiment_bing %&gt;% count(sentiment) %&gt;% adorn_totals() %&gt;% flextable() %&gt;% autofit() %&gt;% colformat_int(j = 2) %&gt;% set_caption(&quot;Bing Lexicon&quot;) .cl-2d2dad84{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-2d2dad85{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-2d2dad86{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-2d2dd476{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd477{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd478{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd479{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd47a{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd47b{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd47c{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d2dd47d{width:68px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2.2: Bing Lexicon sentimentnnegative4,781positive2,005Total6,786 The AFINN lexicon associates words with a manually rated valence integer between -5 (negative) and +5 (positive) by Finn Arup Nielsen. sentiment_afinn &lt;- get_sentiments(&quot;afinn&quot;) sentiment_afinn %&gt;% count(value) %&gt;% adorn_totals() %&gt;% flextable() %&gt;% autofit() %&gt;% colformat_int(j = 2) %&gt;% set_caption(&quot;AFINN Lexicon&quot;) .cl-2d528942{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-2d528943{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-2d528944{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-2d52b002{width:47px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b003{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b004{width:47px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b005{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b006{width:47px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b007{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b008{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b009{width:47px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b00a{width:47px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b00b{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52b00c{width:45px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d52d3a2{width:47px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2.3: AFINN Lexicon valuen-516-443-3264-2966-13090112082448317244555Total2,477 The NRC lexicon associates words with eight emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) corresponding to the second level of Plutchiks Wheel of Emotions and two sentiments (negative and positive). NRC was created by manual annotation on a crowdsourcing platform. Read more here. sentiment_nrc &lt;- get_sentiments(&quot;nrc&quot;) sentiment_nrc %&gt;% count(sentiment) %&gt;% adorn_totals() %&gt;% flextable() %&gt;% autofit() %&gt;% colformat_int(j = 2) %&gt;% set_caption(&quot;NRC Lexicon&quot;) .cl-2d735b5e{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-2d735b5f{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-2d735b60{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-2d738188{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d738189{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73818a{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73818b{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73818c{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73818d{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73818e{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73818f{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d738190{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d738191{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d738192{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73a8f2{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73a8f3{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73a8f4{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73a8f5{width:51px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d73a8f6{width:76px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2.4: NRC Lexicon sentimentnanger1,247anticipation839disgust1,058fear1,476joy689negative3,324positive2,312sadness1,191surprise534trust1,231Total13,901 2.2 Polarity Scoring You can use three packages to measure text polarity. The simplest method is using tidytext. You transform your text into one-row per word with unnest_tokens(), join to one of the sentiment lexicons, and add up the positives and negatives. The polarity score is the net of positive - negative. qdap is more sophisticated. It takes into account valence shifters, surrounding words that change the intensity of a sentiment (e.g., very) or switch its direction (e.g., not). 2.2.1 tidytext The tidy way to score polarity is tagging individual words as positive and negative using the bing lexicon, then defining polarity as difference in counts. In principle, you ought to be able to use the positive|negative subset of NRC, or create weighted counts using AFINN. The qdap and sentimentr packages also correct for text length. A wordy review using twice as many positives as negatives shouldnt score twice as positive. Those packages divide by \\(\\sqrt{n}\\) to reduce the impact of word count (longer reviews are still more emotional, just less so). Another improvement I employ below is capturing the words that registered as positive an negative. This is useful for explaining how the polarity score was calculated. I also attached the results back to the original data frame with an outer join since not all reviews would necessarily have any sentiment words (but they did). This leaves me with the original data, plus all my polarity metadata. hotel_tidy &lt;- hotel %&gt;% select(review_id, review_text) %&gt;% unnest_tokens(output = &quot;word&quot;, input = review_text) hotel_wordcount &lt;- hotel_tidy %&gt;% count(review_id) hotel_tidy_polarity_1 &lt;- hotel_tidy %&gt;% inner_join(get_sentiments(&quot;bing&quot;), by = &quot;word&quot;) %&gt;% group_by(review_id, sentiment) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), words = list(word)) %&gt;% pivot_wider(names_from = sentiment, values_from = c(n, words), values_fill = list(n = 0)) hotel_tidy_polarity_bing &lt;- hotel %&gt;% left_join(hotel_wordcount, by = &quot;review_id&quot;) %&gt;% left_join(hotel_tidy_polarity_1, by = &quot;review_id&quot;) %&gt;% mutate(polarity_score = (n_positive - n_negative) / sqrt(n), polarity_desc = if_else(polarity_score &gt;= 0, &quot;Positive&quot;, &quot;Negative&quot;)) Out of curiosity, Ill try this with AFINN too. hotel_tidy_polarity_2 &lt;- hotel_tidy %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(review_id) %&gt;% summarize(.groups = &quot;drop&quot;, sentiment = sum(value), words = list(word)) hotel_tidy_polarity_afinn &lt;- hotel %&gt;% left_join(hotel_wordcount, by = &quot;review_id&quot;) %&gt;% left_join(hotel_tidy_polarity_2, by = &quot;review_id&quot;) %&gt;% mutate(polarity_score = sentiment / sqrt(n), polarity_desc = if_else(polarity_score &gt;= 0, &quot;Positive&quot;, &quot;Negative&quot;)) How should we present these results? One way is to treat polarity as the numeric measure and group by the factor variable property_name. Here are my Bing results. hotel_tidy_polarity_bing %&gt;% group_by(property_name) %&gt;% mutate(median_polarity = median(polarity_score, na.rm = TRUE)) %&gt;% ungroup() %&gt;% arrange(median_polarity) %&gt;% ggplot(aes(x = fct_inorder(property_name), y = polarity_score)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + geom_hline(yintercept = 0, linetype = &quot;longdash&quot;, color = &quot;#60BD68&quot;, size = 1.25) + coord_flip() + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Bing Polarity = (n_pos - n_neg) / sqrt(n_words)&quot;) And here is is with AFINN. hotel_tidy_polarity_afinn %&gt;% group_by(property_name) %&gt;% mutate(median_polarity = median(polarity_score, na.rm = TRUE)) %&gt;% ungroup() %&gt;% arrange(median_polarity) %&gt;% ggplot(aes(x = fct_inorder(property_name), y = polarity_score)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + geom_hline(yintercept = 0, linetype = &quot;longdash&quot;, color = &quot;#60BD68&quot;, size = 1.25) + coord_flip() + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;AFINN Polarity = sentiment / sqrt(n_words)&quot;) Not too different. 2 of the top 3 are the same. The bottom 4 are the same group, just shuffled. Savoy fared better in AFINN than in Bing. The data set includes a numeric rating review_rating (1-5). Does the polarity score reveal anything that the numeric rating doesnt already tell you? hotel_tidy_polarity_bing %&gt;% filter(!is.na(polarity_score)) %&gt;% ggplot(aes(x = as_factor(review_rating), y = polarity_score)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Polarity = (n_pos - n_neg) / sqrt(n_words)&quot;) Most reviews are positive - even for 2-rated hotels. While sentiment does increase with review rating, there are plenty of reviews with a rating of 5 and a polarity score &lt;0. Lets dig into that a little. Here is a 1-rated review with a decent polarity score. hotel_tidy_polarity_bing %&gt;% filter(review_rating == 1) %&gt;% slice_max(polarity_score) %&gt;% select(polarity_score, review_text) %&gt;% flextable() %&gt;% autofit() .cl-34d84698{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-34d86a06{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-34d86a07{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-34d8942c{width:89px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-34d8942d{width:2596px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-34d8942e{width:89px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-34d8942f{width:2596px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}polarity_scorereview_text0.8728716Stayed here many times both for business and pleasure, alone, with my wife and even with extended family and children. It is in fact impossible to seperate the business and pleasure stays because everytime was a breathtakingly delectable pleasure. Meeting friends and colleagues whether in the lobby one of the resturants always left an impressive memorable impression. Alas, I haven't been able to visit again for sometime - either fully booked or are not able to guarantee convenient parking for my personal chauffeur and car. Well, that is amusing - I the reviewer treating the rating as a kind of ranking (first place!). How about a 5-rating with negative sentiment? hotel_tidy_polarity_bing %&gt;% filter(review_rating == 5) %&gt;% slice_min(polarity_score) %&gt;% select(polarity_score, review_text) %&gt;% flextable() %&gt;% autofit() .cl-34f4dd44{font-family:'Arial';font-size:11px;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(17, 17, 17, 1.00);background-color:transparent;}.cl-34f4dd45{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-34f4dd46{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2px;padding-top:2px;padding-left:5px;padding-right:5px;line-height: 1.00;background-color:transparent;}.cl-34f50454{width:89px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-34f50455{width:1761px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-34f50456{width:89px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-34f50457{width:1761px;background-color:transparent;vertical-align: middle;border-bottom: 2.00px solid rgba(0, 0, 0, 1.00);border-top: 2.00px solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}polarity_scorereview_text-0.70014Some design faults in the bathroom - no stool, misplaced grab handles and vanity mirror. | Very disappointing experience in Savoy Grill. Good quality ingredients but poorly presented and tasteless. Numerous mistakes in service including charging for expensive drinks which we did not have. Service charge revoked and booking for following night cancelled. | Again, I think they got it backwards. The polarity scoring can reveal why some hotels rated worse by looking at the words used. (this plot di not come out well). hotel_tidy_polarity_bing %&gt;% mutate(review_rating = as.factor(review_rating)) %&gt;% filter(!is.na(polarity_desc)) %&gt;% select(!c(words_positive, words_negative)) %&gt;% # no lists allowed unnest_tokens(&quot;word&quot;, review_text) %&gt;% anti_join(stop_words, by = &quot;word&quot;) %&gt;% filter(!str_detect(word, &quot;[0-9]&quot;)) %&gt;% filter(!word %in% c(&quot;hotel&quot;, &quot;stay&quot;, &quot;night&quot;, &quot;london&quot;)) %&gt;% count(review_rating, polarity_desc, word) %&gt;% group_by(review_rating, polarity_desc) %&gt;% slice_max(order_by = n, n = 8, with_ties = FALSE) %&gt;% mutate(n = if_else(polarity_desc == &quot;Negative&quot;, -n, n), word = paste0(if_else(polarity_desc == &quot;Negative&quot;, &quot;-&quot;, &quot;+&quot;), word)) %&gt;% ungroup() %&gt;% arrange(review_rating, n) %&gt;% ggplot(aes(x = fct_inorder(word), y = n, fill = polarity_desc, color = polarity_desc)) + geom_col(alpha = 0.6) + facet_wrap(~as.factor(review_rating), scales = &quot;free&quot;) + scale_fill_few() + scale_color_few() + coord_flip() + theme_minimal() + theme(legend.position = &quot;top&quot;) + labs(title = &quot;Top Words by review type&quot;, y = &quot;Word Count&quot;, x = NULL, fill = NULL, color = NULL) Word clouds are a nice way to get an overview of the data. hotel_tidy_polarity_bing %&gt;% unnest_tokens(output = &quot;word&quot;, input = review_text) %&gt;% anti_join(stop_words, by = &quot;word&quot;) %&gt;% filter(!str_detect(word, &quot;[0-9]&quot;) &amp; !is.na(polarity_desc)) %&gt;% filter(!word %in% c(&quot;hotel&quot;, &quot;stay&quot;, &quot;night&quot;, &quot;london&quot;)) %&gt;% count(word, polarity_desc, wt = n) %&gt;% pivot_wider(names_from = polarity_desc, values_from = n, values_fill = 0) %&gt;% data.table::data.table() %&gt;% as.matrix(rownames = &quot;word&quot;) %&gt;% wordcloud::comparison.cloud(max.words = 20, title.size = 1.5) ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## location could not be fit on page. It will not be plotted. ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## amazing could not be fit on page. It will not be plotted. ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## wonderful could not be fit on page. It will not be plotted. 2.2.2 sentimentr sentimentr calculates polarity at the sentence level. It improves on tidytext in that it takes into account the context in which the sentiment words occur, that is, the valence shifters. A negator flips the sign of a polarized word (e.g., I do not like it.). See lexicon::hash_valence_shifters[y==1]. An amplifier (intensifier) increases the impact (e.g., I really like it.). See lexicon::hash_valence_shifters[y==2]. A de-amplifier (downtoner) reduces the impact (e.g., I hardly like it.). See lexicon::hash_valence_shifters[y==3]. An adversative conjunction overrules the previous clause containing a polarized word (e.g., I like it but its not worth it.). See lexicon::hash_valence_shifters[y==4]. sentimentr uses a lexicon package combined from the syuzhet and lexicon packages. Positive words are scored +1 and negative words are scored -1. sentimentr identifies clusters of words within sentences of the text. The 4 words before and 2 words after are candidate valence shifters. Polarized words are weighted by the valence shifter weights: negators = -1; amplifiers and de-amplifiers = 1.8; adversative conjunctions decrease the value of the prior cluster and increase the value of the following cluster. Neutral words hold no value, but do affect the word count. hotel_sentr_polarity_1 &lt;- hotel %&gt;% mutate(sentences = get_sentences(review_text)) %$% sentiment_by(sentences, review_id) hotel_sentr_polarity &lt;- hotel %&gt;% left_join(hotel_sentr_polarity_1, by = &quot;review_id&quot;) %&gt;% mutate(polarity_desc = if_else(ave_sentiment &gt;= 0, &quot;Positive&quot;, &quot;Negative&quot;)) Here is the chart treating polarity as the numeric measure and group by the factor variable property_name. hotel_sentr_polarity %&gt;% group_by(property_name) %&gt;% mutate(median_polarity = median(ave_sentiment, na.rm = TRUE)) %&gt;% ungroup() %&gt;% arrange(median_polarity) %&gt;% ggplot(aes(x = fct_inorder(property_name), y = ave_sentiment)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + geom_hline(yintercept = 0, linetype = &quot;longdash&quot;, color = &quot;#60BD68&quot;, size = 1.25) + coord_flip() + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Sentimentr Polarity&quot;) Here, Xenia came out on top. The data set includes a numeric rating review_rating (1-5). Does the polarity score reveal anything that the numeric rating doesnt already tell you? hotel_sentr_polarity %&gt;% filter(!is.na(ave_sentiment)) %&gt;% ggplot(aes(x = as_factor(review_rating), y = ave_sentiment)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Polarity = (n_pos - n_neg) / sqrt(n_words)&quot;) One nice feature of sentimentr is that it creates a highlighted text based on sentiment score (green = positive, red = negative). hotel_sentr_polarity %&gt;% highlight() 2.2.3 qdap qdap::polarity(text.var, grouping.var = NULL) calculates the polarity score for each character string text.var, grouping by optional character vector grouping.var. polarity uses the sentiment dictionary to tag polarized words. It considers a context cluster of words around polarized words as valence shifters (neutral, negator, amplifier, or de-amplifier). Neutral words hold no value but do affect word count. polarity applies the dictionary weights to each polarized word and then further weights by the number and position of the valence shifters. Last, it sums the context cluster and divides by the square root of the word count, yielding an unbounded polarity score. # hotel_sentr_polarity &lt;- hotel %&gt;% # mutate(sentences = get_sentences(review_text)) %&gt;% # sentiment_by(sentences, list(review_id)) # hotel_qdap_polarity &lt;- hotel %$% # polarity(review_text, review_id) # # scores(hotel_qdap_polarity) The counts() function returns one row for each line of text. It includes a list of the positive and negative words that contribute to the polarity score. Line 57 has a polarity score of zero because it has a pair of positive and negative words. # sawyer[57,] # counts(sawyer_tm_polarity)[57,] # counts(sawyer_tm_polarity)[57, c(&quot;pos.words&quot;, &quot;neg.words&quot;)] %&gt;% unlist() Oh, but wait - Twain doesnt use mighty as a positive adjective, but rather, as an amplifier adverb. Mighty appears sawyer %&gt;% filter(str_detect(text, \"mighty\")) %&gt;% nrow times in Tom Sawyer. We should remove it from the polarity.frame and add it to the amplifiers. # custom_frame &lt;- sentiment_frame( # positives = qdapDictionaries::positive.words[qdapDictionaries::positive.words != &quot;mighty&quot;], # negatives = qdapDictionaries::negative.words # ) # # sawyer_tm_polarity_2 &lt;- sawyer %&gt;% # mutate(text = str_remove_all(text, &quot;\\\\_&quot;)) %$% # polarity( # text, chapter, # polarity.frame = custom_frame, # amplifiers = sort(c(qdapDictionaries::amplification.words, &quot;mighty&quot;)) # ) # # counts(sawyer_tm_polarity_2)[57,] Something is still wrong here. It removed mighty as a positive word, but did not apply it as amplifier. It seems to be confused by the presence of the comma in tomorrow, to punish. Ill drop the matter for now, but perhaps how we parse the data into rows makes a difference. It also advises that you run SentSplit() on the data first, but the function never stopped running, so I abandoned it. Here is a plot of the polarity results. # plot(sawyer_tm_polarity_2) Chapter 22 had the lowest polarity score and chapter 34 the highest. # sawyer_tm_polarity_2 %&gt;% # scores() %&gt;% # mutate(chapter = as.integer(chapter)) %&gt;% # ggplot(aes(x = chapter, y = ave.polarity)) + # geom_point() + # geom_segment(aes(x = chapter, xend = chapter, y = 0, yend = ave.polarity)) + # geom_smooth() + # geom_hline(yintercept = 0, color = &quot;red&quot;) + # theme_minimal() + # labs(title = &quot;Adventures of Tom Sawyer Chronological Polarity&quot;) Create to strings, one with the positive chapters, and one from the negative chapters. # sawyer_poloarity_pos &lt;- sawyer_tm_polarity_2$all %&gt;% # filter(polarity &gt; 0) %&gt;% # pull(text.var) %&gt;% # paste(collapse = &quot; &quot;) # # sawyer_poloarity_neg &lt;- sawyer_tm_polarity_2$all %&gt;% # filter(polarity &lt; 0) %&gt;% # pull(text.var) %&gt;% # paste(collapse = &quot; &quot;) # # sawyer_polarity_tdm &lt;- c(sawyer_poloarity_pos, sawyer_poloarity_neg) %&gt;% # VectorSource() %&gt;% # VCorpus() %&gt;% # TermDocumentMatrix(control = list(weighting = weightTfIdf, # removePunctuation = TRUE, # stopwords = stopwords(kind = &quot;en&quot;))) Often authors will use more words when they are more passionate. Lengthy reviews may inflate overall sentiment since the reviews will inherently contain more positive or negative language as the review lengthens. 2.3 Emotion Classification Bar plots are usually a clearer alternative, but radar charts do look pretty. https://en.wikipedia.org/wiki/Robert_Plutchik#/media/File:Plutchik-wheel.svg # dat &lt;- sawyer_tidy %&gt;% # inner_join(get_sentiments(&quot;nrc&quot;), by = &quot;word&quot;) %&gt;% # filter(!sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&gt;% # mutate(sentiment = case_when(sentiment == &quot;joy&quot; ~ 1, # sentiment == &quot;trust&quot; ~ 2, # sentiment == &quot;fear&quot; ~ 3, # sentiment == &quot;surprise&quot; ~ 4, # sentiment == &quot;sadness&quot; ~ 5, # sentiment == &quot;disgust&quot; ~ 6, # sentiment == &quot;anger&quot; ~ 7, # sentiment == &quot;anticipation&quot; ~ 8, # TRUE ~ 9), # sentiment = factor(sentiment, levels = c(1:9), # labels = c(&quot;joy&quot;, &quot;trust&quot;, &quot;fear&quot;, &quot;surprise&quot;, # &quot;sadness&quot;, &quot;disgust&quot;, &quot;anger&quot;, # &quot;anticipation&quot;, &quot;other&quot;))) %&gt;% # count(sentiment) # # dat %&gt;% # radarchart::chartJSRadar() # library(gutenbergr) # sawyer_raw &lt;- gutenberg_works(title == &quot;The Adventures of Tom Sawyer&quot;) %&gt;% # gutenberg_download() # hotel %&gt;% filter(is.na(date_of_review)) # min(hotel$date_of_review, na.rm = TRUE) # skimr::skim(sawyer_raw) sawyer_raw is a tibble with 8,832 rows, with one row per line of text and 0-78 characters per line. This is a corpus with a single document and no metadata (although you could get multiple books at once, and attach the title and author as metadata). Most text requires some cleaning. I will want to remove the title lines, and add add some metadata, including the chapter number and line number. # sawyer &lt;- sawyer_raw %&gt;% # tail(-455) %&gt;% # chapter 1 starts on line 456 # mutate( # is_chap = str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE)), # chapter = cumsum(is_chap) # ) %&gt;% # filter(text != &quot;&quot; &amp; !str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE))) %&gt;% # mutate(line = row_number()) %&gt;% # select(line, chapter, text) # head(sawyer) A subjectivity lexicon is a predefined list of words associated with emotional context such as positive/negative. qdap::polarity() uses the lexicon::hash_sentiment_huliu lexicon with sentiment values in (+1, 0, -1.05, -1, -2). It is similar to tidytext::sentiments() AFINN lexicon (-5 to 5). tidytext::sentiments() also includes the NRC lexicon (classifying among 8 emotions) and the Bing lexicon (classifying as positive or negative). Subjectivity lexicons are typically short (a few thousand words), but work because of Zipfs law. According to this law, the nth-ranked item in a frequency table has a frequency count equal to 1/n of the top-ranked item. So infrequently used words are used very infrequently. 2.4 Comparison Cloud # sawyer_tidy %&gt;% # anti_join(stop_words, by = &quot;word&quot;) %&gt;% # filter(!str_detect(word, &quot;[0-9]&quot;)) %&gt;% # inner_join(get_sentiments(&quot;nrc&quot;), by = &quot;word&quot;) %&gt;% # filter(sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&gt;% # count(chapter, sentiment) %&gt;% # group_by(chapter) %&gt;% # mutate(pct = n / sum(n)) %&gt;% # ggplot(aes(x = chapter, y = pct, fill = sentiment, color = sentiment)) + # geom_area(alpha = 0.6) + # scale_x_continuous(breaks = 1:35, minor_breaks = NULL) + # scale_fill_few() + # scale_color_few() + # geom_hline(yintercept = 0.5, linetype = 2) + # theme_minimal() + # theme(legend.position = &quot;top&quot;) + # labs(title = &quot;Sentiment Proportion by Chapter&quot;, x = NULL, y = NULL, fill = NULL, color = NULL) # sawyer_tidy %&gt;% # anti_join(stop_words, by = &quot;word&quot;) %&gt;% # filter(!str_detect(word, &quot;[0-9]&quot;)) %&gt;% # inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% # ggplot(aes(x = value)) + # geom_density(fill = ggthemes::few_pal()(1), alpha = 0.6) + # theme_minimal() + # labs(title = &quot;AFINN Score Density&quot;) # sawyer_tidy %&gt;% # inner_join(get_sentiments(&quot;bing&quot;), by = &quot;word&quot;) %&gt;% # count(chapter, line, sentiment) %&gt;% # pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% # mutate(polarity = positive - negative) %&gt;% # ggplot(aes(x = as.factor(chapter), y = polarity)) + # geom_boxplot() + # geom_jitter(aes(color = as.factor(chapter)), alpha = 0.6, size = .5, show.legend = FALSE) + # theme_minimal() + # labs(title = &quot;Chapter Polarity&quot;) # sawyer_tidy %&gt;% # inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% # count(chapter, value) %&gt;% # ggplot(aes(area = n, fill = value)) + # treemapify::geom_treemap() One more cleaning step. Since these reviews are recorded in web sites, they are likely rife with spelling errors. Ill use the misspellings dataset from the fuzzyjoin package to remove them. # data(&quot;misspellings&quot;, package = &quot;fuzzyjoin&quot;) # # # Some misspelling have multiple correct possibilities - choose one # misspellings_winner &lt;- misspellings %&gt;% # group_by(misspelling) %&gt;% # slice(n = 1) # # hotel &lt;- hotel_raw_3 %&gt;% # unnest_tokens(&quot;word&quot;, review_text) %&gt;% # left_join(misspellings, by = c(&quot;word&quot; = &quot;misspelling&quot;)) %&gt;% # word = coalesce(correct, word) # hotel_raw_2 %&gt;% filter(review_id %in% c(28)) %&gt;% # select(review_text) %&gt;% # flextable::flextable() 2.5 Statistical Test Since this is a comparison of a numeric outcome to a multinominal predictor (property_name) or ordinal predictor(review_rating), you could perform an ANOVA test. my_aov &lt;- aov(polarity_score ~ as.factor(review_rating), data = hotel_tidy_polarity_bing) my_anova &lt;- anova(my_aov) tidy(my_anova) ## # A tibble: 2 x 6 ## term df sumsq meansq statistic p.value ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 as.factor(review_rating) 4 908. 227. 1875. 0 ## 2 Residuals 23271 2818. 0.121 NA NA #plot(TukeyHSD(my_aov)) my_lm &lt;- lm(polarity_score ~ as.factor(review_rating), data = hotel_tidy_polarity_bing) summary(my_lm) ## ## Call: ## lm(formula = polarity_score ~ as.factor(review_rating), data = hotel_tidy_polarity_bing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.50252 -0.23263 -0.00321 0.22338 2.88057 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.14021 0.01574 -8.91 &lt;2e-16 *** ## as.factor(review_rating)2 0.22704 0.02143 10.59 &lt;2e-16 *** ## as.factor(review_rating)3 0.47721 0.01838 25.97 &lt;2e-16 *** ## as.factor(review_rating)4 0.80924 0.01653 48.96 &lt;2e-16 *** ## as.factor(review_rating)5 0.94258 0.01597 59.01 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.348 on 23271 degrees of freedom ## (497 observations deleted due to missingness) ## Multiple R-squared: 0.2438, Adjusted R-squared: 0.2436 ## F-statistic: 1875 on 4 and 23271 DF, p-value: &lt; 2.2e-16 tbl_regression(my_lm) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #tkopdcxccq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #tkopdcxccq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tkopdcxccq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #tkopdcxccq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #tkopdcxccq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tkopdcxccq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tkopdcxccq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #tkopdcxccq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #tkopdcxccq .gt_column_spanner_outer:first-child { padding-left: 0; } #tkopdcxccq .gt_column_spanner_outer:last-child { padding-right: 0; } #tkopdcxccq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #tkopdcxccq .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #tkopdcxccq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #tkopdcxccq .gt_from_md > :first-child { margin-top: 0; } #tkopdcxccq .gt_from_md > :last-child { margin-bottom: 0; } #tkopdcxccq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #tkopdcxccq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #tkopdcxccq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tkopdcxccq .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #tkopdcxccq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tkopdcxccq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #tkopdcxccq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #tkopdcxccq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tkopdcxccq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tkopdcxccq .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #tkopdcxccq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tkopdcxccq .gt_sourcenote { font-size: 90%; padding: 4px; } #tkopdcxccq .gt_left { text-align: left; } #tkopdcxccq .gt_center { text-align: center; } #tkopdcxccq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #tkopdcxccq .gt_font_normal { font-weight: normal; } #tkopdcxccq .gt_font_bold { font-weight: bold; } #tkopdcxccq .gt_font_italic { font-style: italic; } #tkopdcxccq .gt_super { font-size: 65%; } #tkopdcxccq .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Beta 95% CI1 p-value as.factor(review_rating) 1 &mdash; &mdash; 2 0.23 0.19, 0.27 3 0.48 0.44, 0.51 4 0.81 0.78, 0.84 5 0.94 0.91, 1.0 1 CI = Confidence Interval "]]
